{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_generator as gg\n",
    "import obm_dp as dp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from util import diff\n",
    "from gnn_library.util import train, objectview\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'GENConv',\n",
    "    'head':              'regression',\n",
    "    'num_layers':        2,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        25,\n",
    "    'node_feature_dim':  4,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        64,\n",
    "    'dropout':           0.5,\n",
    "    'epochs':            50,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "args = objectview(args)\n",
    "\n",
    "m = 10; n = 6; train_num = 100; test_num = 30\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 1,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 3,\n",
    "    'weighted': True\n",
    "}\n",
    "geom_config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "train_dataset = DataLoader(\n",
    "    [\n",
    "        *gg.generate_examples(train_num, m, n, [0.8] * m, args.head, **er_config),\n",
    "        *gg.generate_examples(train_num, m, n, [0.8] * m, args.head, **ba_config),\n",
    "        *gg.generate_examples(2 * train_num, m, n, [0.8] * m, args.head, **geom_config),\n",
    "        #*gg.generate_examples(25, 8, 8, [0.8] * m, args.head, **geom_config),\n",
    "    ]\n",
    ")\n",
    "test_dataset = DataLoader(\n",
    "    [\n",
    "        *gg.generate_examples(test_num, m, n, [0.8] * m, args.head, **er_config),\n",
    "        *gg.generate_examples(test_num, m, n, [0.8] * m, args.head, **ba_config),\n",
    "        *gg.generate_examples(2 * test_num, m, n, [0.8] * m, args.head, **geom_config), \n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, trained_model, _ = train(train_dataset, test_dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 250\n",
    "node_configs = [(n, 16) for n in range(16, 52, 4)]\n",
    "node_configs = [(48, 16), (32, 32), (16, 48)]\n",
    "graph_configs = [\n",
    "    {\n",
    "        'graph_type': 'GM'\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'ER',\n",
    "        'p': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'BA',\n",
    "        'ba_param': 4,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2),\n",
    "    }\n",
    "]\n",
    "\n",
    "def test_model(trained_model, num_trials, node_configs, graph_configs):\n",
    "    for m, n in node_configs:\n",
    "        for config in graph_configs:\n",
    "            print(m, n, config)\n",
    "            greedy_vals = []\n",
    "            learned_vals = []\n",
    "            for _ in range(num_trials):\n",
    "                A = gg.sample_bipartite_graph(m, n, **config)\n",
    "                p = [0.8 for _ in range(m)]\n",
    "                coin_flips = [np.random.binomial(1, _p) for _p in p]\n",
    "                all_nodes = np.arange(n + m + 1)\n",
    "                offline_nodes = frozenset(np.arange(n))\n",
    "                matching = []\n",
    "                value = 0\n",
    "                for t in range(m):\n",
    "                    if coin_flips[t]:\n",
    "                        input = gg._to_pyg_test(A, p, offline_nodes, t)\n",
    "                        pred = trained_model(input.x, input.edge_index, input.edge_attr, input.batch, input.graph_features)\n",
    "                        if pred.detach().numpy() <= 0.5:\n",
    "                            mask = input.neighbors.detach().numpy()[:A.shape[1]]\n",
    "                            if np.any(mask):\n",
    "                                chosen_index = np.argmax(A[t, :][mask])\n",
    "                                choice = all_nodes[input.neighbors][chosen_index]\n",
    "                                matching.append((t, choice))\n",
    "                                value += A[t, choice]\n",
    "                    \n",
    "                        offline_nodes = diff(offline_nodes, choice)\n",
    "\n",
    "                _, offline_opt = dp.offline_opt(A, coin_flips)\n",
    "                _, greed_value = dp.greedy(A, coin_flips, 0.0)\n",
    "                if offline_opt > 0:\n",
    "                    learned_vals.append(value / offline_opt)\n",
    "                    greedy_vals.append(greed_value / offline_opt)\n",
    "            \n",
    "            learned_mean = np.mean(learned_vals); greedy_mean = np.mean(greedy_vals)\n",
    "            learned_std = np.std(learned_vals, ddof=1); greedy_std = np.std(greedy_vals, ddof=1)\n",
    "            print(f\"Learned competitive ratio: {learned_mean} ± {2 * learned_std / np.sqrt(num_trials)}\")\n",
    "            print(f\"Greedy competitive ratio: {greedy_mean} ± {2 * greedy_std / np.sqrt(num_trials)}\")\n",
    "            print()\n",
    "\n",
    "test_model(trained_model, num_trials, node_configs, graph_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 250\n",
    "node_configs = [(n, 16) for n in range(16, 52, 4)]\n",
    "node_configs = [(48, 12), (32, 32), (12, 48)]\n",
    "graph_configs = [\n",
    "    {\n",
    "        'graph_type': 'GM'\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'ER',\n",
    "        'p': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'BA',\n",
    "        'ba_param': 3,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2),\n",
    "    }\n",
    "]\n",
    "\n",
    "def test_model(trained_model, num_trials, node_configs, graph_configs):\n",
    "    for m, n in node_configs:\n",
    "        for config in graph_configs:\n",
    "            print(m, n, config)\n",
    "            greedy_vals = []\n",
    "            learned_vals = []\n",
    "            for _ in range(num_trials):\n",
    "                A = gg.sample_bipartite_graph(m, n, **config)\n",
    "                p = [0.8 for _ in range(m)]\n",
    "                coin_flips = [np.random.binomial(1, _p) for _p in p]\n",
    "                all_nodes = np.arange(n + m + 1)\n",
    "                offline_nodes = frozenset(np.arange(n))\n",
    "                matching = []\n",
    "                value = 0\n",
    "                for t in range(m):\n",
    "                    if coin_flips[t]:\n",
    "                        input = gg._to_pyg_test(A, p, offline_nodes, t)\n",
    "                        pred = trained_model(input.x, input.edge_index, input.edge_attr, input.batch, input.graph_features)\n",
    "                        chosen_index = np.argmax(pred[input.neighbors].detach().numpy())\n",
    "                        choice = all_nodes[input.neighbors][chosen_index]\n",
    "                        if choice < n:\n",
    "                            matching.append((t, choice))\n",
    "                            value += A[t, choice]\n",
    "                    \n",
    "                        offline_nodes = diff(offline_nodes, choice)\n",
    "\n",
    "                _, offline_opt = dp.offline_opt(A, coin_flips)\n",
    "                _, greed_value = dp.greedy(A, coin_flips, 0.0)\n",
    "                if offline_opt > 0:\n",
    "                    learned_vals.append(value / offline_opt)\n",
    "                    greedy_vals.append(greed_value / offline_opt)\n",
    "            \n",
    "            learned_mean = np.mean(learned_vals); greedy_mean = np.mean(greedy_vals)\n",
    "            learned_std = np.std(learned_vals, ddof=1); greedy_std = np.std(greedy_vals, ddof=1)\n",
    "            print(f\"Learned competitive ratio: {learned_mean} ± {2 * learned_std / np.sqrt(num_trials)}\")\n",
    "            print(f\"Greedy competitive ratio: {greedy_mean} ± {2 * greedy_std / np.sqrt(num_trials)}\")\n",
    "            print()\n",
    "\n",
    "test_model(trained_model, num_trials, node_configs, graph_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def edge_weight_dist(config):\n",
    "  weights = []\n",
    "  for _ in range(100):\n",
    "    weight = gg.sample_bipartite_graph(8, 8, **config)\n",
    "    weight[weight>0] = 1\n",
    "    weights.append(weight.sum(axis=0))\n",
    "  return np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2)\n",
    "    }\n",
    "edge_weight_dist(config).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 0.5\n",
    "    }\n",
    "edge_weight_dist(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "outputs = [\n",
    "  (\n",
    "    [0.934, 0.919, 0.909, 0.910, 0.908, 0.905, 0.909, 0.909, 0.910],\n",
    "    [0.898, 0.867, 0.845, 0.838, 0.829, 0.798, 0.782, 0.763, 0.761],\n",
    "    'GMISSION'\n",
    "  ),\n",
    "  (\n",
    "    [0.915, 0.911, 0.934, 0.950, 0.962, 0.965, 0.965, 0.968, 0.969],\n",
    "    [0.956, 0.921, 0.888, 0.876, 0.864, 0.852, 0.847, 0.842, 0.846],\n",
    "    'ER'\n",
    "  ),\n",
    "  (\n",
    "    [0.909, 0.906, 0.918, 0.929, 0.942, 0.943, 0.952, 0.950, 0.955],\n",
    "    [0.875, 0.828, 0.821, 0.806, 0.796, 0.795, 0.788, 0.774, 0.774],\n",
    "    'BA'\n",
    "  ),\n",
    "  (\n",
    "    [0.859, 0.861, 0.882, 0.903, 0.930, 0.936, 0.949, 0.949, 0.953],\n",
    "    [0.961, 0.941, 0.905, 0.875, 0.855, 0.838, 0.825, 0.814, 0.804],\n",
    "    'GEOM'\n",
    "  ),\n",
    "]\n",
    "\n",
    "node_seq = [n/16 for n in range(16, 52, 4)]\n",
    "\n",
    "for output in outputs:\n",
    "    plt.plot(node_seq, output[0], label=f'GNN')\n",
    "    plt.plot(node_seq, output[1], label=f'Greedy')\n",
    "    plt.legend()\n",
    "    plt.title(output[2])\n",
    "    plt.xlabel('Offline/Online ratio')\n",
    "    plt.ylabel('Competitive ratio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10; n = 10; num_trials = 1\n",
    "\n",
    "# config = {\n",
    "#     'graph_type': 'ER',\n",
    "#     'p': 0.75,\n",
    "#     'weighted': True\n",
    "# }\n",
    "# config = {\n",
    "#         'graph_type': 'BA',\n",
    "#         'ba_param': 3,\n",
    "#         'weighted': True\n",
    "# }\n",
    "config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "# config = {\n",
    "#         'graph_type': 'GM'\n",
    "# }\n",
    "def diagnose(hints, preds):\n",
    "    return np.max(hints) - hints[np.argmax(preds)]\n",
    "    \n",
    "lost_weights = []\n",
    "choices = []\n",
    "no_skips = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    A = gg.sample_bipartite_graph(m, n, **config)\n",
    "    p = [0.8 for _ in range(m)]\n",
    "    cache = dp.cache_stochastic_opt(A, p)\n",
    "    coin_flips = [np.random.binomial(1, _p) for _p in p]\n",
    "    all_nodes = np.arange(n + m + 1)\n",
    "    offline_nodes = frozenset(np.arange(n))\n",
    "    OPT = cache[0][offline_nodes][0]\n",
    "    matching = []\n",
    "    value = 0\n",
    "    for t in range(m):\n",
    "        if coin_flips[t]:\n",
    "            input = gg._to_pyg_test(A, p, offline_nodes, t)\n",
    "            hints = dp.one_step_stochastic_opt(A, offline_nodes, t, cache)\n",
    "            opt_index = np.argmax(hints)\n",
    "            pred = trained_model(input.x, input.edge_index, input.edge_attr, input.batch, input.graph_features)\n",
    "            preds = pred[input.neighbors].detach().numpy()\n",
    "            chosen_index = np.argmax(preds)\n",
    "            choice = all_nodes[input.neighbors][chosen_index]\n",
    "            lost_weight = diagnose(hints, preds) / OPT\n",
    "\n",
    "            #print(hints, preds, A[t,:][input.neighbors.detach().numpy()[:12]])\n",
    "            choices.append(opt_index == chosen_index)\n",
    "            print(opt_index, chosen_index, hints[opt_index], hints[chosen_index], len(hints) - 1)\n",
    "            no_skips.append(chosen_index == len(hints) - 1)\n",
    "\n",
    "            lost_weights.append(lost_weight)\n",
    "            #print(f\"Lost weight: {lost_weight}\")\n",
    "            \n",
    "            \n",
    "            if choice < n:            \n",
    "                matching.append((t, choice))\n",
    "                value += A[t, choice]\n",
    "\n",
    "        \n",
    "            offline_nodes = diff(offline_nodes, choice)\n",
    "    greedy_matching, greedy_val = dp.greedy(A, coin_flips, 0)\n",
    "    # print(len(matching), value, len(greedy_matching), greedy_val, matching, greedy_matching)\n",
    "    # print(A[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(no_skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lost_weights, bins=25)\n",
    "print(np.mean(lost_weights).round(3), np.std(lost_weights).round(3), len(lost_weights) / 250)\n",
    "print(np.quantile(lost_weights, [0.1 * x for x in range(1,10)]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lost_weights, bins=25)\n",
    "print(np.mean(lost_weights).round(3), np.std(lost_weights).round(3), len(lost_weights))\n",
    "print(np.quantile(lost_weights, [0.1 * x for x in range(1,10)]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to predict skip more often?\n",
    "for t in range(m):\n",
    "  print(t, np.mean((record[0][t])).round(3), np.mean(record[1][t]).round(3), np.mean(record[2][t]).round(3))\n",
    "  # plt.bar(labels, vals)\n",
    "  # plt.xticks(rotation=45)\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 0.434 0.184 -0.064\n",
    "1 0.46 0.177 -0.068\n",
    "2 0.515 0.178 -0.059\n",
    "3 0.545 0.173 -0.066\n",
    "4 0.677 0.144 -0.071\n",
    "5 0.99 0.094 -0.0\n",
    "\n",
    "0 0.5 0.11 -0.049\n",
    "1 0.527 0.113 -0.038\n",
    "2 0.465 0.105 -0.046\n",
    "3 0.547 0.091 -0.036\n",
    "4 0.552 0.079 -0.04\n",
    "5 0.99 0.075 -0.0\n",
    "\n",
    "0 0.522 0.115 -0.038\n",
    "1 0.438 0.106 -0.046\n",
    "2 0.576 0.105 -0.058\n",
    "3 0.505 0.093 -0.061\n",
    "4 0.626 0.079 -0.045\n",
    "5 0.99 0.071 -0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 14; n = 8; num_trials = 100\n",
    "\n",
    "# config = {\n",
    "#     'graph_type': 'ER',\n",
    "#     'p': 0.75,\n",
    "#     'weighted': True\n",
    "# }\n",
    "config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "def error_code(chosen_index, pred_index, length):\n",
    "    if chosen_index == pred_index and chosen_index == length - 1:\n",
    "        return \"Correct\"\n",
    "    elif chosen_index == pred_index:\n",
    "        return \"Correct\"\n",
    "    elif chosen_index == length - 1:\n",
    "        return \"Incorrect\"\n",
    "    elif pred_index == length - 1:\n",
    "        return \"Incorrect\"\n",
    "    else:\n",
    "        return \"Incorrect\"\n",
    "    \n",
    "record = ([[] for _ in range(m)], [[] for _ in range(m)], [[] for _ in range(m)])\n",
    "greedy_vals = []\n",
    "learned_vals = []\n",
    "for i in range(num_trials):\n",
    "    A = gg.sample_bipartite_graph(m, n, **config)\n",
    "    p = [1 for _ in range(m)]\n",
    "    cache = dp.cache_stochastic_opt(A, p)\n",
    "    coin_flips = [np.random.binomial(1, _p) for _p in p]\n",
    "    all_nodes = np.arange(n + m + 1)\n",
    "    offline_nodes = frozenset(np.arange(n))\n",
    "    matching = []\n",
    "    value = 0\n",
    "    for t in range(m):\n",
    "        if coin_flips[t]:\n",
    "            input = gg._to_pyg_test(A, p, offline_nodes, t)\n",
    "            pred = trained_model(input.x, input.edge_index, input.edge_attr, input.graph_features)\n",
    "            \n",
    "            hints = dp.one_step_stochastic_opt(A, offline_nodes, t, cache)\n",
    "            hints = np.max(hints) - hints\n",
    "            # print(t)\n",
    "            # print(pred[input.neighbors].squeeze().detach().numpy())\n",
    "            # print(hints)\n",
    "            # print()\n",
    "            chosen_index = np.argmin(pred[input.neighbors].detach().numpy())\n",
    "            opt_index = np.argmin(hints)\n",
    "            choice = all_nodes[input.neighbors][chosen_index]\n",
    "            correct = (chosen_index == opt_index)\n",
    "            reduction = hints[opt_index] - hints[chosen_index]\n",
    "            record[0][t].append(error_code(opt_index, chosen_index, len(hints)))\n",
    "            record[1][t].append(reduction)\n",
    "            record[2][t].append(np.sum(input.neighbors.detach().numpy()))\n",
    "            if choice < n:\n",
    "                matching.append((t, choice))\n",
    "                value += A[t, choice]\n",
    "        \n",
    "            offline_nodes = diff(offline_nodes, choice)\n",
    "\n",
    "   \n",
    "    opt_matching, opt_value = dp.stochastic_opt(A, coin_flips, cache)\n",
    "    _, greed_value = dp.greedy(A, coin_flips, 0)\n",
    "    learned_vals.append(value / opt_value)\n",
    "    greedy_vals.append(greed_value / opt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to predict skip more often?\n",
    "import matplotlib.pyplot as plt\n",
    "for t in range(m):\n",
    "  labels, vals =  np.unique(record[0][t], return_counts=True)\n",
    "  print(t, np.mean(np.array(record[0][t]) == 'Correct'), np.mean(record[2][t]))\n",
    "  # plt.bar(labels, vals)\n",
    "  # plt.xticks(rotation=45)\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 0.59 8.18\n",
    "1 0.51 7.69\n",
    "2 0.54 7.35\n",
    "3 0.64 6.55\n",
    "4 0.54 6.2\n",
    "5 0.69 5.54\n",
    "6 0.68 5.12\n",
    "7 0.64 4.61\n",
    "8 0.63 4.19\n",
    "9 0.7 3.78\n",
    "10 0.67 3.31\n",
    "11 0.74 2.65\n",
    "12 0.83 2.32\n",
    "13 1.0 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(record[0])):\n",
    "    print(f\"Node: {i}, average reduction: {np.mean(record[1][i])}\")\n",
    "    print(f\"Node: {i}, average neighbors: {np.mean(record[2][i])}\")\n",
    "    plt.hist(record[1][i], bins=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, opt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greed_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_test(num_trials, node_configs, graph_configs, r):\n",
    "    matched_weights = []\n",
    "    for m, n in node_configs:\n",
    "        for config in graph_configs:\n",
    "            vals = []\n",
    "            print(m, n, config)\n",
    "            for _ in range(num_trials):\n",
    "                A = gg.sample_bipartite_graph(m, n, **config)\n",
    "                p = [0.8 for _ in range(m)]\n",
    "                coin_flips = [np.random.binomial(1, _p) for _p in p]\n",
    "                matching, val = dp.greedy(A, coin_flips, r)\n",
    "                matched_weight = [A[t, i] for (t, i) in matching]\n",
    "                matched_weights.append(matched_weight)\n",
    "                vals.append(val / dp.offline_opt(A, coin_flips)[1])\n",
    "            mean_ratio = np.mean(vals)\n",
    "            std_ratio = np.std(vals, ddof=1)\n",
    "            print(f\"Stoch opt competitive ratio: {np.round(mean_ratio, 3)} ± {np.round(2 * std_ratio / np.sqrt(num_trials), 3)}\")\n",
    "            print()\n",
    "    return np.array(matched_weights)\n",
    "\n",
    "\n",
    "num_trials = 1000\n",
    "node_configs = [(50, 10)]\n",
    "graph_configs = [\n",
    "    {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2)\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_weights = greedy_test(num_trials, node_configs, graph_configs, 0)\n",
    "matched_weights.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_weights = greedy_test(num_trials, node_configs, graph_configs, 0)\n",
    "matched_weights.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_test(num_trials, node_configs, graph_configs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_test(num_trials, node_configs, graph_configs, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_test(num_trials, node_configs, graph_configs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_test(num_trials, node_configs, graph_configs, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5; n = 10\n",
    "config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "A = gg.sample_bipartite_graph(m, n, **config)\n",
    "for t in range(m):\n",
    "  print(np.mean(A[t, :]), np.std(A[t, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 0.75,\n",
    "    'weighted': True\n",
    "}\n",
    "\n",
    "A = gg.sample_bipartite_graph(m, n, **config)\n",
    "for t in range(m):\n",
    "  print(np.mean(A[t, :]), np.std(A[t, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 4,\n",
    "    'weighted': True\n",
    "}\n",
    "\n",
    "A = gg.sample_bipartite_graph(m, n, **config)\n",
    "weights = A.flatten()\n",
    "for t in range(m):\n",
    "  print(np.mean(A[t, :]), np.std(A[t, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
