{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graph_generator as gg\n",
    "import algorithms as dp\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from gnn_library.util import train, save, load\n",
    "from evaluate import batched_test_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'GENConv',\n",
    "    'head':              'classification',\n",
    "    'num_layers':        2,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        32,\n",
    "    'node_feature_dim':  4,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        64,\n",
    "    'dropout':           0.35,\n",
    "    'epochs':            50,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "m = 10; n = 6; train_num = 100; test_num = 30\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 1,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 4,\n",
    "    'weighted': True\n",
    "}\n",
    "geom_config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "class Dataset(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, data_list):\n",
    "        super().__init__(None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "\n",
    "train_dataset_1 = Dataset(\n",
    "    [\n",
    "        *gg.generate_examples(train_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **er_config),\n",
    "        *gg.generate_examples(train_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **ba_config),\n",
    "        *gg.generate_examples(2 * train_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **geom_config),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset_1 = Dataset(\n",
    "    [\n",
    "        *gg.generate_examples(test_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **er_config),\n",
    "        *gg.generate_examples(test_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **ba_config),\n",
    "        *gg.generate_examples(2 * test_num, 10, 6, np.random.uniform(0.5, 1, m), args['head'], **geom_config)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset_2 = Dataset(\n",
    "    [\n",
    "        *gg.generate_examples(train_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **er_config),\n",
    "        *gg.generate_examples(train_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **ba_config),\n",
    "        *gg.generate_examples(2 * train_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **geom_config),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset_2 = Dataset(\n",
    "    [\n",
    "        *gg.generate_examples(test_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **er_config),\n",
    "        *gg.generate_examples(test_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **ba_config),\n",
    "        *gg.generate_examples(2 * test_num, 8, 8, np.random.uniform(0.5, 1, m), args['head'], **geom_config)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader_1 = DataLoader(\n",
    "    train_dataset_1,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "test_loader_1 = DataLoader(\n",
    "    test_dataset_1,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "train_loader_2 = DataLoader(\n",
    "    train_dataset_2,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader_2 = DataLoader(\n",
    "    test_dataset_2,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, GNN1, _ = train(train_loader_1, test_loader_1, args)\n",
    "#_, _, GNN2, _ = train(train_loader_2, test_loader_2, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(GNN1, args, 'SKIP_CLASS')\n",
    "# save(GNN2, args, 'GNN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, args = load('SKIP_CLASS')\n",
    "#model2 = load('GNN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "batch_size = 5\n",
    "node_config = (48, 16)\n",
    "graph_config =  {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 0.75,\n",
    "    'weighted': True\n",
    "}\n",
    "\n",
    "(gnn1_learned_ratios, greedy_ratios1), log1 = batched_test_model(\n",
    "            model1,\n",
    "            args,\n",
    "            num_trials,\n",
    "            batch_size,\n",
    "            *node_config,\n",
    "            graph_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(gnn1_learned_ratios), np.mean(greedy_ratios1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 250\n",
    "batch_size = 50\n",
    "node_config = (48, 16)\n",
    "graph_config =  {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 0.75,\n",
    "    'weighted': True\n",
    "}\n",
    "\n",
    "(gnn1_learned_ratios, greedy_ratios1), log1 = batched_test_model(\n",
    "            model1,\n",
    "            device,\n",
    "            num_trials,\n",
    "            batch_size,\n",
    "            *node_config,\n",
    "            graph_config)\n",
    "\n",
    "(gnn2_learned_ratios, greedy_ratios2), log2 = batched_test_model(\n",
    "            model2,\n",
    "            device,\n",
    "            num_trials,\n",
    "            batch_size,\n",
    "            *node_config,\n",
    "            graph_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in log1.items():\n",
    "    print(key, np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in log2.items():\n",
    "    print(key, np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(gnn1_learned_ratios), np.mean(greedy_ratios1))\n",
    "print(np.mean(gnn2_learned_ratios), np.mean(greedy_ratios2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 500\n",
    "node_configs = [(x, 16) for x in np.arange(4, 64, 2)]\n",
    "# of nodes [20 -> 80]\n",
    "# of nodes in batch [10,000 -> 40,000]\n",
    "batch_size = 100 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
    "graph_configs = [\n",
    "    # {\n",
    "    #     'graph_type': 'GM'\n",
    "    # },\n",
    "    {\n",
    "        'graph_type': 'ER',\n",
    "        'p': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'BA',\n",
    "        'ba_param': 4,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2),\n",
    "    }\n",
    "]\n",
    "\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "print(ratios)\n",
    "data = {config['graph_type']: [] for config in graph_configs}\n",
    "for graph_config in graph_configs:\n",
    "    for i, node_config in enumerate(node_configs):\n",
    "        (gnn1_learned_ratios, greedy_ratios), _ = batched_test_model(\n",
    "            GNN1,\n",
    "            device,\n",
    "            num_trials,\n",
    "            batch_size,\n",
    "            *node_config,\n",
    "            graph_config)\n",
    "\n",
    "        (gnn2_learned_ratios, _), _ = batched_test_model(\n",
    "            GNN2,\n",
    "            device,\n",
    "            num_trials,\n",
    "            batch_size,\n",
    "            *node_config,\n",
    "            graph_config)\n",
    "\n",
    "        data[graph_config['graph_type']].append(np.array(\n",
    "            [gnn1_learned_ratios, gnn2_learned_ratios, greedy_ratios]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_type, comp_ratios in data.items():\n",
    "    greedy_avg_ratios = []\n",
    "    gnn1_avg_ratios = []\n",
    "    gnn2_avg_ratios = []\n",
    "    max_avg_ratios = []\n",
    "\n",
    "    for trial_ratios in comp_ratios:\n",
    "        gnn1_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
    "        gnn2_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
    "        greedy_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
    "        max_avg_ratios.append(np.array(np.max(trial_ratios, axis=0)).mean())\n",
    "\n",
    "    print(graph_type)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(graph_type)\n",
    "    plt.plot(ratios, gnn1_avg_ratios, label='GNN1')\n",
    "    plt.plot(ratios, gnn2_avg_ratios, label='GNN2')\n",
    "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
    "    plt.plot(ratios, max_avg_ratios, label='MAX')\n",
    "    plt.xlabel('# online / # offline')\n",
    "    plt.ylabel('Average competitive ratio')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 250\n",
    "node_configs = [(32, x)) for x in np.arange(4, 33)]\n",
    "graph_configs = [\n",
    "    # {\n",
    "    #     'graph_type': 'GM'\n",
    "    # },\n",
    "    {\n",
    "        'graph_type': 'ER',\n",
    "        'p': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    # {\n",
    "    #     'graph_type': 'BA',\n",
    "    #     'ba_param': 4,\n",
    "    #     'weighted': True\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'GEOM',\n",
    "    #     'threshold': 0.2,\n",
    "    #     'scaling': 1 / np.sqrt(2),\n",
    "    # }\n",
    "]\n",
    "\n",
    "output = {}\n",
    "# graph_config = {\n",
    "#     'graph_type': 'GM',\n",
    "# }\n",
    "for p in [0.05, 0.1, 0.15, 0.2]:\n",
    "    graph_config = {\n",
    "        'graph_type': 'ER',\n",
    "        'weighted': True,\n",
    "        'p': p\n",
    "    }\n",
    "    for node_config in node_configs:\n",
    "        out = test_model(trained_model, num_trials, *node_config, graph_config)\n",
    "        #output[f\"{graph_config['graph_type']}, {node_config}\"] = out\n",
    "        output[f\"{graph_config['graph_type']}(p={p}), {node_config}\"] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "def format_dict(vals):\n",
    "   return dict(zip(\n",
    "            ['label', 'whislo', 'q1', 'med', 'q3', 'whishi'],\n",
    "            vals\n",
    "        ))\n",
    "\n",
    "KHALIL = {\n",
    "  'ER(p=0.05), (30, 10)': format_dict(['Khalil', 0.66, 0.84, 0.895, 0.945, 1.0]),\n",
    "  'ER(p=0.1), (30, 10)': format_dict(['Khalil', 0.69, 0.83, 0.88, 0.93, 1.0]),\n",
    "  'ER(p=0.15), (30, 10)': format_dict(['Khalil', 0.71, 0.84, 0.89, 0.935, 1.0]),\n",
    "  'ER(p=0.2), (30, 10)': format_dict(['Khalil', 0.735, 0.855, 0.905, 0.94, 1.0]),\n",
    "  'ER(p=0.05), (60, 10)': format_dict(['Khalil', 0.685, 0.83, 0.88, 0.925, 1.0]),\n",
    "  'ER(p=0.1), (60, 10)': format_dict(['Khalil', 0.75, 0.86, 0.905, 0.935, 1.0]),\n",
    "  'ER(p=0.15), (60, 10)': format_dict(['Khalil', 0.79, 0.885, 0.93, 0.955, 1.0]),\n",
    "  'ER(p=0.2), (60, 10)': format_dict(['Khalil', 0.835, 0.91, 0.945, 0.965, 1.0]),\n",
    "  'ER(p=0.05), (100, 100)': format_dict(['Khalil', 0.83, 0.865, 0.875, 0.89, 0.94]),\n",
    "  'ER(p=0.1), (100, 100)': format_dict(['Khalil', 0.84, 0.87, 0.88, 0.895, 0.93]),\n",
    "  'ER(p=0.15), (100, 100)': format_dict(['Khalil', 0.86, 0.885, 0.905, 0.91, 0.955]),\n",
    "  'ER(p=0.2), (100, 100)': format_dict(['Khalil', 0.87, 0.905, 0.92, 0.935, 0.965]),\n",
    "  'GM, (30, 10)': format_dict(['Khalil', 0.7, 0.835, 0.87, 0.91, 1.0]),\n",
    "  'GM, (60, 10)': format_dict(['Khalil', 0.77, 0.865, 0.90, 0.915, 1.0]),\n",
    "  'GM, (100, 100)': format_dict(['Khalil', 0.83, 0.88, 0.89, 0.905, 0.94]),\n",
    "}\n",
    "\n",
    "boxprops = dict(linestyle='-', linewidth=2, color='black')\n",
    "medianprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "for title, stats in output.items():\n",
    "    _, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.bxp([KHALIL[title], *stats], showfliers=False, boxprops=boxprops, medianprops=medianprops)\n",
    "    plt.title(title)\n",
    "    # Give plot a gray background like ggplot.\n",
    "    ax.set_facecolor('#EBEBEB')\n",
    "    # Remove border around plot.\n",
    "    [ax.spines[side].set_visible(False) for side in ax.spines]\n",
    "    # Style the grid.\n",
    "    ax.grid(which='major', color='white', linewidth=1.2)\n",
    "    ax.grid(which='minor', color='white', linewidth=0.6)\n",
    "    # Show the minor ticks and grid.\n",
    "    ax.minorticks_on()\n",
    "    # Now hide the minor ticks (but leave the gridlines).\n",
    "    ax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "    # Only show minor gridlines once in between major gridlines.\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
