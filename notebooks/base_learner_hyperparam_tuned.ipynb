{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'local (Python 3.10.12)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gnn_library.util import train, save, load\n",
    "from evaluate import evaluate_model, pp_output\n",
    "import instance_generator as ig\n",
    "import torch_converter as tc\n",
    "import evaluate as ev\n",
    "import osmnx as ox\n",
    "from util import Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.12.0+cu102\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    args = {\n",
    "        'processor':         'GENConv',\n",
    "        'head':              'regression',\n",
    "        'num_layers':        trial.suggest_int(\"num_layers{}\", 1, 6),\n",
    "        'num_mlp_layers':    trial.suggest_int(\"num_mlp_layers{}\", 2, 5), # TODO set to larger\n",
    "        'aggr':              'max',\n",
    "        'batch_size':        2**trial.suggest_int(\"log_batch_size\", 1, 6), \n",
    "        'node_feature_dim':  4,\n",
    "        'edge_feature_dim':  1,\n",
    "        'graph_feature_dim': 2,\n",
    "        'hidden_dim':        2**trial.suggest_int(\"hidden_dim\", 1, 7), # TODO set to 128\n",
    "        'output_dim':        1,\n",
    "        'dropout':           trial.suggest_float(\"dropout\", 0, 0.5),\n",
    "        'epochs':            trial.suggest_int(\"epochs\", 5, 100), # TODO set to larger\n",
    "        'opt':               trial.suggest_categorical(\"optimizer\", [\"adam\", \"adagrad\"]),\n",
    "        'opt_scheduler':     'none',\n",
    "        'opt_restart':       0,\n",
    "        'weight_decay':      5e-3, # TODO possibly modify\n",
    "        'lr':                trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True),\n",
    "        'device':            device\n",
    "    }\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\targs = define_model(trial)\n",
    "\ttrain_num = 100; test_num = 30\n",
    "\n",
    "\ter_config = {\n",
    "\t'graph_type': 'ER',\n",
    "\t'p': 1,\n",
    "\t'weighted': True\n",
    "\t}\n",
    "\tba_config = {\n",
    "\t'graph_type': 'BA',\n",
    "\t'ba_param': 2,\n",
    "\t'weighted': True\n",
    "\t}\n",
    "\tgeom_config = {\n",
    "\t'graph_type': 'GEOM',\n",
    "\t'threshold': 0.2,\n",
    "\t'scaling': 1 / np.sqrt(2)\n",
    "\t}\n",
    "\n",
    "\trng = np.random.default_rng()\n",
    "\n",
    "\n",
    "\ttrain_instances = [\n",
    "\t\t*ig.sample_instances(9, 7, train_num, rng, **er_config),\n",
    "\t\t*ig.sample_instances(9, 7, train_num, rng, **ba_config),\n",
    "\t\t*ig.sample_instances(9, 7, train_num, rng, **geom_config),\n",
    "\t]\n",
    "\n",
    "\ttest_instances = [\n",
    "\t\t*ig.sample_instances(9, 7, test_num, rng, **er_config),\n",
    "\t\t*ig.sample_instances(9, 7, test_num, rng, **ba_config),\n",
    "\t\t*ig.sample_instances(9, 7, test_num, rng, **geom_config),\n",
    "\t]\n",
    "\n",
    "\n",
    "\ttrain_data = Dataset(tc._instances_to_train_samples(train_instances, args['head']))\n",
    "\ttest_data = Dataset(tc._instances_to_train_samples(test_instances, args['head']))\n",
    "\n",
    "\ttrain_loader = DataLoader(\n",
    "\ttrain_data,\n",
    "\tbatch_size=args['batch_size'],\n",
    "\tshuffle=True,\n",
    "\tnum_workers=4\n",
    "\t)\n",
    "\n",
    "\ttest_loader = DataLoader(\n",
    "\ttest_data,\n",
    "\tbatch_size=args['batch_size'],\n",
    "\tshuffle=True,\n",
    "\tnum_workers=4\n",
    "\t)\n",
    "\n",
    "\t### Training\n",
    "\n",
    "\t_, _, test_accuracies, GNN, _ = train(train_loader, test_loader, args, trial)\n",
    "\treturn test_accuracies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-13 09:15:15,609] A new study created in memory with name: no-name-1db4720c-fd92-4f21-96ea-12bb553392af\n",
      "Training:   0%|          | 0/51 [00:00<?, ?Epochs/s]/home/alexhay/.local/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
      "Training: 100%|██████████| 51/51 [02:24<00:00,  2.84s/Epochs]\n",
      "[I 2024-01-13 09:17:50,509] Trial 0 finished with value: 0.6881720423698425 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 3, 'log_batch_size': 5, 'hidden_dim': 12, 'dropout': 0.4734006881921554, 'epochs': 51, 'optimizer': 'rmsprop', 'lr': 4.023110050071799e-05}. Best is trial 0 with value: 0.6881720423698425.\n",
      "Training: 100%|██████████| 29/29 [00:58<00:00,  2.02s/Epochs]\n",
      "[I 2024-01-13 09:18:55,463] Trial 1 finished with value: 0.8659638166427612 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 3, 'log_batch_size': 6, 'hidden_dim': 20, 'dropout': 0.05547570651232242, 'epochs': 29, 'optimizer': 'sgd', 'lr': 0.007323990710908852}. Best is trial 1 with value: 0.8659638166427612.\n",
      "Training: 100%|██████████| 92/92 [02:30<00:00,  1.64s/Epochs]\n",
      "[I 2024-01-13 09:21:32,524] Trial 2 finished with value: 0.8765243291854858 and parameters: {'num_layers{}': 2, 'num_mlp_layers{}': 2, 'log_batch_size': 6, 'hidden_dim': 44, 'dropout': 0.39678530690563873, 'epochs': 92, 'optimizer': 'sgd', 'lr': 0.0018747862561094395}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training: 100%|██████████| 59/59 [13:54<00:00, 14.14s/Epochs]\n",
      "[I 2024-01-13 09:35:33,466] Trial 3 finished with value: 0.4899536073207855 and parameters: {'num_layers{}': 2, 'num_mlp_layers{}': 3, 'log_batch_size': 2, 'hidden_dim': 29, 'dropout': 0.49513518875508844, 'epochs': 59, 'optimizer': 'adagrad', 'lr': 7.665212347752094e-05}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training: 100%|██████████| 12/12 [00:22<00:00,  1.87s/Epochs]\n",
      "[I 2024-01-13 09:36:01,659] Trial 4 finished with value: 0.8465116024017334 and parameters: {'num_layers{}': 5, 'num_mlp_layers{}': 4, 'log_batch_size': 6, 'hidden_dim': 59, 'dropout': 0.018709906105669416, 'epochs': 12, 'optimizer': 'sgd', 'lr': 0.00727930119771755}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training:   0%|          | 0/21 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 09:36:09,562] Trial 5 pruned. \n",
      "Training:   0%|          | 0/31 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 09:36:18,025] Trial 6 pruned. \n",
      "Training:   5%|▌         | 4/77 [01:21<24:56, 20.50s/Epochs]\n",
      "[I 2024-01-13 09:37:45,219] Trial 7 pruned. \n",
      "Training:   0%|          | 0/75 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 09:37:53,919] Trial 8 pruned. \n",
      "Training:  74%|███████▍  | 64/86 [28:45<09:53, 26.96s/Epochs]\n",
      "[I 2024-01-13 10:06:45,333] Trial 9 pruned. \n",
      "Training:  60%|██████    | 60/100 [03:51<02:34,  3.86s/Epochs]\n",
      "[I 2024-01-13 10:10:42,133] Trial 10 pruned. \n",
      "Training:   0%|          | 0/40 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:10:54,657] Trial 11 pruned. \n",
      "Training:   0%|          | 0/7 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:11:04,144] Trial 12 pruned. \n",
      "Training: 100%|██████████| 55/55 [02:02<00:00,  2.23s/Epochs]\n",
      "[I 2024-01-13 10:13:12,537] Trial 13 finished with value: 0.868300199508667 and parameters: {'num_layers{}': 1, 'num_mlp_layers{}': 2, 'log_batch_size': 5, 'hidden_dim': 15, 'dropout': 0.18984754930109946, 'epochs': 55, 'optimizer': 'sgd', 'lr': 0.049292363738013184}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training:   0%|          | 0/61 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:13:21,312] Trial 14 pruned. \n",
      "Training:   8%|▊         | 8/95 [01:00<10:55,  7.53s/Epochs]\n",
      "[I 2024-01-13 10:14:27,247] Trial 15 pruned. \n",
      "Training:   0%|          | 0/72 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:14:35,863] Trial 16 pruned. \n",
      "Training: 100%|██████████| 44/44 [02:48<00:00,  3.83s/Epochs]\n",
      "[I 2024-01-13 10:17:29,746] Trial 17 finished with value: 0.8449848294258118 and parameters: {'num_layers{}': 1, 'num_mlp_layers{}': 2, 'log_batch_size': 4, 'hidden_dim': 37, 'dropout': 0.29263591642926934, 'epochs': 44, 'optimizer': 'adam', 'lr': 0.00043725719992969127}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training:   9%|▉         | 8/85 [00:26<04:11,  3.27s/Epochs]\n",
      "[I 2024-01-13 10:18:01,737] Trial 18 pruned. \n",
      "Training:   6%|▌         | 4/65 [00:39<09:58,  9.82s/Epochs]\n",
      "[I 2024-01-13 10:18:47,341] Trial 19 pruned. \n",
      "Training:   9%|▉         | 8/86 [00:34<05:32,  4.26s/Epochs]\n",
      "[I 2024-01-13 10:19:27,249] Trial 20 pruned. \n",
      "Training: 100%|██████████| 27/27 [00:47<00:00,  1.74s/Epochs]\n",
      "[I 2024-01-13 10:20:20,086] Trial 21 finished with value: 0.8602484464645386 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 3, 'log_batch_size': 6, 'hidden_dim': 19, 'dropout': 0.014571134308052403, 'epochs': 27, 'optimizer': 'sgd', 'lr': 0.01985496425011042}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training:   0%|          | 0/39 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:20:27,821] Trial 22 pruned. \n",
      "Training: 100%|██████████| 51/51 [02:14<00:00,  2.63s/Epochs]\n",
      "[I 2024-01-13 10:22:47,887] Trial 23 finished with value: 0.8660435676574707 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 4, 'log_batch_size': 5, 'hidden_dim': 31, 'dropout': 0.09873842714359549, 'epochs': 51, 'optimizer': 'sgd', 'lr': 0.00338251317117934}. Best is trial 2 with value: 0.8765243291854858.\n",
      "Training:   8%|▊         | 4/51 [00:14<02:45,  3.52s/Epochs]\n",
      "[I 2024-01-13 10:23:08,408] Trial 24 pruned. \n",
      "Training:  75%|███████▌  | 52/69 [02:13<00:43,  2.57s/Epochs]\n",
      "[I 2024-01-13 10:25:28,433] Trial 25 pruned. \n",
      "Training:  17%|█▋        | 8/47 [00:42<03:29,  5.37s/Epochs]\n",
      "[I 2024-01-13 10:26:17,414] Trial 26 pruned. \n",
      "Training: 100%|██████████| 61/61 [08:09<00:00,  8.02s/Epochs]\n",
      "[I 2024-01-13 10:34:33,168] Trial 27 finished with value: 0.8930232524871826 and parameters: {'num_layers{}': 2, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 26, 'dropout': 0.1547240493884824, 'epochs': 61, 'optimizer': 'adam', 'lr': 0.00030606732410619325}. Best is trial 27 with value: 0.8930232524871826.\n",
      "Training:  20%|██        | 12/59 [01:35<06:12,  7.93s/Epochs]\n",
      "[I 2024-01-13 10:36:14,372] Trial 28 pruned. \n",
      "Training:   0%|          | 0/96 [00:17<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:36:38,417] Trial 29 pruned. \n",
      "Training:   5%|▌         | 4/78 [00:35<11:04,  8.98s/Epochs]\n",
      "[I 2024-01-13 10:37:20,115] Trial 30 pruned. \n",
      "Training:   7%|▋         | 4/56 [00:14<03:10,  3.66s/Epochs]\n",
      "[I 2024-01-13 10:37:40,916] Trial 31 pruned. \n",
      "Training:   8%|▊         | 4/49 [00:13<02:31,  3.37s/Epochs]\n",
      "[I 2024-01-13 10:38:00,662] Trial 32 pruned. \n",
      "Training:  11%|█▏        | 4/35 [00:24<03:10,  6.14s/Epochs]\n",
      "[I 2024-01-13 10:38:31,522] Trial 33 pruned. \n",
      "Training:   0%|          | 0/55 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:38:39,376] Trial 34 pruned. \n",
      "Training:   0%|          | 0/63 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:38:47,243] Trial 35 pruned. \n",
      "Training:   0%|          | 0/69 [00:34<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:39:27,353] Trial 36 pruned. \n",
      "Training:   5%|▍         | 4/81 [01:13<23:34, 18.38s/Epochs]\n",
      "[I 2024-01-13 10:40:46,606] Trial 37 pruned. \n",
      "Training:  22%|██▏       | 4/18 [00:08<00:29,  2.08s/Epochs]\n",
      "[I 2024-01-13 10:41:00,508] Trial 38 pruned. \n",
      "Training:   0%|          | 0/43 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:41:15,531] Trial 39 pruned. \n",
      "Training:   8%|▊         | 4/53 [01:32<18:54, 23.15s/Epochs]\n",
      "[I 2024-01-13 10:42:53,594] Trial 40 pruned. \n",
      "Training:   0%|          | 0/27 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:43:01,755] Trial 41 pruned. \n",
      "Training:   0%|          | 0/16 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:43:09,878] Trial 42 pruned. \n",
      "Training:   0%|          | 0/32 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:43:17,981] Trial 43 pruned. \n",
      "Training:  57%|█████▋    | 4/7 [00:15<00:11,  3.78s/Epochs]\n",
      "[I 2024-01-13 10:43:38,880] Trial 44 pruned. \n",
      "Training:   0%|          | 0/65 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:43:46,915] Trial 45 pruned. \n",
      "Training:   0%|          | 0/23 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:43:56,834] Trial 46 pruned. \n",
      "Training:   4%|▍         | 4/91 [00:21<07:43,  5.33s/Epochs]\n",
      "[I 2024-01-13 10:44:23,974] Trial 47 pruned. \n",
      "Training:   0%|          | 0/37 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:44:33,132] Trial 48 pruned. \n",
      "Training: 100%|██████████| 44/44 [04:48<00:00,  6.55s/Epochs]\n",
      "[I 2024-01-13 10:49:26,928] Trial 49 finished with value: 0.8690292835235596 and parameters: {'num_layers{}': 1, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 40, 'dropout': 0.06994624470404011, 'epochs': 44, 'optimizer': 'sgd', 'lr': 0.00022606767569961536}. Best is trial 27 with value: 0.8930232524871826.\n",
      "Training:   0%|          | 0/46 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:49:40,669] Trial 50 pruned. \n",
      "Training:  10%|▉         | 4/42 [00:34<05:28,  8.65s/Epochs]\n",
      "[I 2024-01-13 10:50:21,092] Trial 51 pruned. \n",
      "Training:   7%|▋         | 4/56 [00:34<07:34,  8.73s/Epochs]\n",
      "[I 2024-01-13 10:51:01,888] Trial 52 pruned. \n",
      "Training:   8%|▊         | 4/50 [00:21<04:05,  5.33s/Epochs]\n",
      "[I 2024-01-13 10:51:29,581] Trial 53 pruned. \n",
      "Training:  38%|███▊      | 12/32 [02:46<04:37, 13.87s/Epochs]\n",
      "[I 2024-01-13 10:54:22,149] Trial 54 pruned. \n",
      "Training:  88%|████████▊ | 52/59 [01:31<00:12,  1.76s/Epochs]\n",
      "[I 2024-01-13 10:55:59,872] Trial 55 pruned. \n",
      "Training:   0%|          | 0/39 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:56:10,728] Trial 56 pruned. \n",
      "Training:   0%|          | 0/25 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:56:26,671] Trial 57 pruned. \n",
      "Training:   0%|          | 0/12 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:56:36,277] Trial 58 pruned. \n",
      "Training:   6%|▌         | 4/68 [00:22<05:58,  5.61s/Epochs]\n",
      "[I 2024-01-13 10:57:04,635] Trial 59 pruned. \n",
      "Training:   5%|▌         | 4/75 [00:08<02:29,  2.10s/Epochs]\n",
      "[I 2024-01-13 10:57:19,206] Trial 60 pruned. \n",
      "Training:   0%|          | 0/34 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:57:27,653] Trial 61 pruned. \n",
      "Training:   0%|          | 0/29 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:57:36,266] Trial 62 pruned. \n",
      "Training:   0%|          | 0/21 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:57:44,708] Trial 63 pruned. \n",
      "Training:   0%|          | 0/47 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:57:54,339] Trial 64 pruned. \n",
      "Training:   0%|          | 0/61 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 10:58:02,506] Trial 65 pruned. \n",
      "Training: 100%|██████████| 90/90 [04:24<00:00,  2.94s/Epochs]\n",
      "[I 2024-01-13 11:02:33,732] Trial 66 finished with value: 0.8802395462989807 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 5, 'hidden_dim': 55, 'dropout': 0.040475674033228895, 'epochs': 90, 'optimizer': 'sgd', 'lr': 0.0256128976309297}. Best is trial 27 with value: 0.8930232524871826.\n",
      "Training:   4%|▍         | 4/93 [00:13<05:03,  3.41s/Epochs]\n",
      "[I 2024-01-13 11:02:53,210] Trial 67 pruned. \n",
      "Training:  27%|██▋       | 24/88 [01:02<02:47,  2.62s/Epochs]\n",
      "[I 2024-01-13 11:04:02,182] Trial 68 pruned. \n",
      "Training: 100%|██████████| 82/82 [11:25<00:00,  8.35s/Epochs]\n",
      "[I 2024-01-13 11:15:33,268] Trial 69 finished with value: 0.4716692268848419 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 59, 'dropout': 0.07805015999160961, 'epochs': 82, 'optimizer': 'adagrad', 'lr': 0.0041811564050157}. Best is trial 27 with value: 0.8930232524871826.\n",
      "Training:   0%|          | 0/96 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:15:44,187] Trial 70 pruned. \n",
      "Training:   0%|          | 0/54 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:15:53,147] Trial 71 pruned. \n",
      "Training:   0%|          | 0/99 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:16:01,199] Trial 72 pruned. \n",
      "Training:   0%|          | 0/72 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:16:09,952] Trial 73 pruned. \n",
      "Training:   0%|          | 0/90 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:16:18,390] Trial 74 pruned. \n",
      "Training:   0%|          | 0/83 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:16:34,942] Trial 75 pruned. \n",
      "Training:   0%|          | 0/45 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:16:43,294] Trial 76 pruned. \n",
      "Training:  28%|██▊       | 8/29 [01:51<04:53, 13.99s/Epochs]\n",
      "[I 2024-01-13 11:18:41,127] Trial 77 pruned. \n",
      "Training:   0%|          | 0/36 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:18:50,675] Trial 78 pruned. \n",
      "Training:  78%|███████▊  | 32/41 [02:38<00:44,  4.94s/Epochs]\n",
      "[I 2024-01-13 11:21:34,817] Trial 79 pruned. \n",
      "Training:   0%|          | 0/52 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:21:43,164] Trial 80 pruned. \n",
      "Training:   0%|          | 0/14 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:21:51,967] Trial 81 pruned. \n",
      "Training:   0%|          | 0/6 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:22:00,115] Trial 82 pruned. \n",
      "Training:   0%|          | 0/10 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:22:08,476] Trial 83 pruned. \n",
      "Training:   0%|          | 0/49 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:22:25,250] Trial 84 pruned. \n",
      "Training:  24%|██▎       | 4/17 [00:12<00:39,  3.08s/Epochs]\n",
      "[I 2024-01-13 11:22:43,555] Trial 85 pruned. \n",
      "Training:  10%|█         | 8/79 [00:14<02:12,  1.86s/Epochs]\n",
      "[I 2024-01-13 11:23:04,317] Trial 86 pruned. \n",
      "Training:   0%|          | 0/58 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:23:14,748] Trial 87 pruned. \n",
      "Training:   0%|          | 0/25 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:23:22,429] Trial 88 pruned. \n",
      "Training:  20%|██        | 4/20 [00:36<02:25,  9.10s/Epochs]\n",
      "[I 2024-01-13 11:24:04,320] Trial 89 pruned. \n",
      "Training:   0%|          | 0/63 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:24:12,833] Trial 90 pruned. \n",
      "Training:   0%|          | 0/43 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:24:23,525] Trial 91 pruned. \n",
      "Training:  11%|█         | 4/38 [00:12<01:44,  3.07s/Epochs]\n",
      "[I 2024-01-13 11:24:41,862] Trial 92 pruned. \n",
      "Training:   8%|▊         | 4/52 [00:35<07:01,  8.79s/Epochs]\n",
      "[I 2024-01-13 11:25:22,857] Trial 93 pruned. \n",
      "Training:   0%|          | 0/57 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:25:33,893] Trial 94 pruned. \n",
      "Training:   0%|          | 0/45 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:25:41,631] Trial 95 pruned. \n",
      "Training:   0%|          | 0/33 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:25:50,458] Trial 96 pruned. \n",
      "Training:  24%|██▍       | 12/50 [01:26<04:33,  7.21s/Epochs]\n",
      "[I 2024-01-13 11:27:22,731] Trial 97 pruned. \n",
      "Training:   0%|          | 0/10 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:27:32,396] Trial 98 pruned. \n",
      "Training:   0%|          | 0/48 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:27:40,466] Trial 99 pruned. \n",
      "Training:   7%|▋         | 4/54 [00:41<08:41, 10.44s/Epochs]\n",
      "[I 2024-01-13 11:28:28,015] Trial 100 pruned. \n",
      "Training:   0%|          | 0/44 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:28:37,339] Trial 101 pruned. \n",
      "Training:   0%|          | 0/40 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:28:46,212] Trial 102 pruned. \n",
      "Training:   0%|          | 0/60 [00:37<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:29:29,758] Trial 103 pruned. \n",
      "Training:   0%|          | 0/47 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:29:40,915] Trial 104 pruned. \n",
      "Training:   0%|          | 0/85 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:29:50,511] Trial 105 pruned. \n",
      "Training:   0%|          | 0/64 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:29:59,540] Trial 106 pruned. \n",
      "Training:   0%|          | 0/29 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:30:08,056] Trial 107 pruned. \n",
      "Training:   0%|          | 0/99 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:30:19,216] Trial 108 pruned. \n",
      "Training:   0%|          | 0/94 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:30:28,204] Trial 109 pruned. \n",
      "Training:   0%|          | 0/55 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:30:36,460] Trial 110 pruned. \n",
      "Training:   0%|          | 0/68 [00:32<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:31:14,133] Trial 111 pruned. \n",
      "Training:   0%|          | 0/62 [00:16<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:31:36,290] Trial 112 pruned. \n",
      "Training:   0%|          | 0/66 [00:16<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:31:58,462] Trial 113 pruned. \n",
      "Training:   0%|          | 0/52 [00:15<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:32:19,647] Trial 114 pruned. \n",
      "Training:   8%|▊         | 4/50 [00:23<04:35,  5.98s/Epochs]\n",
      "[I 2024-01-13 11:32:49,394] Trial 115 pruned. \n",
      "Training:   0%|          | 0/57 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:32:57,160] Trial 116 pruned. \n",
      "Training:   0%|          | 0/88 [00:16<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:33:19,909] Trial 117 pruned. \n",
      "Training:   0%|          | 0/71 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:33:29,272] Trial 118 pruned. \n",
      "Training:   0%|          | 0/36 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:33:37,671] Trial 119 pruned. \n",
      "Training:   0%|          | 0/19 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:33:47,082] Trial 120 pruned. \n",
      "Training:   0%|          | 0/91 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 11:34:02,404] Trial 121 pruned. \n",
      "Training: 100%|██████████| 88/88 [12:31<00:00,  8.54s/Epochs]\n",
      "[I 2024-01-13 11:46:39,583] Trial 122 finished with value: 0.8956385850906372 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 60, 'dropout': 0.040095102711993236, 'epochs': 88, 'optimizer': 'adagrad', 'lr': 0.0035231987529062113}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 88/88 [12:14<00:00,  8.35s/Epochs]\n",
      "[I 2024-01-13 11:59:00,889] Trial 123 finished with value: 0.8684210181236267 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 61, 'dropout': 0.33422001400772916, 'epochs': 88, 'optimizer': 'adagrad', 'lr': 0.00818300891373942}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   5%|▍         | 4/88 [00:43<15:18, 10.93s/Epochs]\n",
      "[I 2024-01-13 11:59:50,681] Trial 124 pruned. \n",
      "Training:  80%|████████  | 60/75 [08:22<02:05,  8.37s/Epochs]\n",
      "[I 2024-01-13 12:08:18,533] Trial 125 pruned. \n",
      "Training:  62%|██████▎   | 60/96 [08:25<05:03,  8.43s/Epochs]\n",
      "[I 2024-01-13 12:16:50,139] Trial 126 pruned. \n",
      "Training:   0%|          | 0/90 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:17:05,765] Trial 127 pruned. \n",
      "Training:   5%|▍         | 4/86 [00:41<14:17, 10.46s/Epochs]\n",
      "[I 2024-01-13 12:17:53,610] Trial 128 pruned. \n",
      "Training:   0%|          | 0/23 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:18:10,520] Trial 129 pruned. \n",
      "Training:   0%|          | 0/81 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:18:24,734] Trial 130 pruned. \n",
      "Training:   0%|          | 0/92 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:18:32,624] Trial 131 pruned. \n",
      "Training:   0%|          | 0/14 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:18:43,964] Trial 132 pruned. \n",
      "Training:   5%|▍         | 4/84 [01:05<21:59, 16.49s/Epochs]\n",
      "[I 2024-01-13 12:19:55,595] Trial 133 pruned. \n",
      "Training:   0%|          | 0/42 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:20:04,178] Trial 134 pruned. \n",
      "Training:   0%|          | 0/59 [00:12<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:20:22,632] Trial 135 pruned. \n",
      "Training:   0%|          | 0/55 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:20:32,218] Trial 136 pruned. \n",
      "Training:   0%|          | 0/53 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:20:40,371] Trial 137 pruned. \n",
      "Training:   5%|▍         | 4/88 [00:25<08:48,  6.29s/Epochs]\n",
      "[I 2024-01-13 12:21:11,273] Trial 138 pruned. \n",
      "Training:  26%|██▌       | 8/31 [03:47<10:54, 28.47s/Epochs]\n",
      "[I 2024-01-13 12:25:05,092] Trial 139 pruned. \n",
      "Training:   0%|          | 0/48 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:25:20,247] Trial 140 pruned. \n",
      "Training:   5%|▍         | 4/82 [00:44<14:23, 11.07s/Epochs]\n",
      "[I 2024-01-13 12:26:10,558] Trial 141 pruned. \n",
      "Training:   0%|          | 0/93 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:26:26,630] Trial 142 pruned. \n",
      "Training:   0%|          | 0/89 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:26:43,003] Trial 143 pruned. \n",
      "Training:   4%|▍         | 4/98 [00:47<18:47, 12.00s/Epochs]\n",
      "[I 2024-01-13 12:27:36,978] Trial 144 pruned. \n",
      "Training:  14%|█▍        | 12/86 [01:47<11:00,  8.92s/Epochs]\n",
      "[I 2024-01-13 12:29:30,331] Trial 145 pruned. \n",
      "Training:   0%|          | 0/94 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:29:38,741] Trial 146 pruned. \n",
      "Training:   0%|          | 0/51 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:29:48,068] Trial 147 pruned. \n",
      "Training:  13%|█▎        | 8/60 [01:21<08:48, 10.17s/Epochs]\n",
      "[I 2024-01-13 12:31:15,456] Trial 148 pruned. \n",
      "Training:   5%|▌         | 4/79 [00:08<02:48,  2.24s/Epochs]\n",
      "[I 2024-01-13 12:31:30,905] Trial 149 pruned. \n",
      "Training:   0%|          | 0/46 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:31:44,049] Trial 150 pruned. \n",
      "Training:   0%|          | 0/86 [00:31<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:32:21,452] Trial 151 pruned. \n",
      "Training:   0%|          | 0/83 [00:16<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:32:44,742] Trial 152 pruned. \n",
      "Training:   4%|▍         | 4/91 [02:19<50:42, 34.97s/Epochs]\n",
      "[I 2024-01-13 12:35:10,805] Trial 153 pruned. \n",
      "Training: 100%|██████████| 5/5 [01:12<00:00, 14.42s/Epochs]\n",
      "[I 2024-01-13 12:36:28,885] Trial 154 finished with value: 0.8712120652198792 and parameters: {'num_layers{}': 2, 'num_mlp_layers{}': 3, 'log_batch_size': 2, 'hidden_dim': 45, 'dropout': 0.12191418934928498, 'epochs': 5, 'optimizer': 'sgd', 'lr': 0.0033359230411065272}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:  27%|██▋       | 4/15 [01:12<03:20, 18.20s/Epochs]\n",
      "[I 2024-01-13 12:37:47,513] Trial 155 pruned. \n",
      "Training: 100%|██████████| 8/8 [02:02<00:00, 15.32s/Epochs]\n",
      "[I 2024-01-13 12:39:56,350] Trial 156 finished with value: 0.8590908646583557 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 44, 'dropout': 0.12694527573571723, 'epochs': 8, 'optimizer': 'sgd', 'lr': 0.0037253865537508375}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/5 [00:15<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:40:17,621] Trial 157 pruned. \n",
      "Training:   0%|          | 0/7 [00:17<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:40:41,133] Trial 158 pruned. \n",
      "Training: 100%|██████████| 8/8 [02:13<00:00, 16.71s/Epochs]\n",
      "[I 2024-01-13 12:43:01,325] Trial 159 finished with value: 0.8686708807945251 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 43, 'dropout': 0.12429676075386438, 'epochs': 8, 'optimizer': 'sgd', 'lr': 0.0027446229551055853}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 10/10 [02:53<00:00, 17.31s/Epochs]\n",
      "[I 2024-01-13 12:46:00,597] Trial 160 finished with value: 0.862500011920929 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 43, 'dropout': 0.14778800429136119, 'epochs': 10, 'optimizer': 'sgd', 'lr': 0.002639706116265875}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 9/9 [02:35<00:00, 17.26s/Epochs]\n",
      "[I 2024-01-13 12:48:41,667] Trial 161 finished with value: 0.8266870975494385 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 44, 'dropout': 0.16241870102263006, 'epochs': 9, 'optimizer': 'sgd', 'lr': 0.00259387903587691}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/9 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:49:07,954] Trial 162 pruned. \n",
      "Training:   0%|          | 0/12 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:49:33,952] Trial 163 pruned. \n",
      "Training: 100%|██████████| 12/12 [03:28<00:00, 17.34s/Epochs]\n",
      "[I 2024-01-13 12:53:07,845] Trial 164 finished with value: 0.8508371710777283 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 44, 'dropout': 0.16600440394316346, 'epochs': 12, 'optimizer': 'sgd', 'lr': 0.00274571040414861}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/11 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:53:33,946] Trial 165 pruned. \n",
      "Training: 100%|██████████| 7/7 [02:01<00:00, 17.42s/Epochs]\n",
      "[I 2024-01-13 12:55:41,836] Trial 166 finished with value: 0.8524096012115479 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 43, 'dropout': 0.12605370042375347, 'epochs': 7, 'optimizer': 'sgd', 'lr': 0.0034049060925365553}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/5 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:56:07,959] Trial 167 pruned. \n",
      "Training:  50%|█████     | 4/8 [01:32<01:32, 23.24s/Epochs]\n",
      "[I 2024-01-13 12:57:46,925] Trial 168 pruned. \n",
      "Training:   0%|          | 0/13 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:58:13,402] Trial 169 pruned. \n",
      "Training:   0%|          | 0/8 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:58:38,786] Trial 170 pruned. \n",
      "Training:   0%|          | 0/7 [00:28<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:59:13,022] Trial 171 pruned. \n",
      "Training:   0%|          | 0/11 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 12:59:41,297] Trial 172 pruned. \n",
      "Training: 100%|██████████| 5/5 [01:27<00:00, 17.50s/Epochs]\n",
      "[I 2024-01-13 13:01:14,821] Trial 173 finished with value: 0.863636314868927 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 44, 'dropout': 0.19248461053501864, 'epochs': 5, 'optimizer': 'sgd', 'lr': 0.0021409253002063152}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/17 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:01:40,335] Trial 174 pruned. \n",
      "Training:   0%|          | 0/5 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:02:06,648] Trial 175 pruned. \n",
      "Training:   0%|          | 0/10 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:02:31,288] Trial 176 pruned. \n",
      "Training:   0%|          | 0/7 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:02:56,389] Trial 177 pruned. \n",
      "Training:   0%|          | 0/13 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:03:22,131] Trial 178 pruned. \n",
      "Training:   0%|          | 0/9 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:03:47,795] Trial 179 pruned. \n",
      "Training:   0%|          | 0/16 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:04:14,344] Trial 180 pruned. \n",
      "Training:   0%|          | 0/6 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:04:39,068] Trial 181 pruned. \n",
      "Training:   0%|          | 0/11 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:05:05,272] Trial 182 pruned. \n",
      "Training: 100%|██████████| 5/5 [01:29<00:00, 17.81s/Epochs]\n",
      "[I 2024-01-13 13:06:40,672] Trial 183 finished with value: 0.8655332326889038 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 46, 'dropout': 0.13126025498514243, 'epochs': 5, 'optimizer': 'sgd', 'lr': 0.0024651242772255654}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/5 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:07:06,382] Trial 184 pruned. \n",
      "Training: 100%|██████████| 8/8 [02:13<00:00, 16.63s/Epochs]\n",
      "[I 2024-01-13 13:09:25,101] Trial 185 finished with value: 0.8623853325843811 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 46, 'dropout': 0.12856838758330444, 'epochs': 8, 'optimizer': 'sgd', 'lr': 0.0023860820983737175}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:  50%|█████     | 4/8 [01:28<01:28, 22.10s/Epochs]\n",
      "[I 2024-01-13 13:10:59,558] Trial 186 pruned. \n",
      "Training:   0%|          | 0/7 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:11:25,516] Trial 187 pruned. \n",
      "Training:   0%|          | 0/5 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:11:51,420] Trial 188 pruned. \n",
      "Training:  44%|████▍     | 4/9 [01:29<01:51, 22.39s/Epochs]\n",
      "[I 2024-01-13 13:13:26,788] Trial 189 pruned. \n",
      "Training:   0%|          | 0/12 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:13:52,792] Trial 190 pruned. \n",
      "Training:   0%|          | 0/10 [00:21<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:14:20,425] Trial 191 pruned. \n",
      "Training:  18%|█▊        | 4/22 [01:29<06:41, 22.29s/Epochs]\n",
      "[I 2024-01-13 13:15:55,603] Trial 192 pruned. \n",
      "Training:   0%|          | 0/14 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:16:21,886] Trial 193 pruned. \n",
      "Training:   0%|          | 0/8 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:16:30,112] Trial 194 pruned. \n",
      "Training:   0%|          | 0/7 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:16:56,137] Trial 195 pruned. \n",
      "Training:   0%|          | 0/5 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:17:22,281] Trial 196 pruned. \n",
      "Training:   0%|          | 0/11 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:17:31,119] Trial 197 pruned. \n",
      "Training: 100%|██████████| 9/9 [02:40<00:00, 17.84s/Epochs]\n",
      "[I 2024-01-13 13:20:17,686] Trial 198 finished with value: 0.8773584365844727 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 2, 'hidden_dim': 45, 'dropout': 0.13033255554112635, 'epochs': 9, 'optimizer': 'sgd', 'lr': 0.0046077152788732536}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/9 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:20:44,649] Trial 199 pruned. \n",
      "Training:  57%|█████▋    | 4/7 [01:30<01:07, 22.65s/Epochs]\n",
      "[I 2024-01-13 13:22:22,305] Trial 200 pruned. \n",
      "Training:   0%|          | 0/13 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:22:48,609] Trial 201 pruned. \n",
      "Training:  16%|█▌        | 4/25 [01:32<08:04, 23.05s/Epochs]\n",
      "[I 2024-01-13 13:24:27,319] Trial 202 pruned. \n",
      "Training:   0%|          | 0/9 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:24:54,238] Trial 203 pruned. \n",
      "Training:   0%|          | 0/11 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:25:03,037] Trial 204 pruned. \n",
      "Training:  80%|████████  | 4/5 [01:28<00:22, 22.15s/Epochs]\n",
      "[I 2024-01-13 13:26:37,497] Trial 205 pruned. \n",
      "Training:  21%|██        | 4/19 [01:20<05:02, 20.13s/Epochs]\n",
      "[I 2024-01-13 13:28:04,098] Trial 206 pruned. \n",
      "Training:   0%|          | 0/15 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:28:12,678] Trial 207 pruned. \n",
      "Training:   0%|          | 0/7 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:28:38,442] Trial 208 pruned. \n",
      "Training:   0%|          | 0/10 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:28:55,714] Trial 209 pruned. \n",
      "Training:   0%|          | 0/12 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:29:21,621] Trial 210 pruned. \n",
      "Training:   0%|          | 0/40 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:29:30,903] Trial 211 pruned. \n",
      "Training:   0%|          | 0/37 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:29:45,472] Trial 212 pruned. \n",
      "Training:  57%|█████▋    | 4/7 [00:08<00:06,  2.15s/Epochs]\n",
      "[I 2024-01-13 13:30:00,451] Trial 213 pruned. \n",
      "Training:   0%|          | 0/5 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:30:24,737] Trial 214 pruned. \n",
      "Training:   0%|          | 0/34 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:30:37,890] Trial 215 pruned. \n",
      "Training:  13%|█▎        | 4/31 [01:20<09:00, 20.01s/Epochs]\n",
      "[I 2024-01-13 13:32:03,849] Trial 216 pruned. \n",
      "Training:   0%|          | 0/89 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:32:12,552] Trial 217 pruned. \n",
      "Training:   0%|          | 0/27 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:32:29,119] Trial 218 pruned. \n",
      "Training: 100%|██████████| 9/9 [02:00<00:00, 13.44s/Epochs]\n",
      "[I 2024-01-13 13:34:36,206] Trial 219 finished with value: 0.8639876246452332 and parameters: {'num_layers{}': 1, 'num_mlp_layers{}': 2, 'log_batch_size': 2, 'hidden_dim': 43, 'dropout': 0.1205524134346698, 'epochs': 9, 'optimizer': 'sgd', 'lr': 0.0002829717012367279}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/10 [00:14<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:34:57,207] Trial 220 pruned. \n",
      "Training:  50%|█████     | 4/8 [01:06<01:06, 16.66s/Epochs]\n",
      "[I 2024-01-13 13:36:09,619] Trial 221 pruned. \n",
      "Training:   0%|          | 0/44 [00:14<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:36:30,688] Trial 222 pruned. \n",
      "Training:  57%|█████▋    | 4/7 [01:06<00:49, 16.56s/Epochs]\n",
      "[I 2024-01-13 13:37:42,986] Trial 223 pruned. \n",
      "Training:   0%|          | 0/9 [00:15<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:38:04,390] Trial 224 pruned. \n",
      "Training:   0%|          | 0/12 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:38:14,099] Trial 225 pruned. \n",
      "Training:   4%|▍         | 4/93 [01:05<24:11, 16.31s/Epochs]\n",
      "[I 2024-01-13 13:39:25,663] Trial 226 pruned. \n",
      "Training:   0%|          | 0/5 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:39:51,201] Trial 227 pruned. \n",
      "Training:   0%|          | 0/14 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:39:59,500] Trial 228 pruned. \n",
      "Training:   0%|          | 0/91 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:40:16,949] Trial 229 pruned. \n",
      "Training:  44%|████▍     | 4/9 [01:05<01:22, 16.50s/Epochs]\n",
      "[I 2024-01-13 13:41:28,926] Trial 230 pruned. \n",
      "Training:   0%|          | 0/7 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:41:54,785] Trial 231 pruned. \n",
      "Training:   0%|          | 0/10 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:42:19,765] Trial 232 pruned. \n",
      "Training:   0%|          | 0/8 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:42:46,102] Trial 233 pruned. \n",
      "Training:   0%|          | 0/11 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:43:11,211] Trial 234 pruned. \n",
      "Training:  67%|██████▋   | 4/6 [01:30<00:45, 22.56s/Epochs]\n",
      "[I 2024-01-13 13:44:47,611] Trial 235 pruned. \n",
      "Training:   0%|          | 0/9 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:44:57,487] Trial 236 pruned. \n",
      "Training:   0%|          | 0/56 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:45:23,612] Trial 237 pruned. \n",
      "Training:   0%|          | 0/95 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:45:32,018] Trial 238 pruned. \n",
      "Training:   0%|          | 0/87 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:45:44,118] Trial 239 pruned. \n",
      "Training:   0%|          | 0/13 [00:16<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:46:07,101] Trial 240 pruned. \n",
      "Training:   0%|          | 0/53 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:46:16,440] Trial 241 pruned. \n",
      "Training:   0%|          | 0/46 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:46:26,209] Trial 242 pruned. \n",
      "Training:   0%|          | 0/51 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:46:35,815] Trial 243 pruned. \n",
      "Training:   0%|          | 0/49 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:46:45,427] Trial 244 pruned. \n",
      "Training:   0%|          | 0/48 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:47:01,218] Trial 245 pruned. \n",
      "Training:   0%|          | 0/5 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:47:28,140] Trial 246 pruned. \n",
      "Training:   0%|          | 0/7 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:47:37,672] Trial 247 pruned. \n",
      "Training:   0%|          | 0/41 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:48:02,992] Trial 248 pruned. \n",
      "Training:   0%|          | 0/9 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:48:11,381] Trial 249 pruned. \n",
      "Training:   0%|          | 0/54 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:48:36,541] Trial 250 pruned. \n",
      "Training:   0%|          | 0/38 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:48:52,618] Trial 251 pruned. \n",
      "Training:   5%|▌         | 4/76 [01:13<22:01, 18.35s/Epochs]\n",
      "[I 2024-01-13 13:50:12,198] Trial 252 pruned. \n",
      "Training:   0%|          | 0/58 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:50:37,844] Trial 253 pruned. \n",
      "Training:  33%|███▎      | 4/12 [00:28<00:56,  7.02s/Epochs]\n",
      "[I 2024-01-13 13:51:12,412] Trial 254 pruned. \n",
      "Training:   0%|          | 0/90 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:51:20,377] Trial 255 pruned. \n",
      "Training:   0%|          | 0/17 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:51:29,701] Trial 256 pruned. \n",
      "Training:   0%|          | 0/7 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:51:44,874] Trial 257 pruned. \n",
      "Training:   0%|          | 0/10 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:52:12,068] Trial 258 pruned. \n",
      "Training:  14%|█▍        | 4/28 [01:12<07:17, 18.21s/Epochs]\n",
      "[I 2024-01-13 13:53:30,954] Trial 259 pruned. \n",
      "Training:   0%|          | 0/51 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:53:40,236] Trial 260 pruned. \n",
      "Training:   0%|          | 0/5 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:53:48,807] Trial 261 pruned. \n",
      "Training:   6%|▌         | 4/66 [01:14<19:09, 18.54s/Epochs]\n",
      "[I 2024-01-13 13:55:08,804] Trial 262 pruned. \n",
      "Training:   0%|          | 0/43 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:55:34,922] Trial 263 pruned. \n",
      "Training:   0%|          | 0/9 [00:13<?, ?Epochs/s]\n",
      "[I 2024-01-13 13:55:53,840] Trial 264 pruned. \n",
      "Training:  85%|████████▍ | 60/71 [33:19<06:06, 33.33s/Epochs]\n",
      "[I 2024-01-13 14:29:19,708] Trial 265 pruned. \n",
      "Training:   0%|          | 0/11 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:29:27,732] Trial 266 pruned. \n",
      "Training:   0%|          | 0/7 [00:14<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:29:48,408] Trial 267 pruned. \n",
      "Training:   4%|▍         | 4/92 [01:18<28:40, 19.55s/Epochs]\n",
      "[I 2024-01-13 14:31:12,427] Trial 268 pruned. \n",
      "Training: 100%|██████████| 14/14 [01:06<00:00,  4.74s/Epochs]\n",
      "[I 2024-01-13 14:32:24,675] Trial 269 finished with value: 0.8734755516052246 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 4, 'hidden_dim': 45, 'dropout': 0.02959900848596754, 'epochs': 14, 'optimizer': 'sgd', 'lr': 0.0027537266946520964}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/12 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:32:36,465] Trial 270 pruned. \n",
      "Training:   0%|          | 0/16 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:32:48,491] Trial 271 pruned. \n",
      "Training:   0%|          | 0/14 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:33:00,740] Trial 272 pruned. \n",
      "Training:  50%|█████     | 4/8 [00:44<00:44, 11.04s/Epochs]\n",
      "[I 2024-01-13 14:33:51,081] Trial 273 pruned. \n",
      "Training:   0%|          | 0/9 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:34:15,550] Trial 274 pruned. \n",
      "Training:   0%|          | 0/11 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:34:36,793] Trial 275 pruned. \n",
      "Training:  67%|██████▋   | 4/6 [01:23<00:41, 20.91s/Epochs]\n",
      "[I 2024-01-13 14:36:13,179] Trial 276 pruned. \n",
      "Training:   4%|▍         | 4/97 [01:23<32:24, 20.91s/Epochs]\n",
      "[I 2024-01-13 14:37:42,992] Trial 277 pruned. \n",
      "Training:   0%|          | 0/13 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:37:59,447] Trial 278 pruned. \n",
      "Training:   0%|          | 0/5 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:38:07,257] Trial 279 pruned. \n",
      "Training:   0%|          | 0/24 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:38:33,699] Trial 280 pruned. \n",
      "Training:   0%|          | 0/21 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:38:49,685] Trial 281 pruned. \n",
      "Training:   0%|          | 0/35 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:39:14,451] Trial 282 pruned. \n",
      "Training:   0%|          | 0/8 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:39:22,213] Trial 283 pruned. \n",
      "Training:   0%|          | 0/62 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:39:33,295] Trial 284 pruned. \n",
      "Training:   0%|          | 0/10 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:39:57,745] Trial 285 pruned. \n",
      "Training:  27%|██▋       | 4/15 [01:23<03:50, 20.99s/Epochs]\n",
      "[I 2024-01-13 14:41:27,708] Trial 286 pruned. \n",
      "Training:   0%|          | 0/7 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:41:35,322] Trial 287 pruned. \n",
      "Training:  40%|████      | 4/10 [01:24<02:06, 21.14s/Epochs]\n",
      "[I 2024-01-13 14:43:05,968] Trial 288 pruned. \n",
      "Training:   0%|          | 0/87 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:43:21,534] Trial 289 pruned. \n",
      "Training:   0%|          | 0/89 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:43:46,654] Trial 290 pruned. \n",
      "Training:   0%|          | 0/13 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:43:54,757] Trial 291 pruned. \n",
      "Training:  22%|██▏       | 4/18 [01:11<04:08, 17.78s/Epochs]\n",
      "[I 2024-01-13 14:45:11,566] Trial 292 pruned. \n",
      "Training:   0%|          | 0/5 [00:07<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:45:25,217] Trial 293 pruned. \n",
      "Training:   0%|          | 0/30 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:45:49,867] Trial 294 pruned. \n",
      "Training:   0%|          | 0/11 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:46:01,157] Trial 295 pruned. \n",
      "Training:  50%|█████     | 4/8 [01:06<01:06, 16.71s/Epochs]\n",
      "[I 2024-01-13 14:47:13,390] Trial 296 pruned. \n",
      "Training:   0%|          | 0/7 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:47:37,413] Trial 297 pruned. \n",
      "Training:   0%|          | 0/84 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:47:53,726] Trial 298 pruned. \n",
      "Training:   0%|          | 0/10 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 14:48:01,708] Trial 299 pruned. \n",
      "Training:  12%|█▏        | 4/33 [01:10<08:30, 17.60s/Epochs]\n",
      "[I 2024-01-13 14:49:17,541] Trial 300 pruned. \n",
      "Training:  15%|█▌        | 4/26 [01:25<07:49, 21.36s/Epochs]\n",
      "[I 2024-01-13 14:50:48,802] Trial 301 pruned. \n",
      "Training: 100%|██████████| 93/93 [26:34<00:00, 17.14s/Epochs]\n",
      "[I 2024-01-13 15:17:28,633] Trial 302 finished with value: 0.8871473073959351 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 2, 'hidden_dim': 45, 'dropout': 0.02559939945828732, 'epochs': 93, 'optimizer': 'sgd', 'lr': 0.0018799506346524014}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/92 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:17:38,747] Trial 303 pruned. \n",
      "Training:   0%|          | 0/90 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:17:46,941] Trial 304 pruned. \n",
      "Training:   4%|▍         | 4/94 [00:45<17:03, 11.37s/Epochs]\n",
      "[I 2024-01-13 15:18:38,389] Trial 305 pruned. \n",
      "Training:   0%|          | 0/39 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:19:05,844] Trial 306 pruned. \n",
      "Training:   0%|          | 0/96 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:19:32,940] Trial 307 pruned. \n",
      "Training:   0%|          | 0/91 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:19:42,532] Trial 308 pruned. \n",
      "Training:   0%|          | 0/93 [00:15<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:20:04,813] Trial 309 pruned. \n",
      "Training:   0%|          | 0/45 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:20:13,427] Trial 310 pruned. \n",
      "Training:   0%|          | 0/5 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:20:30,179] Trial 311 pruned. \n",
      "Training:   0%|          | 0/95 [00:20<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:20:57,723] Trial 312 pruned. \n",
      "Training:   0%|          | 0/57 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:21:10,620] Trial 313 pruned. \n",
      "Training:   0%|          | 0/87 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:21:20,868] Trial 314 pruned. \n",
      "Training:  27%|██▋       | 4/15 [01:15<03:27, 18.83s/Epochs]\n",
      "[I 2024-01-13 15:22:43,143] Trial 315 pruned. \n",
      "Training:   0%|          | 0/7 [00:34<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:23:24,457] Trial 316 pruned. \n",
      "Training:   0%|          | 0/89 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:23:33,030] Trial 317 pruned. \n",
      "Training:  31%|███       | 4/13 [01:27<03:17, 21.98s/Epochs]\n",
      "[I 2024-01-13 15:25:07,208] Trial 318 pruned. \n",
      "Training:   0%|          | 0/73 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 15:25:22,468] Trial 319 pruned. \n",
      "Training:   7%|▋         | 4/60 [01:08<16:00, 17.15s/Epochs]\n",
      "[I 2024-01-13 15:26:36,986] Trial 320 pruned. \n",
      "Training: 100%|██████████| 47/47 [07:07<00:00,  9.10s/Epochs]\n",
      "[I 2024-01-13 15:33:50,628] Trial 321 finished with value: 0.8622848391532898 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 43, 'dropout': 0.0017875691309763037, 'epochs': 47, 'optimizer': 'sgd', 'lr': 0.004169454661993556}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   8%|▊         | 4/50 [00:44<08:34, 11.19s/Epochs]\n",
      "[I 2024-01-13 15:34:41,319] Trial 322 pruned. \n",
      "Training: 100%|██████████| 48/48 [06:57<00:00,  8.69s/Epochs]\n",
      "[I 2024-01-13 15:41:44,170] Trial 323 finished with value: 0.8052959442138672 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 3, 'hidden_dim': 43, 'dropout': 0.011362228378569914, 'epochs': 48, 'optimizer': 'sgd', 'lr': 0.004965978955321045}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 99/99 [14:29<00:00,  8.79s/Epochs]\n",
      "[I 2024-01-13 15:56:19,968] Trial 324 finished with value: 0.8746223449707031 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 44, 'dropout': 0.004784439299821109, 'epochs': 99, 'optimizer': 'sgd', 'lr': 0.003738670748059803}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 96/96 [13:57<00:00,  8.72s/Epochs]\n",
      "[I 2024-01-13 16:10:23,145] Trial 325 finished with value: 0.852986216545105 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 44, 'dropout': 0.0009480833393182358, 'epochs': 96, 'optimizer': 'sgd', 'lr': 0.003647993147006785}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 99/99 [14:46<00:00,  8.96s/Epochs]\n",
      "[I 2024-01-13 16:25:16,089] Trial 326 finished with value: 0.8348624110221863 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 51, 'dropout': 0.010216982254388288, 'epochs': 99, 'optimizer': 'sgd', 'lr': 0.004084911297441301}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training: 100%|██████████| 47/47 [07:14<00:00,  9.24s/Epochs]\n",
      "[I 2024-01-13 16:32:36,732] Trial 327 finished with value: 0.8669725060462952 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 44, 'dropout': 0.002595564052796746, 'epochs': 47, 'optimizer': 'sgd', 'lr': 0.0036180357119602446}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/100 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 16:32:54,378] Trial 328 pruned. \n",
      "Training:   0%|          | 0/98 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 16:33:12,033] Trial 329 pruned. \n",
      "Training:   0%|          | 0/46 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 16:33:28,841] Trial 330 pruned. \n",
      "Training: 100%|██████████| 97/97 [14:53<00:00,  9.22s/Epochs]\n",
      "[I 2024-01-13 16:48:29,834] Trial 331 finished with value: 0.851739764213562 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 47, 'dropout': 0.0026281744653848123, 'epochs': 97, 'optimizer': 'sgd', 'lr': 0.0032354655690876623}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/100 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 16:48:47,251] Trial 332 pruned. \n",
      "Training: 100%|██████████| 97/97 [14:49<00:00,  9.17s/Epochs]\n",
      "[I 2024-01-13 17:03:43,908] Trial 333 finished with value: 0.8520801663398743 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 49, 'dropout': 0.0013299578979801493, 'epochs': 97, 'optimizer': 'adagrad', 'lr': 0.004329006460061675}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/48 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:03:59,861] Trial 334 pruned. \n",
      "Training:   4%|▍         | 4/95 [00:44<16:50, 11.11s/Epochs]\n",
      "[I 2024-01-13 17:04:50,230] Trial 335 pruned. \n",
      "Training:   0%|          | 0/94 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:05:07,115] Trial 336 pruned. \n",
      "Training: 100%|██████████| 53/53 [07:40<00:00,  8.69s/Epochs]\n",
      "[I 2024-01-13 17:12:53,693] Trial 337 finished with value: 0.884437620639801 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 44, 'dropout': 0.010094976270954015, 'epochs': 53, 'optimizer': 'sgd', 'lr': 0.002245090167301033}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/47 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:13:09,494] Trial 338 pruned. \n",
      "Training:   0%|          | 0/55 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:13:26,017] Trial 339 pruned. \n",
      "Training: 100%|██████████| 49/49 [07:19<00:00,  8.96s/Epochs]\n",
      "[I 2024-01-13 17:20:50,972] Trial 340 finished with value: 0.8890625238418579 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 42, 'dropout': 0.08982925307623943, 'epochs': 49, 'optimizer': 'sgd', 'lr': 0.002262559530466488}. Best is trial 122 with value: 0.8956385850906372.\n",
      "Training:   0%|          | 0/53 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:21:07,692] Trial 341 pruned. \n",
      "Training:   8%|▊         | 4/52 [00:47<09:32, 11.92s/Epochs]\n",
      "[I 2024-01-13 17:22:01,454] Trial 342 pruned. \n",
      "Training:   0%|          | 0/52 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:22:18,544] Trial 343 pruned. \n",
      "Training:   0%|          | 0/49 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:22:35,093] Trial 344 pruned. \n",
      "Training:   0%|          | 0/50 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:22:52,347] Trial 345 pruned. \n",
      "Training:   0%|          | 0/50 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:23:08,838] Trial 346 pruned. \n",
      "Training:   0%|          | 0/45 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:23:25,442] Trial 347 pruned. \n",
      "Training:   0%|          | 0/47 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:23:41,907] Trial 348 pruned. \n",
      "Training:   0%|          | 0/55 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:23:58,001] Trial 349 pruned. \n",
      "Training:   0%|          | 0/52 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:24:14,762] Trial 350 pruned. \n",
      "Training:   0%|          | 0/42 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:24:30,713] Trial 351 pruned. \n",
      "Training: 100%|██████████| 43/43 [06:15<00:00,  8.74s/Epochs]\n",
      "[I 2024-01-13 17:30:52,310] Trial 352 finished with value: 0.8967136144638062 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 53, 'dropout': 0.04213737338790596, 'epochs': 43, 'optimizer': 'sgd', 'lr': 0.002120570804021556}. Best is trial 352 with value: 0.8967136144638062.\n",
      "Training:   0%|          | 0/44 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:31:08,519] Trial 353 pruned. \n",
      "Training:   0%|          | 0/43 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:31:24,765] Trial 354 pruned. \n",
      "Training:   0%|          | 0/50 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:31:41,069] Trial 355 pruned. \n",
      "Training:   0%|          | 0/46 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:31:56,117] Trial 356 pruned. \n",
      "Training: 100%|██████████| 85/85 [12:59<00:00,  9.17s/Epochs]\n",
      "[I 2024-01-13 17:45:01,053] Trial 357 finished with value: 0.8850932121276855 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 55, 'dropout': 0.03444546865957629, 'epochs': 85, 'optimizer': 'sgd', 'lr': 0.002269842815607784}. Best is trial 352 with value: 0.8967136144638062.\n",
      "Training:   0%|          | 0/91 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:45:18,305] Trial 358 pruned. \n",
      "Training: 100%|██████████| 83/83 [12:54<00:00,  9.33s/Epochs]\n",
      "[I 2024-01-13 17:58:19,504] Trial 359 finished with value: 0.9007633328437805 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 55, 'dropout': 0.037959697173705884, 'epochs': 83, 'optimizer': 'adagrad', 'lr': 0.0020921984053898913}. Best is trial 359 with value: 0.9007633328437805.\n",
      "Training:   0%|          | 0/88 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:58:37,093] Trial 360 pruned. \n",
      "Training:   0%|          | 0/83 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 17:58:55,027] Trial 361 pruned. \n",
      "Training:   5%|▍         | 4/87 [00:39<13:41,  9.89s/Epochs]\n",
      "[I 2024-01-13 17:59:41,013] Trial 362 pruned. \n",
      "Training: 100%|██████████| 80/80 [12:03<00:00,  9.04s/Epochs]\n",
      "[I 2024-01-13 18:11:50,895] Trial 363 finished with value: 0.9181102514266968 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 58, 'dropout': 0.06566594164473301, 'epochs': 80, 'optimizer': 'adagrad', 'lr': 0.0022434305890468857}. Best is trial 363 with value: 0.9181102514266968.\n",
      "Training:   0%|          | 0/80 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:12:08,735] Trial 364 pruned. \n",
      "Training:   0%|          | 0/85 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:12:26,133] Trial 365 pruned. \n",
      "Training:   5%|▍         | 4/85 [00:47<16:08, 11.95s/Epochs]\n",
      "[I 2024-01-13 18:13:20,461] Trial 366 pruned. \n",
      "Training:   0%|          | 0/82 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:13:36,235] Trial 367 pruned. \n",
      "Training:   0%|          | 0/84 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:13:53,295] Trial 368 pruned. \n",
      "Training:   0%|          | 0/81 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:14:10,442] Trial 369 pruned. \n",
      "Training:   5%|▍         | 4/86 [00:48<16:42, 12.23s/Epochs]\n",
      "[I 2024-01-13 18:15:05,733] Trial 370 pruned. \n",
      "Training:   0%|          | 0/77 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:15:23,303] Trial 371 pruned. \n",
      "Training:   0%|          | 0/89 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:15:40,778] Trial 372 pruned. \n",
      "Training:   0%|          | 0/92 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:15:57,846] Trial 373 pruned. \n",
      "Training:   5%|▍         | 4/88 [00:47<16:31, 11.81s/Epochs]\n",
      "[I 2024-01-13 18:16:51,709] Trial 374 pruned. \n",
      "Training:   0%|          | 0/79 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:17:08,675] Trial 375 pruned. \n",
      "Training:   5%|▍         | 4/86 [00:13<04:45,  3.49s/Epochs]\n",
      "[I 2024-01-13 18:17:28,866] Trial 376 pruned. \n",
      "Training:   0%|          | 0/83 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:17:45,665] Trial 377 pruned. \n",
      "Training:   0%|          | 0/85 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:18:00,703] Trial 378 pruned. \n",
      "Training:   0%|          | 0/89 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:18:18,332] Trial 379 pruned. \n",
      "Training:   0%|          | 0/93 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:18:35,161] Trial 380 pruned. \n",
      "Training:   0%|          | 0/54 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:18:45,634] Trial 381 pruned. \n",
      "Training:   7%|▋         | 4/56 [00:35<07:42,  8.90s/Epochs]\n",
      "[I 2024-01-13 18:19:27,430] Trial 382 pruned. \n",
      "Training:   0%|          | 0/87 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:19:44,456] Trial 383 pruned. \n",
      "Training:   0%|          | 0/91 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:20:01,992] Trial 384 pruned. \n",
      "Training:   0%|          | 0/41 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:20:18,870] Trial 385 pruned. \n",
      "Training:   0%|          | 0/84 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:20:35,907] Trial 386 pruned. \n",
      "Training:   0%|          | 0/90 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:20:45,557] Trial 387 pruned. \n",
      "Training:   0%|          | 0/53 [00:07<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:20:59,960] Trial 388 pruned. \n",
      "Training:   8%|▊         | 4/49 [00:39<07:20,  9.78s/Epochs]\n",
      "[I 2024-01-13 18:21:45,176] Trial 389 pruned. \n",
      "Training:   0%|          | 0/58 [00:41<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:22:33,265] Trial 390 pruned. \n",
      "Training:   0%|          | 0/65 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:22:49,915] Trial 391 pruned. \n",
      "Training:   0%|          | 0/51 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:23:00,105] Trial 392 pruned. \n",
      "Training:   0%|          | 0/88 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:23:16,875] Trial 393 pruned. \n",
      "Training:   9%|▉         | 4/45 [00:46<07:57, 11.65s/Epochs]\n",
      "[I 2024-01-13 18:24:09,683] Trial 394 pruned. \n",
      "Training:   0%|          | 0/80 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:24:25,954] Trial 395 pruned. \n",
      "Training:   0%|          | 0/48 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:24:41,173] Trial 396 pruned. \n",
      "Training:   0%|          | 0/93 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:24:58,984] Trial 397 pruned. \n",
      "Training:   0%|          | 0/83 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:25:09,050] Trial 398 pruned. \n",
      "Training:   5%|▍         | 4/86 [00:35<12:09,  8.90s/Epochs]\n",
      "[I 2024-01-13 18:25:50,671] Trial 399 pruned. \n",
      "Training:   0%|          | 0/90 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:26:02,694] Trial 400 pruned. \n",
      "Training:   0%|          | 0/53 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:26:19,355] Trial 401 pruned. \n",
      "Training:   0%|          | 0/68 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:26:35,426] Trial 402 pruned. \n",
      "Training:   0%|          | 0/44 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:26:45,198] Trial 403 pruned. \n",
      "Training:   0%|          | 0/5 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:26:59,812] Trial 404 pruned. \n",
      "Training:   0%|          | 0/81 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:27:16,556] Trial 405 pruned. \n",
      "Training:   0%|          | 0/91 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:27:31,942] Trial 406 pruned. \n",
      "Training:   0%|          | 0/94 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:27:44,154] Trial 407 pruned. \n",
      "Training:   0%|          | 0/62 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:28:00,841] Trial 408 pruned. \n",
      "Training:   0%|          | 0/49 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:28:17,552] Trial 409 pruned. \n",
      "Training:   0%|          | 0/74 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:28:27,090] Trial 410 pruned. \n",
      "Training:   5%|▍         | 4/88 [00:44<15:31, 11.09s/Epochs]\n",
      "[I 2024-01-13 18:29:17,538] Trial 411 pruned. \n",
      "Training:   0%|          | 0/51 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:29:32,560] Trial 412 pruned. \n",
      "Training:   0%|          | 0/70 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:29:47,212] Trial 413 pruned. \n",
      "Training:   0%|          | 0/85 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:30:03,304] Trial 414 pruned. \n",
      "Training:   0%|          | 0/55 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:30:20,113] Trial 415 pruned. \n",
      "Training:   0%|          | 0/47 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:30:31,927] Trial 416 pruned. \n",
      "Training:   0%|          | 0/37 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:30:48,687] Trial 417 pruned. \n",
      "Training:   0%|          | 0/41 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:30:57,714] Trial 418 pruned. \n",
      "Training:   0%|          | 0/20 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:31:13,899] Trial 419 pruned. \n",
      "Training:   0%|          | 0/23 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:31:27,885] Trial 420 pruned. \n",
      "Training:   0%|          | 0/89 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:31:43,654] Trial 421 pruned. \n",
      "Training:   0%|          | 0/86 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:31:55,245] Trial 422 pruned. \n",
      "Training:   0%|          | 0/92 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:32:04,076] Trial 423 pruned. \n",
      "Training:   0%|          | 0/43 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:32:19,924] Trial 424 pruned. \n",
      "Training:   0%|          | 0/6 [00:35<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:33:01,014] Trial 425 pruned. \n",
      "Training:   0%|          | 0/98 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:33:17,051] Trial 426 pruned. \n",
      "Training:   0%|          | 0/50 [00:14<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:33:37,549] Trial 427 pruned. \n",
      "Training:   0%|          | 0/83 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:33:53,091] Trial 428 pruned. \n",
      "Training:   0%|          | 0/46 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:34:18,474] Trial 429 pruned. \n",
      "Training:   0%|          | 0/54 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:34:34,758] Trial 430 pruned. \n",
      "Training:   0%|          | 0/5 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:34:44,205] Trial 431 pruned. \n",
      "Training:   0%|          | 0/57 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:34:59,815] Trial 432 pruned. \n",
      "Training:   0%|          | 0/78 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:35:23,957] Trial 433 pruned. \n",
      "Training:   0%|          | 0/96 [00:07<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:35:37,576] Trial 434 pruned. \n",
      "Training:   4%|▍         | 4/90 [00:38<13:50,  9.66s/Epochs]\n",
      "[I 2024-01-13 18:36:21,823] Trial 435 pruned. \n",
      "Training:   0%|          | 0/88 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:36:47,234] Trial 436 pruned. \n",
      "Training:   0%|          | 0/52 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:36:56,747] Trial 437 pruned. \n",
      "Training:   0%|          | 0/94 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:37:22,040] Trial 438 pruned. \n",
      "Training:   0%|          | 0/48 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:37:36,370] Trial 439 pruned. \n",
      "Training:   7%|▋         | 4/60 [00:43<10:13, 10.96s/Epochs]\n",
      "[I 2024-01-13 18:38:26,054] Trial 440 pruned. \n",
      "Training:   0%|          | 0/5 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:38:37,654] Trial 441 pruned. \n",
      "Training:   0%|          | 0/87 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:38:53,809] Trial 442 pruned. \n",
      "Training:   0%|          | 0/92 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:39:02,145] Trial 443 pruned. \n",
      "Training:   0%|          | 0/100 [00:15<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:39:23,243] Trial 444 pruned. \n",
      "Training:   0%|          | 0/7 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:39:39,051] Trial 445 pruned. \n",
      "Training:   0%|          | 0/39 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:40:03,096] Trial 446 pruned. \n",
      "Training:   0%|          | 0/28 [00:04<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:40:14,075] Trial 447 pruned. \n",
      "Training:   0%|          | 0/35 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:40:30,910] Trial 448 pruned. \n",
      "Training:   0%|          | 0/82 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:40:56,434] Trial 449 pruned. \n",
      "Training:   0%|          | 0/85 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:41:12,219] Trial 450 pruned. \n",
      "Training:   0%|          | 0/50 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:41:21,631] Trial 451 pruned. \n",
      "Training:   0%|          | 0/5 [00:08<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:41:35,759] Trial 452 pruned. \n",
      "Training:   0%|          | 0/45 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:41:44,252] Trial 453 pruned. \n",
      "Training:   0%|          | 0/90 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:42:00,371] Trial 454 pruned. \n",
      "Training:   0%|          | 0/7 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:42:26,179] Trial 455 pruned. \n",
      "Training:   0%|          | 0/52 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:42:42,235] Trial 456 pruned. \n",
      "Training:   9%|▉         | 4/43 [01:26<13:58, 21.51s/Epochs]\n",
      "[I 2024-01-13 18:44:14,315] Trial 457 pruned. \n",
      "Training:   0%|          | 0/31 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:44:29,645] Trial 458 pruned. \n",
      "Training:   0%|          | 0/48 [00:17<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:44:53,251] Trial 459 pruned. \n",
      "Training:   0%|          | 0/64 [00:07<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:45:06,721] Trial 460 pruned. \n",
      "Training:   0%|          | 0/84 [00:37<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:45:50,835] Trial 461 pruned. \n",
      "Training:   0%|          | 0/9 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:46:00,349] Trial 462 pruned. \n",
      "Training:   0%|          | 0/56 [00:05<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:46:11,809] Trial 463 pruned. \n",
      "Training:   0%|          | 0/95 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:46:28,365] Trial 464 pruned. \n",
      "Training:   5%|▍         | 4/87 [01:11<24:42, 17.86s/Epochs]\n",
      "[I 2024-01-13 18:47:52,347] Trial 465 pruned. \n",
      "Training:   0%|          | 0/54 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:48:00,858] Trial 466 pruned. \n",
      "Training:   0%|          | 0/92 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:48:17,568] Trial 467 pruned. \n",
      "Training:   0%|          | 0/8 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:48:26,913] Trial 468 pruned. \n",
      "Training:   0%|          | 0/46 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:48:42,844] Trial 469 pruned. \n",
      "Training:   0%|          | 0/58 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:49:06,910] Trial 470 pruned. \n",
      "Training:   0%|          | 0/81 [00:11<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:49:23,712] Trial 471 pruned. \n",
      "Training:   0%|          | 0/89 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:49:39,665] Trial 472 pruned. \n",
      "Training:   8%|▊         | 4/50 [01:19<15:17, 19.96s/Epochs]\n",
      "[I 2024-01-13 18:51:05,341] Trial 473 pruned. \n",
      "Training:   0%|          | 0/67 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:51:13,159] Trial 474 pruned. \n",
      "Training:   0%|          | 0/5 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:51:28,805] Trial 475 pruned. \n",
      "Training:   0%|          | 0/7 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 18:51:45,026] Trial 476 pruned. \n",
      "Training:  61%|██████    | 60/98 [14:11<08:59, 14.20s/Epochs]\n",
      "[I 2024-01-13 19:06:02,436] Trial 477 pruned. \n",
      "Training:   0%|          | 0/86 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:06:12,502] Trial 478 pruned. \n",
      "Training:   0%|          | 0/90 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:06:29,399] Trial 479 pruned. \n",
      "Training:  79%|███████▉  | 60/76 [17:20<04:37, 17.35s/Epochs]\n",
      "[I 2024-01-13 19:23:56,365] Trial 480 pruned. \n",
      "Training:   8%|▊         | 4/48 [00:34<06:16,  8.56s/Epochs]\n",
      "[I 2024-01-13 19:24:36,299] Trial 481 pruned. \n",
      "Training:   0%|          | 0/93 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:24:52,626] Trial 482 pruned. \n",
      "Training: 100%|██████████| 10/10 [01:32<00:00,  9.29s/Epochs]\n",
      "[I 2024-01-13 19:26:31,430] Trial 483 finished with value: 0.8615384697914124 and parameters: {'num_layers{}': 4, 'num_mlp_layers{}': 4, 'log_batch_size': 3, 'hidden_dim': 46, 'dropout': 0.11338322362012626, 'epochs': 10, 'optimizer': 'adagrad', 'lr': 0.0072763529545478755}. Best is trial 363 with value: 0.9181102514266968.\n",
      "Training: 100%|██████████| 42/42 [11:07<00:00, 15.89s/Epochs]\n",
      "[I 2024-01-13 19:37:44,500] Trial 484 finished with value: 0.9071207046508789 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 2, 'log_batch_size': 2, 'hidden_dim': 43, 'dropout': 0.018443905526205496, 'epochs': 42, 'optimizer': 'sgd', 'lr': 0.003107583585571047}. Best is trial 363 with value: 0.9181102514266968.\n",
      "Training:   0%|          | 0/42 [00:19<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:38:09,774] Trial 485 pruned. \n",
      "Training:   0%|          | 0/40 [00:06<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:38:21,974] Trial 486 pruned. \n",
      "Training:   0%|          | 0/38 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:38:30,337] Trial 487 pruned. \n",
      "Training:   0%|          | 0/43 [00:03<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:38:39,966] Trial 488 pruned. \n",
      "Training:   0%|          | 0/44 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:38:56,569] Trial 489 pruned. \n",
      "Training:   0%|          | 0/40 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:39:21,012] Trial 490 pruned. \n",
      "Training:   0%|          | 0/33 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:39:36,920] Trial 491 pruned. \n",
      "Training:   0%|          | 0/45 [00:18<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:40:01,116] Trial 492 pruned. \n",
      "Training:   0%|          | 0/41 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:40:16,706] Trial 493 pruned. \n",
      "Training:   0%|          | 0/47 [00:02<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:40:25,364] Trial 494 pruned. \n",
      "Training: 100%|██████████| 52/52 [07:03<00:00,  8.15s/Epochs]\n",
      "[I 2024-01-13 19:47:34,900] Trial 495 finished with value: 0.8929110169410706 and parameters: {'num_layers{}': 3, 'num_mlp_layers{}': 2, 'log_batch_size': 3, 'hidden_dim': 51, 'dropout': 0.02601193184385723, 'epochs': 52, 'optimizer': 'sgd', 'lr': 0.0038860620944900937}. Best is trial 363 with value: 0.9181102514266968.\n",
      "Training:   8%|▊         | 4/51 [00:40<07:51, 10.04s/Epochs]\n",
      "[I 2024-01-13 19:48:21,037] Trial 496 pruned. \n",
      "Training:   0%|          | 0/53 [00:09<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:48:35,656] Trial 497 pruned. \n",
      "Training:   7%|▋         | 4/55 [00:41<08:50, 10.40s/Epochs]\n",
      "[I 2024-01-13 19:49:23,032] Trial 498 pruned. \n",
      "Training:   0%|          | 0/51 [00:10<?, ?Epochs/s]\n",
      "[I 2024-01-13 19:49:38,838] Trial 499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  500\n",
      "  Number of pruned trials:  454\n",
      "  Number of complete trials:  46\n",
      "Best trial:\n",
      "  Value:  0.9181102514266968\n",
      "  Params: \n",
      "    num_layers{}: 4\n",
      "    num_mlp_layers{}: 2\n",
      "    log_batch_size: 3\n",
      "    hidden_dim: 58\n",
      "    dropout: 0.06566594164473301\n",
      "    epochs: 80\n",
      "    optimizer: adagrad\n",
      "    lr: 0.0022434305890468857\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500, timeout=60000)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "\tprint(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(GNN, args, 'GNN3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN, args = load('GNN1', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot to feature-generated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_graph(city):\n",
    "\tlocation_graph = ox.graph_from_place(city, network_type=\"drive\")\n",
    "\tlocation_graph = ox.speed.add_edge_speeds(location_graph)\n",
    "\tlocation_graph = ox.speed.add_edge_travel_times(location_graph)\n",
    "\treturn {'location_graph': location_graph, 'city': city}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "piedmont = get_location_graph(\"Piedmont, California, USA\")\n",
    "# san_francisco = get_location_graph(\"San Francisco, California, USA\")\n",
    "founex = get_location_graph(\"Founex, Switzerland\")\n",
    "carmel = get_location_graph(\"Carmel, Indiana, USA\")\n",
    "geneva = get_location_graph(\"Geneva, Switzerland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'GENConv',\n",
    "    'head':              'regression',\n",
    "    'num_layers':        2,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        32,\n",
    "    'node_feature_dim':  4,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        64,\n",
    "    'output_dim':        1,\n",
    "    'dropout':           0.35,\n",
    "    'epochs':            50,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "train_num = 100; test_num = 30\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 0.75,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 2,\n",
    "    'weighted': True\n",
    "}\n",
    "feat_config = {\n",
    "    'graph_type': 'FEAT',\n",
    "    'q': 0.85,\n",
    "    'weighted': True\n",
    "}\n",
    "osmnx_config = {\n",
    "    'graph_type': 'OSMNX',\n",
    "    'location_graph': piedmont['location_graph']\n",
    "}\n",
    "# osmnx_config_2 = {\n",
    "#     'graph_type': 'OSMNX',\n",
    "#     'location_graph': san_francisco['location_graph']\n",
    "# }\n",
    "\n",
    "# ox.plot_graph(piedmont['location_graph'])\n",
    "# ox.plot_graph(san_francisco['location_graph'])\n",
    "\n",
    "# part_config = {\n",
    "# \t'graph_type': 'PART',\n",
    "#     'p': 0.5,\n",
    "#     'size': 4,\n",
    "#     'eps': 0.1\n",
    "# },\n",
    "# part_config = {\n",
    "# \t'graph_type': 'PART',\n",
    "#     'p': 0.5,\n",
    "#     'size': 3,\n",
    "#     'eps': 0.3\n",
    "# }\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "train_instances = [\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config_2),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **part_config),\n",
    "    ]\n",
    "\n",
    "test_instances = [\n",
    "        *ig.sample_instances(8, 8, test_num, rng, **er_config),\n",
    "        *ig.sample_instances(8, 8, test_num, rng, **ba_config),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config_2),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
    "        # *ig.sample_instances(8, 8, train_num, rng, **part_config),\n",
    "    ]\n",
    "\n",
    "\n",
    "train_data = Dataset(tc._instances_to_train_samples(train_instances, args['head']))\n",
    "test_data = Dataset(tc._instances_to_train_samples(test_instances, args['head']))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/50 [00:00<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.106903511831696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1/50 [00:07<06:20,  7.77s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 30.454212188720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 2/50 [00:12<04:49,  6.04s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.58574105236018\n",
      "49.71131266371112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 3/50 [00:20<05:24,  6.90s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 28.536415100097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 4/50 [00:25<04:43,  6.15s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.395805121448554\n",
      "48.16656526672506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 5/50 [00:33<05:06,  6.81s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 26.773653030395508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 6/50 [00:38<04:30,  6.14s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.57358171311494\n",
      "45.52464294326639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 7/50 [00:45<04:41,  6.54s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 26.396894454956055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 8/50 [00:50<04:12,  6.02s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.53729570789872\n",
      "49.42635243638654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9/50 [00:58<04:28,  6.56s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 24.67470932006836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10/50 [01:03<04:02,  6.07s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.79879299235121\n",
      "44.9593545633833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 11/50 [01:10<04:14,  6.54s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 25.050689697265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 12/50 [01:15<03:50,  6.06s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.46595388510517\n",
      "47.41107727344905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 13/50 [01:23<04:00,  6.49s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 22.553268432617188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 14/50 [01:28<03:37,  6.03s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.991975688399556\n",
      "42.864472754915184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 15/50 [01:36<03:48,  6.54s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 21.422317504882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 16/50 [01:40<03:23,  5.97s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.39781870262645\n",
      "45.712507039052305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 17/50 [01:48<03:32,  6.43s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 21.82000732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 18/50 [01:53<03:12,  6.02s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.59528014174131\n",
      "44.27297433634785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 19/50 [02:00<03:20,  6.47s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 20.133201599121094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20/50 [02:05<03:00,  6.02s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.628333289311314\n",
      "42.08484000678374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 21/50 [02:13<03:08,  6.51s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 18.195068359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 22/50 [02:17<02:45,  5.93s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4525077665632\n",
      "43.43435348319116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 23/50 [02:25<02:51,  6.35s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 17.225929260253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 24/50 [02:30<02:33,  5.91s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.18080467010213\n",
      "40.63400520164276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 25/50 [02:37<02:39,  6.40s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 21.04060935974121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 26/50 [02:42<02:19,  5.83s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.35510210956369\n",
      "40.64163245980985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 27/50 [02:49<02:25,  6.34s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 17.116933822631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 28/50 [02:54<02:09,  5.90s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.49823658542098\n",
      "40.32126688605157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 29/50 [03:02<02:16,  6.48s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 15.147028923034668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30/50 [03:07<02:02,  6.10s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.688233496407484\n",
      "38.75253979874549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 31/50 [03:15<02:04,  6.54s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 16.327695846557617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 32/50 [03:20<01:48,  6.02s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.11284236872308\n",
      "39.39152059844721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 33/50 [03:27<01:50,  6.47s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 13.122635841369629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 34/50 [03:32<01:34,  5.92s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.03061410079493\n",
      "39.4217336247569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 35/50 [03:39<01:35,  6.35s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 12.350340843200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 36/50 [03:44<01:22,  5.88s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.58326076650174\n",
      "36.11739979289403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 37/50 [03:52<01:23,  6.46s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 12.730376243591309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 38/50 [03:57<01:12,  6.02s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.48876111396005\n",
      "35.98195260076879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 39/50 [04:04<01:11,  6.47s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 11.356830596923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40/50 [04:09<00:59,  5.92s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.61535904995749\n",
      "40.50164809293836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 41/50 [04:16<00:57,  6.44s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 11.237894058227539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 42/50 [04:21<00:47,  5.97s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.236447702835655\n",
      "34.09373296051382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▌ | 43/50 [04:30<00:47,  6.81s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 12.657241821289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 44/50 [04:35<00:37,  6.25s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.06951147418156\n",
      "31.772064428552287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 45/50 [04:43<00:33,  6.71s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 10.170735359191895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 46/50 [04:48<00:24,  6.16s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.63345767558178\n",
      "33.37477687918137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 47/50 [04:55<00:19,  6.58s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 9.780745506286621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 48/50 [05:00<00:12,  6.06s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.565709700216757\n",
      "30.314167617280905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 49/50 [05:08<00:06,  6.48s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.0\n",
      "TEST LOSS: 8.354435920715332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [05:12<00:00,  6.25s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.35175694782043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, GNN, _ = train(train_loader, test_loader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the threshold greedy value\n",
    "The instance set used to determine the threshold should be the same as the training set for the base models. Here we reduce the number of instances to make the evaluation faster.\n",
    "\n",
    "For the moment, the instance set is the evaluation set since they are too different and would disadvantage threshold greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold value: 0.0 achieves CR: 0.9146754475262843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gnn_library.OBM_threshold_greedy import OBM_Threshold_Greedy\n",
    "from tqdm import tqdm\n",
    "seed = np.random.randint(0, 500000)\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "thresholds = np.linspace(0, 1, 2) # TODO remove\n",
    "#TODO max value in threshold should be max value observable in graphs (is not the case for osmnx graphs for the moment)\n",
    "thresholded_greedy_models = {threshold: OBM_Threshold_Greedy(threshold) for threshold in thresholds}\n",
    "\n",
    "osmnx_config1 = {\n",
    "    'graph_type': 'OSMNX',\n",
    "    'location_graph': piedmont['location_graph']\n",
    "}\n",
    "osmnx_config2 = {\n",
    "    'graph_type': 'OSMNX',\n",
    "    'location_graph': geneva['location_graph']\n",
    "}\n",
    "osmnx_config3 = {\n",
    "    'graph_type': 'OSMNX',\n",
    "    'location_graph': carmel['location_graph']\n",
    "}\n",
    "\n",
    "train_num = 10\n",
    "train_instances = [\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config1),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config2),\n",
    "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config3),\n",
    "]\n",
    "\n",
    "# train_instances = [\n",
    "#         *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
    "#         *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
    "#         *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
    "#         *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
    "# ]\n",
    "\n",
    "\n",
    "greedy_ratios = {}\n",
    "for threshold, model in tqdm(thresholded_greedy_models.items()): \n",
    "    rng = np.random.default_rng(seed)\n",
    "    ratio = ev.evaluate_model(\n",
    "        meta_model=None,\n",
    "        meta_model_type=None,\n",
    "        base_models=[model],\n",
    "        instances=train_instances,\n",
    "        batch_size=50,\n",
    "        rng=rng,\n",
    "        num_realizations=5\n",
    "    )\n",
    "    greedy_ratios[threshold] = np.mean(ratio[0])\n",
    "    \n",
    "\n",
    "max_threshold = max(greedy_ratios, key = greedy_ratios.get)\n",
    "print(f\"Best threshold value: {max_threshold} achieves CR: {greedy_ratios[max_threshold]}\")\n",
    "THRESHOLD_MODEL = thresholded_greedy_models[max_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.9146754475262843, 1.0: 0.8810199370175859}\n"
     ]
    }
   ],
   "source": [
    "print(greedy_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Competitive ratios --\n",
      "GNN: 0.8371\n",
      "Greedy: 0.8441\n",
      "LP-rounding: 0.9389\n",
      "Thresholded greedy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "seed = np.random.randint(0, 500000)\n",
    "(m, n) = (32, 16)\n",
    "# config = {\n",
    "#     'graph_type': 'FEAT',\n",
    "#     'q': 0.85,\n",
    "#     'weighted': True\n",
    "# }\n",
    "# config = {\n",
    "#     'graph_type': 'OSMNX',\n",
    "#     'location_graph': piedmont['location_graph']\n",
    "# }\n",
    "# config = {\n",
    "# \t'graph_type': 'PART',\n",
    "#     'p': 0.5,\n",
    "#     'size': 4,\n",
    "#     'eps': 0.1\n",
    "# }\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "# eval_instances = ig.sample_instances(m, n, 100, rng, **config)\n",
    "eval_num = 25\n",
    "eval_instances = [\n",
    "        *ig.sample_instances(m, n, eval_num, rng, **er_config),\n",
    "        *ig.sample_instances(m, n, eval_num, rng, **ba_config),\n",
    "        *ig.sample_instances(m, n, eval_num, rng, **feat_config),\n",
    "        *ig.sample_instances(m, n, eval_num, rng, **osmnx_config),\n",
    "]\n",
    "\n",
    "ratios = ev.evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[GNN],\n",
    "    instances=eval_instances,\n",
    "    batch_size=50,\n",
    "    rng=rng,\n",
    "    num_realizations=5\n",
    ")\n",
    "\n",
    "\n",
    "ratios2 = ev.evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[THRESHOLD_MODEL],\n",
    "    instances=eval_instances,\n",
    "    batch_size=50,\n",
    "    rng=rng,\n",
    "    num_realizations=5\n",
    ")\n",
    "\n",
    "pp_output(ratios, _, show_log=False)\n",
    "print(f\"Thresholded greedy: {np.mean(ratios2[0]).round(4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.75, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75]\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (4, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (12, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (20, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (28, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (36, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (44, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (52, 16)\n",
      "{'graph_type': 'FEAT', 'q': 0.75, 'weighted': True} (60, 16)\n"
     ]
    }
   ],
   "source": [
    "num_trials = 40\n",
    "node_configs = [(x, 16) for x in np.arange(4, 64, 8)]\n",
    "# of nodes [20 -> 80]\n",
    "# of nodes in batch [10,000 -> 40,000]\n",
    "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
    "graph_configs = [\n",
    "    # {\n",
    "    #     'graph_type': 'GM'\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'ER',\n",
    "    #     'p': 0.75,\n",
    "    #     'weighted': False\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'BA',\n",
    "    #     'ba_param': 4,\n",
    "    #     'weighted': False\n",
    "    # },\n",
    "    {\n",
    "        'graph_type': 'FEAT',\n",
    "        'q': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    # {\n",
    "    #     'graph_type': 'FEAT',\n",
    "    #     'q': 0.9,\n",
    "    #     'weighted': True\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'FEAT',\n",
    "    #     'q': 0.95,\n",
    "    #     'weighted': True\n",
    "    # },\n",
    "\n",
    "    # {\n",
    "    #     'graph_type': 'PART',\n",
    "    #     'p': 0.5,\n",
    "    #     'size': 4,\n",
    "    #     'eps': 0.1\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'PART',\n",
    "    #     'p': 0.5,\n",
    "    #     'size': 3,\n",
    "    #     'eps': 0.3\n",
    "    # }\n",
    "]\n",
    "\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "print(ratios)\n",
    "\n",
    "data = {config['q']: [] for config in graph_configs}\n",
    "for graph_config in graph_configs:\n",
    "    for i, node_config in enumerate(node_configs):\n",
    "        print(graph_config, node_config)\n",
    "        seed = np.random.randint(0, 500000)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        instances = ig.sample_instances(*node_config, num_trials, rng, **graph_config)\n",
    "\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        gnn_learned_ratios, greedy_ratios, lp_match_ratios = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type=None,\n",
    "            base_models=[GNN],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "\n",
    "\n",
    "        data[graph_config['q']].append(np.array(\n",
    "            [\n",
    "                gnn_learned_ratios,\n",
    "                greedy_ratios,\n",
    "                lp_match_ratios\n",
    "            ]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.75, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75]\n",
      "(4, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158288/946936367.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data[graph_config['city']].append(np.array(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(20, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(28, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(36, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(44, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(52, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n",
      "(60, 16) {'graph_type': 'OSMNX', 'location_graph': <networkx.classes.multidigraph.MultiDiGraph object at 0x7fdec395be80>, 'city': 'Piedmont, California, USA'}\n"
     ]
    }
   ],
   "source": [
    "num_trials = 30\n",
    "node_configs = [(x, 16) for x in np.arange(4, 64, 8)]\n",
    "# of nodes [20 -> 80]\n",
    "# of nodes in batch [10,000 -> 40,000]\n",
    "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graph_configs = [\n",
    "    # {\n",
    "    # 'graph_type': 'FEAT',\n",
    "    # 'q': 0.5\n",
    "    # },\n",
    "    {\n",
    "        'graph_type': 'OSMNX',\n",
    "        'location_graph': piedmont['location_graph'],\n",
    "        'city': piedmont['city']\n",
    "    },\n",
    "    # {\n",
    "    #     'graph_type': 'OSMNX',\n",
    "    #     'location_graph': carmel['location_graph'],\n",
    "    #     'city': carmel['city']\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'OSMNX',\n",
    "    #     'location_graph': geneva['location_graph'],\n",
    "    #     'city': geneva['city']\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'OSMNX',\n",
    "    #     'location_graph': founex['location_graph'],\n",
    "    #     'city': founex['city']\n",
    "    # },\n",
    "    # {\n",
    "    # 'graph_type': 'FEAT',\n",
    "    # 'q': 0.75,\n",
    "    # 'weighted': True\n",
    "    # },\n",
    "    # {\n",
    "    # 'graph_type': 'FEAT',\n",
    "    # 'q': 0.9,\n",
    "    # 'weighted': True\n",
    "    # },\n",
    "    # {\n",
    "    # 'graph_type': 'FEAT',\n",
    "    # 'q': 0.95,\n",
    "    # 'weighted': True\n",
    "    # },\n",
    "    # {\n",
    "    # 'graph_type': 'FEAT',\n",
    "    # 'q': 0.99\n",
    "    # }\n",
    "    # {\n",
    "    #     'graph_type': 'PART',\n",
    "    #     'p': 0.5,\n",
    "    #     'size': 4,\n",
    "    #     'eps': 0.1\n",
    "    # },\n",
    "    # {\n",
    "    #     'graph_type': 'PART',\n",
    "    #     'p': 0.5,\n",
    "    #     'size': 3,\n",
    "    #     'eps': 0.3\n",
    "    # }\n",
    "]\n",
    "\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "print(ratios)\n",
    "\n",
    "data = {config['city']: [] for config in graph_configs}\n",
    "for graph_config in graph_configs:\n",
    "    for i, node_config in enumerate(node_configs):\n",
    "        print(node_config, graph_config)\n",
    "        seed = np.random.randint(0, 500000)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        instances = ig.sample_instances(*node_config, num_trials, rng, **graph_config)\n",
    "\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        gnn_learned_ratios, greedy_ratios, lp_match_ratios = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type=None,\n",
    "            base_models=[GNN],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "        thresholded_greedy_ratios = [0]\n",
    "\n",
    "        # thresholded_greedy_ratios, greedy_ratios, lp_match_ratios = evaluate_model(\n",
    "        #     meta_model=None,\n",
    "        #     meta_model_type=None,\n",
    "        #     base_models=[THRESHOLD_MODEL],\n",
    "        #     instances=instances,\n",
    "        #     batch_size=batch_size,\n",
    "        #     rng=rng,\n",
    "        #     num_realizations=5\n",
    "        # )\n",
    "\n",
    "        data[graph_config['city']].append(np.array(\n",
    "            [\n",
    "                gnn_learned_ratios,\n",
    "                thresholded_greedy_ratios,\n",
    "                greedy_ratios,\n",
    "                lp_match_ratios\n",
    "            ]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.75, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "print(ratios)\n",
    "for city, comp_ratios in data.items():\n",
    "    greedy_avg_ratios = []\n",
    "    thresholded_greedy_avg_ratios = []\n",
    "    gnn_avg_ratios = []\n",
    "    lp_match_avg_ratios = []\n",
    "\n",
    "\n",
    "    for trial_ratios in comp_ratios:\n",
    "        gnn_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
    "        thresholded_greedy_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
    "        greedy_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
    "        lp_match_avg_ratios.append(np.array(trial_ratios[3]).mean())\n",
    "        \n",
    "\n",
    "    title = f\"OSMNX_discard_{city}\"\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(title)\n",
    "    plt.plot(ratios, gnn_avg_ratios, label='GNN')\n",
    "    plt.plot(ratios, thresholded_greedy_avg_ratios, label='Thresholded Greedy')\n",
    "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
    "    plt.plot(ratios, lp_match_avg_ratios, label='LP ROUNDING')\n",
    "    plt.xlabel('# online / # offline')\n",
    "    plt.ylabel('Average competitive ratio')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"data/{title}.png\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEAT_only_ratings_0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAGDCAYAAADHzQJ9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABw+0lEQVR4nO3dd3gUVdvH8e+dRhISaui9914UpCNNIVQLKgJi76KCCiiKoohi5VXkUYpYEJCqSFGKgCBFegcpAUInQHo57x+zYBrJAtnMZnN/rmsvdmdnd37zrE/umTNnzhFjDEoppZTyLF52B1BKKaVU1tMCr5RSSnkgLfBKKaWUB9ICr5RSSnkgLfBKKaWUB9ICr5RSSnkgLfBK5TIiYkSkss0ZWorIHjszKOXptMArdR1E5JCIRIvI5WSP5o6ieTnV455Unx3pWO8Wx+v7k60bLSJJyT9vzx66RuqDCmPMn8aYajbmaS8iu0UkSkSWiUi5a6xXNp3f1YjIi47326T+3USkf/bujVLp0wKv1PXrZowJuvIAjjuWF0i+3Bgz/coHRESAB4Fzjn8xxnyX7Du6AMdTfW+OICI+dme4HiISAvwMjAAKARuA6emta4w5kuo3qQMkAbOSrXY81e8+xcW7oJRTtMArlT1aAiWAZ4F7RcTvZr5MRGqIyHIRuSAiO0QkNNl7k0VkvIj8IiKXRGSdiFRK5zuaiMhJEfFOtqyXiGzJZNsjRWSmiEwTkYvAABFpKiJ/OfKcEJHPr+yjiKx0fHTLlZYNx5lvWLLvPCQiL4nIVhGJEJHpIuKf7P0hju89LiIPJ28REJE7RGSnY1+PichLmfzP1wvYYYyZYYyJAUYC9USkeiafA+vgbKUx5pAT6yplKy3wSmWP/sB84CfH6243+kUi4uv4rsVAUeAZ4DsRSd7kfS/wJlAQ2A+8k/p7jDHrgbNAx2SL+wFTnYjRHZgJFAC+AxKBF4AQoBnQHnjSsZ1Wjs/US92ykcrdQGegAlAXGODY387AYOB2oDLQJtXnvgYeM8YEA7WBPzLJXgu4ehBjjIkEDjiWX1OyVpjUZ+hFHQdK/4rIRyKSN5PtK5UttMArdf3mOM5UL4jInGTLzyRbfkFEagCISCBwF/C9MSYeqzA+eBPbvxUIAt4zxsQZY/4AFgB9k60z2xjztzEmAasA17/Gd00BHnDkLAR0Ar53IsNfxpg5xpgkY0y0MWajMWatMSbBcXY7AWh9nfv1qTHmuDHmHNYBzJXMdwOTjDE7jDFRWGfcycUDNUUknzHmvDFmUybbCQIiUi2LAIIz+VwLoBjW73fFbkfOEkA7oBEwLpPvUSpbaIFX6vr1MMYUcDx6JFsekmx5AWPMLsfynkAC8Kvj9XdAFxEpcoPbLwkcNcYkJVt2GCiV7HV4sudRWEUtPdOAbo6zzruBP40xJ5zIcDT5CxGpKiILRCTc0Ww/Guts/npcK3PJVNtLsW2gN3AHcFhEVohIs0y2cxnIl2pZPuBSJp/rD8wyxlztAGmMCTfG7HQc6PwLDHHkUcp2WuCVcr3+WMXqiIiEAzMAX+C+G/y+40AZEUn+/9+ywLHr/SJjzDHgL6zr0v2Ab539aKrXX2CdzVYxxuQDXgPkevNcwwmgdLLXZVIEMWa9MaY71uWKOfx3GeRadgD1rrxwHNxUcixPl4gEYLXCZNaBzqB/V5Wb0P8QlXIhESmFdT26K1ZTbn2s4jKGG2+mX4d1hjtERHxFpA3WNf0fb/D7pmKdedbB6l1+I4KBi8BlR2e1J1K9fxKoeIPf/RMw0NGxMBCr9zsAIuLnuN0wv+Pyx0WsXu4ZmQ3UFpHejo58rwNbjTG7M/hMT+A8sCz5QhFpKyLlxFIGeA+Ye917qJQLaIFXKutcSHU/9GCss+LNxpjFjubccGNMOPApUFdEal/vRowxcVgFvQtwBvg/4MFMClRGZgPlsK7bR93gd7yE1SJxCZhI2tvORgJTHH0T7r6eLzbGLMT632sZVofBtY63Yh3/9gMOOS4NPA7cn8n3ncZqRn8Hq2jfgtUpEQAR+VJEvkz1sf7At8aY1C0XDYA1QKTj321Yd0ooZTtJ+9+rUiq3EZEDWD3Rl9qdJTOOzovbgTyOToRKqXToGbxSuZyI9Ma6dpzZ7WW2EZGeIpJHRApiXd6Yr8VdqYxpgVfKDUn6Q6ReeZTNwu0sx+og91TyXvkisvAa234tq7Z9nR4DTmHdr55I2mv8KYjIa9fIvzA7wirlDrSJXimllPJAegavlFJKeSAt8EoppZQHylGzQGUkJCTElC9f3u4YSimlVLbZuHHjGWNMuqNiekyBL1++PBs2bLA7hlJKKZVtROTwtd7TJnqllFLKA2mBV0oppTyQFnillFLKA2mBV0oppTyQFnillFLKA2mBV0oppTyQFnillFLKA2mBV0oppTyQFnillFLKA7mswIvINyJySkS2X+N9EZFPRWS/iGwVkYbJ3usvIvscj/6uyqiUUkp5KleewU8GOmfwfhegiuPxKNac1IhIIeAN4BagKfCGiBR0YU6llFLK47iswBtjVgLnMlilOzDVWNYCBUSkBNAJWGKMOWeMOQ8sIeMDBZfYvPRH9h85RnxiUnZvWimllLppdk42Uwo4mux1mGPZtZanISKPYp39U7Zs2SwLFn32KDX+fJrtK8vTJPFVioUUoWrxYKoVC6JqsWCqFQ+mTMFAvLwky7aplFJKZaUcPZucMeYr4CuAxo0bm6z6Xr+CpTnecTwNlj7BvPyf8W7+t/jnyHnmbzl+dZ0AX2+qXCn4xYIdBwDBFMuXBxEt/EoppexlZ4E/BpRJ9rq0Y9kxoE2q5cuzLRXg7SWUue0eyOdN2Z8f4YuQD2DwdC4n+bLv5CX2nrzEnvDL7D15iRV7TzNzY9jVz+bz96Fa8eCrZ/pXDgAK5vXLzl1QSimVy9lZ4OcBT4vIj1gd6iKMMSdEZBEwOlnHuo7Aq7YkrNMHEuNhzhMw/QGC7v2eBmUL0qBsyj5/5yLj2Hu18Fv/zt9ynO/WJVxdp0hwHutMv1gw1YpbZ/5VigUTlCdHN6IopZRyUy6rLiLyA9aZeIiIhGH1jPcFMMZ8CfwK3AHsB6KAgY73zonIKGC946veMsZk1FnPter3hcQ4mP8szBgAd00Bn5Rn44Xy+nFrxcLcWrHw1WXGGE5ejGXPyUvsDb9k/XvyEt//fZiY+P867pUuGJCiib9qsWAqFc1LHh/v7NpDpZRSHkiMybJL17Zq3Lix2bBhg+s28PdE+PUlqNkden8D3jd2bJSUZDh6Purqmf6ek5fZG36JA6cvk5Bk/RbeXkL5woEpmvirFg+mXKFAfLx1bCKllFIWEdlojGmc3nvaPuyspo9YZ/KLXgPvx6HnBPC6/rNsLy+hXOG8lCucl461il9dHpeQxKGzkf8V/vBL7Dx+kYXbw7lyDObn40XlIkHJrvFbTf2lCgRoxz6llFIpaIG/Hs2egoRY+P1N8PaD0M/BK2vOqP18vKjqaKJPLjoukf2nLl9t4t8Tfom1B88y+59jV9cJyuNDlWJBya7xW/+GBPlp4VdKqVxKC/z1ajnYKvIr3rOKfNePwIVFNMDPmzql81OndP4UyyOi49l38lKKa/yLdoTz4/r/hhAolNePqlcKv+Maf5ViweQP8HVZXqWUUu5BC/yNaPMKJMbCqo+sIt9ljEuLfHryB/jSuHwhGpcvdHWZMYYzl+NS9Obfc/ISMzeGERmXeHW9Evn9r57pVykaRPH8/uQP8KVAgB/5A3wJ9vfRQXyUUiqH0wJ/I0Sg/RuQEAdrx1u96juMyvYinzaWUCQ4D0WC83Bb5ZCry40xHLsQneL+/T3hl/jr4FniEtIOxStiHUBYRd+XfAG+FAj0o8CVZYGOZY7lV5blD/DF31d7/yullDvQAn+jRKDTO1bHuzWfgY8/tBtud6p0iQilCwZSumAg7aoXu7o8ITGJo+ejOXs5lgtR8VyIjiciOp6IqLirzy9EWf+GnY/mQlQcEdHxJGVw40UeH6+rxb5AgB/5A/87ULh6IHDloCDZsmB/X7y11UAppbKMFvibIQJd3rea61eOBe880Pplu1M5zcfbiwoheakQktfpzyQlGS7HJRARlfIA4EJ0HBei4rmYatnRc1HsiLYOHqKSXSZITQSC8/ikaRFI/jzFAUOyZf6+XtqZUCmlUtECf7O8vKDrJ1Zz/bK3reb6256zO5XLeHkJ+fx9yefvm2KcYWfEJSRZLQTRcVcPDv47GLBaDq4+j47n2Pnoq88TM2g28PPxSttKEJDyQKFQXj/aVS9KXh05UCmVS+hfu6zg5QXdx1vN9Utetzre3fqE3ancjp+P19U+AtfDGMPl2IQULQZXDxAcBwvJWxSOXYhh14lLXIiKS9G5sHrxYKY81JRi+fyzeteUUsrtaIHPKt4+0Osrq8j/9opV5JsMsjuVRxARgv2t6/SlC2a+fnJxCUlcjIln4+HzDJ6+mV7/t4bJA5tQJdV4A0op5Wl03NOs5O0LfSZB1c7wy2DY9K3diXI9Px8vQoLy0KlWcaY/1ozYhCR6f7GGv/+1b3oDpZTKDlrgs5qPnzUhTaV2MO8Z2DLd7kTKoXap/Mx+sjkhwXl44Ot1LNx2wu5ISingzOVYwiNiOHs5lojoeKLjEklITMJT5kqxi0424yrx0fDdXXB4NfT5Bmr1tDuRcjgfGcegKev55+gFXu9ak4G3VbA7klK5ijGGXSes0TcX7Qhnd/ila67r5+2Fj7fg6+3leFjPfbwFP8ey/953vOflhZ9Pyuc+Xo7P+wi+Xl4pvuPK5/3S+a6U61nLkz9PvY6vt1e23vKb0WQzWuBdKS4SpvWGsPVw91SofqfdiZRDTHwiz/7wD4t3nuSxVhUZ2rm6jt6nlAslJRk2HTnvKOonOXIuChFoUq4Q7WsUJV+AL/GJScQnGuvfhCTik6znCY7lccmeW+umfJ7geB6XaBzrpX0/LjGJhCST4Z05N0sEq/B7Cb4+Ximev9OjDi2qhGT+JU5vS2eTs4dfXrjvJ/i2J/zUH+79Hqp2tDuVAvx9vfnigUaMnLeDCSsPciIihrF31SWPj47Ep1RWiUtI4q+DZ/ltezhLdp7kzOVY/Ly9uK1yYZ5sU4nbaxYjJOj67qrJKolXDh6SjONgwnEwkJBEQlIScQmGhCTrwCD58/QOLhKuLkvvPeuA48rz7JwLRAu8q/nngwdmwdRQmP4A3PejdX1e2c7bS3irey1KFPDn/d/2cPpSLBMebEQ+f52MR6kbFRmbwIq9p1m0I5w/dp/iUkwCef28aVO9KJ1qFadttSIEu8H/x7y9BO8rU37bc4zhctpEn12izsGUbnD2ADwwE8q3sDuRSubnTWEMmbmVykWDmDSwCSXyB9gdSakc43xkHEt3nWTRjpP8ue80sQlJFMrrx+01rKJ+W+UQnafCRfQavLu4fBqmdIULR6Hfz1D2VrsTqWT+3HeaJ6ZtItjfhykPNaWq3iuv1DWdiIhm8Y6TLNoRzrp/z5GYZCiZ35+OtYrTuXZxGpcriI+33qjlalrg3cmlcJh0B1w+BQ/OhdKN7E6kktlxPIIBk9YTG5/IVw825taKhe2OpJTbOHD6stVJbns4W8IiAKhcNIjOtYrTqVZxapfKp/NCZDMt8O4m4hhMvgOiz0P/+VCint2JVDJh56Po/83fHD0Xzbh76tG1bkm7IyllC2MM249d5LcdJ1i04yT7T10GoF7p/HSqbRX1SkWCbE6Zu2mBd0cXjlhn8nGRMGABFKtldyKVzIWoOB6esoENh88z/M4aPNyyot2RlMoWCYlJrD9k3c62ZOdJjl2IxttLuKVCITrVKk7HWsW0j4ob0QLvrs4dtIp8UgIM+BWKVLU7kUomJj6R53/czG87wnm4RQVeu6OG3iuvPFJMfCKr959h0Y5wlu46xbnIOPL4eNGyShE61SrG7TWKUTCvn90xVTq0wLuzM/usIi9eMPBXKFzJ7kQqmcQkw6gFO5m85hBd65bgw7vr6b3yyiNcioln2Z7TLNoezvI9p4iMSyQ4jw/tHD3fW1ctotMr5wA60I07C6kC/efB5Dut2+gG/goFy9udSjl4ewlvdKtJifz+vLtwN6cvxfLVg42zdbAKpbLKmcuxLNlp9Xxfs/8scYlJhATlIbR+KTrXLk6zioXx89Ge755Cz+DdRfg2mNzVGhhnwK9QoIzdiVQqczcf46UZW6gQkpfJA5tSsoBeh1Tu7+i5KBbtCGfxjpNsOHyOJANlCgVc7fneoGzBbB07XWUtbaLPKY5tgqndIW+IVeTzlbA7kUpl9f4zPP7tRvLm8WHyQ02oXjyf3ZGUSsEYw96Tl69O5LLj+EUAqhcPppOjqNcoEay3s3kILfA5ydG/rbHr85WEAb9AUFG7E6lUdp24yIBJfxMVm8iEBxvRvFLWTRyh1I1ISjJsDrtw9R71Q2etiVwali1Ip1rF6FSrOOUK57U7pnIBLfA5zaHV8F0f61p8/wWQVwdbcTfHLkQz4Ju/OXw2ig/urkdoPb1XXmWv+MQk1h08x287TrBk50lOXozFx0toVqmwdTtbzWIUzedvd0zlYlrgc6KDy+H7exyd8OZDQEG7E6lUIqLieWTqBv4+dI5hd9Tg4ZYVtNlTuVR0XCIr9p5m8Y5wft99iojoeAJ8vWldtQidahejXbVi5A/UDqC5iRb4nGrfUvixLxSrDQ/OAf/8didSqcTEJzL4p838ui2cgbeVZ8SdNfVeeZWlIqLi+X231fN9xd7TxMRbU462r1GUzrWK07JKEQL89NbN3Epvk8upqtwOd0+1ppn97i5r2tk8OgGKO/H39ebzvg0ZlW8nk1Yf4uTFGMbdXV9nzlI3befxi4z5bTer958hIclQLF8e7m5chk61itO0QiF8dSIXlQkt8O6uWhfo8w3MGAjf3wv3zwC/QLtTqWS8vIQ3utWiVIEA3v5lF2cu/c3EBxtrU6m6IZGxCXy8dC/frD5EgQBfHm5ZkU61ilGvdAFtHVLXRZvoc4ptM2HWw1CxNfSdDr7aecYdzdtynBd/2kz5wnmZ/FBTSum98uo6LN15ktfnbud4RAx9m5ZhaOfqFAjUIWLVtWXURK9tPDlFnT7QfbzV+e6nfpAQa3cilY7QeiWZ8lBTwi/G0Ov/VrPTcQ+yUhk5ERHNY99u4OGpGwj292Xm4814t1ddLe7qpmiBz0ka3A9dP4Z9i60m+8R4uxOpdDSvFMKMx5shCHdP+IvV+8/YHUm5qYTEJL5e9S+3f7iCFXtPM7RzdRY824LG5QvZHU15AC3wOU3jgdBlLOz5xWqyT0ywO5FKR/Xi+fj5yeaULODPgEl/M3fzMbsjKTezNewC3cevZtSCnTSpUIglL7TmiTaVtPOcyjLayS4nuuVRSIyFxcPB2w96fgle2mvb3ZQsEMCMx5vz6NQNPPfjZk5ExPBYq4p6r3wudykmng8X72XqX4cICcrD+Psacked4vrfhcpyWuBzqubPWNfh/xhlFfnQz8BLj/zdTf4AX6YOasrgn7bw3sLdhEfEMKJrTZ3cIxcyxrBwezhvzt/BqUuxPHhrOV7sVI18/nq3hXINLfA5WauXIDEOVowBHz+4cxzoWYDbyePjzWf3NqBEPn/+t+pfwiNi+PhevVc+Nzl6LorX525n2Z7T1CyRjwn9GlO/TAG7YykPpwU+p2vzKiTEwOpPwDsPdH5Xi7wb8vIShnetSYkCAbz9y04e+N86/te/sfaS9nDxjk50Hy/di5cIw++swYDm5fHR6+wqG2iBz+lE4PY3ISEO1n1hncnf/qYWeTc1qEUFiuXLw+DpW+j9xRqmPNSU0gV14CJPtPHweYbN3sbu8Et0qFmMkaG1dFwEla20wHsCEevMPTHuvzP5dsPsTqWuoWvdkoQE5eHRqRvo+X9rmDywCbVK6jwDniIiKp4xi3bz/bojlMjvz1f9GtGxVnG7Y6lcyKXtRCLSWUT2iMh+EXklnffLicjvIrJVRJaLSOlk770vIjtEZJeIfCraxTRjInDHB9CgH6x8H1aOtTuRysCtFQsz84nm+HgJ90xYy5/7TtsdSd0kYwxzNx+j/bjl/Pj3EQa1qMCSwa21uCvbuKzAi4g3MB7oAtQE+opIzVSrfQBMNcbUBd4C3nV8tjlwG1AXqA00AVq7KqvH8PKCbp9A3Xvhj7dh9ad2J1IZqFosmJ+fbE7pggEMnLSenzeF2R1J3aBDZyJ58Ju/ee7HzZQqEMC8p1swomtNgvJoI6myjyv/62sK7DfGHAQQkR+B7sDOZOvUBAY7ni8D5jieG8Af8AME8AVOujCr5/Dytoa0TYyFJSOsW+hufdzuVOoaSuQP4KfHm/HY1I0M/mkLJyJieLJNJb0nOoeITUjkqxUH+WzZfvJ4e/FW91rcf0s5vQ1SuQVXFvhSwNFkr8OAW1KtswXoBXwC9ASCRaSwMeYvEVkGnMAq8J8bY3a5MKtn8faBXhOtoWx/G2p1vGv8kN2p1DXk8/dl8kNNeHnGVsYu2kN4RAwjQ2tpkXBzaw+eZdjsbRw4HcmddUrwereaFMunk0Ap92F3+9FLwOciMgBYCRwDEkWkMlADuHJNfomItDTG/Jn8wyLyKPAoQNmyZbMtdI7g7WtNMzv9AVjwgtXxrsH9dqdS15DHx5uP76lPifz+TFh5kJMXY/i0bwO9V94NnYuM491fdzFjYxilCwYwaWAT2lYrancspdJwZSe7Y0CZZK9LO5ZdZYw5bozpZYxpAAxzLLuAdTa/1hhz2RhzGVgINEu9AWPMV8aYxsaYxkWKFHHRbuRgPnng7m+hYluY+xRsnWF3IpUBLy/h1Ttq8Ea3mizZdZL7Jq7lfGSc3bGUgzGGGRuO0v7D5cz+5xhPtKnEkhdaa3FXbsuVBX49UEVEKoiIH3AvMC/5CiISIiJXMrwKfON4fgRoLSI+IuKL1cFOm+hvhK8/3Ps9lG8Bsx+DHXPsTqQyMfC2CvzffQ3Zfvwivb9cw9FzUXZHyvX2n7rMvV+t5eWZW6lYJIhfnm3J0M7VCfDTFhblvlxW4I0xCcDTwCKs4vyTMWaHiLwlIqGO1doAe0RkL1AMeMexfCZwANiGdZ1+izFmvquyejy/QOj7I5RuArMGwe5f7E6kMtGlTgmmDbqFM5di6fl/a9h+LMLuSLlSTHwi4xbvocsnK9l14iLv9qrDjMeaUa14sN3RVE4SfR62z4LZj8OZ/dm2WTHGZNvGXKlx48Zmw4YNdsdwbzEX4dsecGIr9P0BqnSwO5HKxL6TlxgwaT0XouL4vwca0bqqXorKLqv2nWH4nG0cOhtFzwalGHZnDUKC8tgdS+UExkD4Vti3GPYthbC/wSRBQEHoOQGqdsqyTYnIRmNM43Tf0wKfy0SfhymhcHoP3DcdKrW1O5HKxMmLMfT/5m/2n7rMe73r0qdR6cw/pG7Y6UuxvPPLTuZsPk75woG83aMOLaqE2B1LubuYCDiwDPYtgf1L4XK4tbxEfajS0TqhKtUoy6f21gKvUoo8C1O6wbmD8MAsKH+b3YlUJi7FxPP4tI2s3n+WlzpW5am2lfVe+SyWlGT4cf1R3lu4i5j4JB5vU4kn21TSOxlU+oyBkzuss/T9S+HIWjCJ4J8fKrWzinql9hBczKUxtMCrtC6fhsl3QMQx6Ps9VGxjdyKVibiEJIbM3MKczce575ayvBVaS2clyyK7wy8ybPZ2Nh4+zy0VCvFOzzpULhpkdyzlbmIuwr8r/mt6v3TcWl68jlXQK3ew+jp5Z98d6BkVeLvvg1d2CSoC/edbzfXf9oS2w6DFYGu4W+WW/Hy8GHd3fYrnD+DLFQc4dTGGz/o21J7cNyE6LpFPft/H//48SLC/Dx/cVY/eDUtp64iyGAOndzsK+hI48hckJUCefNblzcodoPLtkK+E3UnTpWfwuV3sJZj/nNXDs0pHqwNIYCG7U6lMTP3rEG/M20G90gX4un9jCmvnr+u2bPcpRszdTtj5aO5uXJpXu9SgYF4/u2Mpu8VedpylL7EeFx1zRBSrbRXzKh2hTFNrMDE3oE30KmPGwPr/wW+vQnBxuGsKlG5kdyqVid+2h/Pcj/9QskAAUwY2pWxhnVfeGScvxvDm/B38ui2cykWDeKdHbW6pWNjuWMouxsCZfY5r6Uvg8Bpr6m2/IOvSZZUO1pl6/lJ2J02XFnjlnLCNMKM/XAq35pdv8rA1Da1yWxsOnWPQlA34egvfDGhC3dIF7I7kthKTDNPWHmbsoj3EJSbxbLvKPNqqEn4+elkq14mLhH//tAr6vsVw4Yi1vEgNqHLlLP1Wax4PN6cFXjkv6pw14t2+xVC7tzX9bB4d1MOd7T91mf7f/M35qDjG399Qh05Nx/ZjEQybvY0tYRG0rBLCqO61KR+S1+5YKjudPeC4lr4YDq22Ztz0DUx2ln47FMh5c5pogVfXJykJVn9kzSlfqBLc8y0UrWF3KpWBUxdjGDBpPXtOXqJ+mQKULhhAqQIBlC4YSOmCAZQuGEDJAgG57pavy7EJjFu8l8lr/qVQ3jyM6FqD0HoltRNdbhAfDYdWOa6lL4bz/1rLQ6paTe5VOkC55tacHTmYFnh1Y/5dCTMHQdxl6PoR1LvX7kQqA5djE/hw8R52n7hE2IUojl+IITEp5f+/iwbnoVTBlIW/dMFAx8GAZx0ALNoRzsh5OzgREcP9t5RlSOfq5A9wj45RykXOHbRuX9u3GA79CQkx4BMAFVpZBb1KByhY3u6UWUoLvLpxl8Jh5kNweDU0GgCdx1gT2Ci3l5CYxMlLsYSdi+LYhWjCzkcTdj7K8W80xy9Ek5DqACAkKE/Kwu94XqZgAKUKBOaIW/KOXYjmjbk7WLrrJNWLB/NOzzo0KlfQ7ljKFeJjrL9N+5ZY19PPOsZ5L1Tpv4JeroVH/83SAq9uTmIC/DEKVn8MxevC3VOhUAW7U6mblJhkOHUp5r/Cf84q/NbBgHVQEJ+Y+gDAL03T/5XnpQoGEOhn39AaCYlJTF5ziHFL9mIMPH97FR5qUQFfHQzIs5w/7Ogct8RqZYyPAh9/a8bMKh2ta+mFK9mdMttogVdZY89CqwOeAXp+AdXvtDuRcqGkJMOpS7FXz/qvFP4rLQDHzkcTl5iU4jOF8vqlLfwF/msNCMrjmgOAzUcv8NrP29h54iLtqhflzdBalCmktw16hIRYa4CZK/eln9ljLS9Y/r/R48q3sGbNzIW0wKusc/4Q/NQfTmyG5s9C+9fdZsAHlb2SkgynL8emafq/cvYfdj6auISUBwAFA31TXPO/eiBQyDoQCPa/vv+WLsbE88GiPXy79jBFg/MwslstOtcurp3ocrqIsP8K+sHlEB8J3n5WIb/SQa5wZb2NFy3wKqvFx8Ci12DD11C2GfSZ5LZDNSr7JCUZzkTGpiz851P2BYhNdQCQP8D3mi0ApQsFkM9xAGCM4ZdtJ3hr/k7OXI7lwWblebFj1es+QFBuIjHemqzlysQtp3Zay/OXdVxL7wgVWoKf3tqYmhZ45RpbZ8D8Z63/0/X+n05Yo66LMYYzl+NSnPGnbgmIiU95AJDP34fSBQPx8Ra2hkVQu1Q+RvesowP85GSH/4If74Poc+Dla926dqWoh1TVs/RMaIFXrnNqN/z0IJzdB21eg5Yv6oQ1KksYYzgXGZei4F/pC3Dmciw96pfiwWbldEa9nOzIWpjW2xoiu8Nb1u1sOrDWddHZ5JTrFK0Oj/wBC56HZW/D0XXQ6yudsEbdNBGhcFAeCgfloV6ZAnbHUVnt6N8wrQ8EFYP+C/Qynwvooa+6eXmCoNdEuHOcNQvTly0hTFtTlFLXcHQ9fNvLmrZ6gBZ3V9ECr7KGCDQZBA8tsprov+kM6yZYMzUppdQVYRthWi/IG+I4cy9pdyKPpQVeZa1SDeGxlVC5PSwcAjMGQMxFu1MppdzBsU3wbU/rEt6ABW47Baun0AKvsl5AQbj3B7h9JOyaBxPbwskddqdSStnp+D/wbQ8IKGCduecvbXcij6cFPhc7H3OeV/98lXUn1mX9l3t5QYsX4MF51hn8xPaw+fus345Syv0d3wxTe0Ce/NaZe4EydifKFbTA51LhkeH0/60/Cw4u4KUVLxEeGe6aDVVoCY//CaUawZwnYN4z1jSOSqnc4cRWmNrduv1twPwcOed6TqUFPhc6FHGIBxc+yOmo07zV/C1iE2N55c9XSExKdM0Gg4vDg3OhxWDYNBW+7mBN66iU8mzh22BqKPgFQf/5HjdVq7vTAp/L7D63m/6/9Sc2MZavO31Nzyo9GX7rcDae3MhXW79y3Ya9feD2N6DvdLhwFCa0hl3zXbc9pZS9wrfDlFDwDbTO3HUGymynBT4X2XRyEwN/G4iftx+TO0+mZuGaAIRWCqVbxW58ufVL1oevd22Iap2tXvaFK8H0B2DRMGscaqWU5zi50zpz9/G3ztwLVbQ7Ua6kBT6XWBm2kseWPEZIQAhTO0+lQv6UR9PDbx1OmeAyvLLyFc7HnHdtmILlrPvlmzwMf30Ok7vCxeOu3aZSKnuc2gVTulnjyg9YkKvmZnc3WuBzgV8P/spzfzxHhfwVmNx5MiWC0o4aFegbyNhWYzkfe57hq4fj8jkKfPLAnR9C76+t63RftoQDy1y7TaWUa53a7SjuPlrc3UCmBV5EfEXkWRGZ6Xg8IyI6J2MOMX33dF758xXqFa3HN52+oXBA4WuuW6NwDV5s/CIrw1by7c5vsydgnT7w6DJrVKtve8LyMZCUlPnnlFLu5fReq7gjVrN8SBW7E+V6zpzBfwE0Av7P8WjoWKbcmDGGiVsn8va6t2lVuhVf3v4lQX5BmX7uvur30bZMWz7a9BE7zmTT4DRFqlkT1tS5C5aPhu/6QOTZ7Nm2UurmndkHU7oCxjpzL1LV7kQKJ6aLFZEtxph6mS2zm04X+x9jDB9u+JApO6dwZ8U7GXXbKHy9nG90iYiNoM/8Pvh6+fJT15+cOjDIEsbAxkmwcCjkLQJ3TYYyTbNn20qpG3NmP0y+E5ISYMAv1gyTKttkNF2sM2fwiSJy9UKKiFQEXHTDtLpZCUkJvLHmDabsnELf6n0Z3WL0dRV3gPx58jOm5RiOXz7OW2vfcv31+CtEoPFDMGixdQ1vUhdY+4VOWKOUuzp7wDpzT0qwmuW1uLsVZwr8y8AyEVkuIiuAP4AXXRtL3Yi4xDheXvEys/fP5vF6j/Nq01fxkhvrR9mwWEOerP8kC/9dyJz9c7I2aGZKNoDHVkCVjvDbKzCjv05Yo5S7OXfQugMmMQ76z4NiNe1OpFLJtIkeQETyANUcL/cYY2JdmuoG5PYm+qj4KJ5b9hxrT6xlSJMh9KvZ76a/MzEpkceWPMaW01uY3nU6FQtk872sxsCaT2Hpm9YIWHdPheK1szeDUiqtc/9axT0+yiruxevYnSjXuqEmehFp5/i3F3AnUNnxuNOxTLmJiNgIHln8COvD1/P2bW9nSXEH8Pby5t2W7xLoG8iLK14kJiEmS77XaSJw23NW019cJPyvPfzzXfZmUEqldP6Q1Vs+PtIaglqLu9vKqP22tePfbuk8uro4l3LSqahTDPhtALvO7eLDNh/SvXL3LP3+IoFFeKfFO+y/sJ+x68dm6Xc7rfxt1oQ1pZvA3Cdh7lM6YY1Sdjh/GCZ3g9hLVnEvUdfuRCoDPtd6wxjzhuPpW8aYf5O/JyI6qLAbOHrxKI8seYTzMef54vYvuKXELS7ZTotSLRhYayCTdkzilhK30LF8R5dsJ0NBRa0/KMtGw58fwPEtcPcUHUhDqexy4ajVoS42wlHc3epGKpUOZ3pgzUpn2cysDqKuz97ze3nwtwe5HH+Z/3X8n8uK+xXPNHiGOiF1GLlmJGGXwly6rWvy8ob2I+C+GXAxDL5qAzvn2ZNFqdwkIsy6FS46AvrNsTrCKreX0TX46iLSG8gvIr2SPQYA/tmWUKWx+dRmBvw2AC/xYkrnKdQp4vprYL7evrzf6n0MhqErhxKfZOMEMVU7WhPWhFSBn/rBb6/phDVKuUrEMUdxPw8PzoZSDe1OpJyU0Rl8Naxr7QVIef29IfCIy5OpdK05toZHlzxKwTwFmdplKpUKZF8Tdeng0oxsPpKtZ7by+T+fZ9t201WgLAz8DZo+BmvHW3+AIo7Zm0kpT3PxuNUsH3kW+s2GUo3sTqSuQ0bX4OcCc0WkmTHmr2zMpK5h8aHFDP1zKBXzV2RChwmEBIRke4ZO5Tux7sQ6vtn+DU2LN+W2Urdle4arfPzgjveh7C0w71mY0BJ6TYTK7e3LpJSnuHjCuhXu8mno9zOUTvdOLOXGnBmq1h8YBNQiWdO8MeYh10a7Pp5+H/zP+37mzb/epG5IXcbfPp58fvlsyxKTEEPfX/pyLuYcM7vNpEhgEduyXHVmH0zvB6d3Q+uh0HqIdc1eKXX9LoVbrWKXwuGBn62DaOWWbnao2m+B4kAnYAVQGrjk5IY7i8geEdkvIq+k8345EfldRLY6Rsorney9siKyWER2ichOESnvzDY90aTtk3hjzRs0K9mMCR0m2FrcAfx9/Pmg9QdExUfx6qpXSTJuMPtbSBV45Heoew+seA+m9YbIM3anUirnuXTSus/94gm4f6YW9xzMmQJf2RgzAog0xkzBGvQm019cRLyB8UAXoCbQV0RSj2X4ATDVGFMXeAt4N9l7U4GxxpgaQFPglBNZPYoxho83fsy4jePoXL4zn7X9jEDfQLtjAVCpQCVeveVV1p1Yx9fbvrY7jsUvL/T8Erp9AofXWHPMH1lndyqlco7Lp6ziHnEMHpgJ5ZrZnUjdBGcK/JXuyRdEpDaQHyjqxOeaAvuNMQeNMXHAj0DqUVhqYo1tD7DsyvuOAwEfY8wSAGPMZWNMlBPb9BiJSYmMWjuKr7d/zV1V7+K9lu/h6319k8a4Ws/KPelSvgvjN4/nn1P/2B3HIgKNBsDDS6xr9JPvgL/G64Q1SmXm8mlHcT8K9/8E5ZrbnUjdJGcK/FciUhAYDswDdgJjnPhcKeBostdhjmXJbQGuDHvbEwgWkcJAVawDip9F5B8RGetoEUhBRB4VkQ0isuH06dNORMoZ4hPjeeXPV5ixdwaDag9ixK0j8HbD68kiwuvNXqdE3hIMXTmUiNgIuyP9p0Q9eHQFVO0Mi16zbqfTCWuUSl/kGau4nz8M9/0E5VvYnUhlgQwLvIh4AReNMeeNMSuNMRWNMUWNMROyaPsvAa1F5B+soXGPYU1F6wO0dLzfBKgIDEj9YWPMV8aYxsaYxkWKuEFHrywQnRDNM8ue4bdDvzG40WCeb/Q8ImJ3rGsK8gvig9YfcDr6NK+vfj37ppZ1RkABuGcadHwbdv8Kc57QM3mlUos8C1NC4fy/cN90qNDS7kQqi2RY4I0xScCQG/zuY0CZZK9LO5Yl//7jxphexpgGwDDHsgtYZ/ubHc37CcAcrPvvPdrFuIs8tuQx/jr+FyObjWRg7YF2R3JKrZBaPN/wef44+gc/7vnR7jgpiUDzZ6DjKNi9ANZl1bGpUh4g6hxMDYVzB6Dvj1CxdeafUTmGM030S0XkJREpIyKFrjyc+Nx6oIqIVBARP+BerCb+q0QkxNFKAPAq8E2yzxYQkSun5e2wLg14rDPRZ3jot4fYdmYbY1uNpXfV3nZHui79avajZamWjF0/lt3ndtsdJ61bn7Sa6xcPh2Ob7E6jlP2uFPcz++De76FSW7sTqSzmTIG/B3gKWAlsdDwyveHcceb9NLAI2AX8ZIzZISJviUioY7U2wB4R2QsUA95xfDYRq3n+dxHZBggw8Tr2K0c5dvkY/Rf258ilI4xvN96eyVxukpd48XaLtymYpyAvr3iZqHg36xMpAj2+gKBiMHMgxLhRfwGlslvUOZjaHU7vhb7f6+BQHirTgW5yipw60M2BCwd4dPGjRCdG83/t/4/6RevbHemmrA9fz6BFg+hWqRvvtHjH7jhpHVkLk+6AmqHQZ5JV+JXKTaLPw9QecGqndeZepYPdidRNuNmBbpSLbD+znf6/9SeJJCZ3npzjiztAk+JNeKzeY8w7MI/5B+bbHSetsrdCu+GwYzZsnGR3GqWyV/QF+LanVdzv+U6Lu4fTAm+Tv0/8zaBFgwjyDWJq56lULVjV7khZ5rG6j9GoWCNGrR3FoYhDdsdJ67bnoVI7WPgKhG+3O41S2SMmAqb1sv6bv/tba1ZG5dG0wNvg9yO/88TSJygZVJKpXaZSJl+ZzD+Ug/h4+fBey/fw8/bj5ZUvE5cYZ3eklLy8oOdXEFAQZgyA2Mt2J1LKtWIuwre94MRWuHsqVOtsdyKVDTIt8GJ5QERed7wuKyJNXR/NM83dP5fBywdTvVB1JneeTNFAZwYFzHmK5y3O27e9ze5zuxm3cZzdcdIKKgK9/2fdHvTrS3anUcp1Yi9ZczOc2Ax3TYbqd9idSGUTZ87g/w9oBvR1vL6ENca8uk7Tdk5j+OrhNC3elIkdJ5I/T367I7lUmzJteKDGA3y36zv+OPJH5h/IbhVaWjPPbfkBNn9vdxqlsl7sJZjWB45ttDqV1uhqdyKVjZwp8LcYY54CYgCMMecBP5em8jDGGMZvHs+Y9WO4veztjG8/3m0mjXG1Fxq9QI1CNRixegThkeF2x0mr1ctQviX88iKccsP795W6UbGX4bu7IGw99PnGunNE5SpOTTbjGAfeADgGn3GD+UFzhiSTxLt/v8uXW76kR+UejG09Fj/v3HN85Oftx9jWY0lISmDoyqEkJCXYHSklL2/oNRF8A6374+Pc7P59pW7EleJ+9G/o8zXU6mF3ImUDZwr8p8BsoKiIvAOsAka7NJWHiE+K57VVr/HD7h/oX7M/bzV/Cx8vH7tjZbty+crxerPX2XRqE19s+cLuOGnlKwG9vrJuHfrtFbvTKHVz4iLh+3vg6FroPRFq9bQ7kbJJptXGGPOdiGwE2mONKNfDGLPL5clyuJiEGF5a8RIrwlbwbINnebjOw249aYyr3VnxTtaeWMvErRNpWrwpt5S4xe5IKVVuDy0Gw6pxUKEV1OljdyKlrl9clFXcj6yxWqZq56whr1XWcqYX/adAIWPMeGPM51rcM3c57jJPLH2ClWErGX7LcB6p+0iuLu5XvNr0VcrnL88rf77C2eizdsdJq+0wKHMrzH8Ozh6wO41S1ycuCn64Bw6vhp4T9CBVOdVEvxEYLiIHROQDEUl3SDxlORdzjocWPcTmU5t5r+V73FP9HrsjuY1A30DGthrLxdiLDFs9jCTjZl05vH2s65XevjCjP8TH2J1IKefER8OPfeHfP605F+rebXci5QYyLfDGmCnGmDuw5mXfA4wRkX0uT5YDnbh8gv4L+3Mw4iCftPuEOyrq/aapVStUjSFNhrD62Gqm7phqd5y08pe2/kCGb4MlI+xOo1Tm4mPgx/vg4Aro8X9Q7167Eyk3cT0j2VUGqgPlAL2fKJV/I/7lwd8e5Ez0GSZ0mECr0q3sjuS27q52Nx3KdeCTTZ+w9fRWu+OkVa0LNHsa/v4Kds7LfH2l7BIfA9PvhwPLoPvnUP8+uxMpN+LMNfj3HWfsbwHbgcbGmG4uT5aD7Dy7kwG/DSAuMY5vOn1Do2KN7I7k1kSEN5q9QdHAogxZOYSLcRftjpRW+zegZEOY+zScP2R3GqXSSoiFn/rB/qUQ+ik0eMDuRMrNOHMGfwBoZozpbIyZZIy54OJMOcqG8A0MWjSIPN55mNJ5CjUK17A7Uo6QP09+xrQaQ3hkOG+ueRO3m7bYxw/ucsw2N/MhSHCz8fRV7pYQC9P7wb7F0O0TaPig3YmUG7pmgReR6o6n64GyItIw+SN74rm3lWEreXzp4xQJLMLULlMpn7+83ZFylPpF6/NMg2dYfHgxM/fNtDtOWgXLQ/fPrGE+f3/T7jRKWRLi4Kf+sG8RdP0IGg2wO5FyUxndBz8YeBT4MJ33DNDOJYlyiF8O/sLwVcOpWqgqX97+JQX9C9odKUcaWHsg606sY8zfY6hfpD5VClaxO1JKNbtDk0fgr8+tIW11Fi5lp4Q4awbEvQvhzg+h8UN2J1JuTDJrGhURf2NMTGbL7Na4cWOzYcOGbNnWj7t/ZPS60TQq1ojP2n1GkF9QtmzXU52JPkOfeX0okKcAP3T9gQCfALsjpRQfA1/fDhFh8PhqyF/K7kQqN0qMt4r77gVwxwfQ9BG7Eyk3ICIbjTHp3r7uzDX4NU4u83jGGCZsmcA7696hdenWfHH7F1rcs0BIQAjvtnyXgxEHGfP3GLvjpOXrD30mW39gZw2CRDcbT195vsR4qy/I7gXQ5X0t7sopGV2DLy4ijYAAEWmQ7Pp7GyB3TIWWTJJJYuyGsXy++XO6VezGuLbj8PfxtzuWx2hWshmD6gxi1r5ZLPx3od1x0gqpDF0/hiN/wXKdikFloysHlrvmQad34ZbH7E6kcoiMrsF3AgYApYFxyZZfAl5zYSa3k5CUwMg1I5l7YC73Vb+PoU2H4iXXM4SAcsaT9Z9kffh63vzrTWqH1KZMcBm7I6VU9y44tBL+HAflbrPGr1fKlRIT4OdHYOdc6DQamj1pdyKVgzhzDb63MWZWNuW5Ya66Bh+bGMvQlUP5/cjvPFnvSR6v97iOK+9Cxy8fp8/8PpQNLsu3Xb7F19vX7kgpxUXBxHYQdQYeXwXBxe1OpDxVQhzMeQK2z4QOo+C2Z+1OpNzQDV2DF5EroyaUF5HBqR8uSepmIuMjeWrpU/x+5HeGNhnKE/Wf0OLuYiWDSvJW87fYcXYHn2z6xO44afkFwl2Trfm2Zz0MSYl2J1Ke6PJp+LaHVdxvf1OLu7ohGbUz53X8GwQEp3p4fM+yCzEXeHjRw2w4uYF3WrzDAzV1lKjscnu527mn2j1M2TmFlWEr7Y6TVtHqcOcHcOhPWPmB3WmUpzmxBSa2tcZf6P01tHje7kQqh3Kmif42Y8zqzJbZLSub6M9Gn2XQokEcvXSUD1p/QNuybbPke5XzYhNjue+X+zgddZoZ3WZQLG8xuyOlZAzMfhy2/QQPzoMKLe1OpDzBtpnW8MiBheDe76BkA7sTKTd3s7fJfebkMo+Rzy8fVQpW4Yvbv9DibpM83nkY23osMYkxvLrqVRLdrSlcxBpopFBFq6k+8ozdiVROlpQIS0daveVL1odHl2txVzcto2vwzUTkRaBIquvvIwHvbEtoA19vX8a2HkvTEk3tjpKrVcxfkddueY314euZuG2i3XHSyhNkXY+PPg+zH4MkN5vfXuUMMRHww72w6iNoNNBqEQoqancq5QEyOoP3w7rW7kPK6+8XgT6uj6YUdK/Una4Vu/LFli/YEJ49IxVel+J1oPO71oxea9ywU6Byb2f2wcT2cOAPuHMcdPvYmuhIqSzgzDX4csaYwyISaIyJyqZc1y07h6pV2SsyPpK7599NTGIMs7rNooB/AbsjpWQMzBxozR0/cCGUvcXuRCon2LvYapL39oO7p0L52+xOpHKgm70GX1JEdgK7HV9WT0T+LysDKpWRvL55Gdt6LOdjzjNi9Qj3m1pWxJqys0AZazjRqHN2J1LuzBirOf77u60ZCx9drsVduYQzBf5jrFHtzgIYY7YArVyYSak0ahauyYuNX2R52HK+2/Wd3XHS8s8PfSbB5ZMw9ynrj7hSqcVFWWftS0dC7V7w0CLrwFApF3BqvFVjzNFUi9ysS7PKDe6rfh9tSrfhw40fsuPsDrvjpFWqIXQcBXt+hbVf2J1GuZsLR+GbTrD9Z7h9pHWPu1+um9ZDZSNnCvxREWkOGBHxFZGXgF0uzqVUGiLCqNtGUdi/MENWDCEyPtLuSGnd8jhUuxOWvG4NVKIUwKHV8FUbOH8I7vsJWrxgXdpRyoWcKfCPA08BpYDjQH3Ha6WyXQH/AoxpNYawy2GMWjvKPa/Hd//cGqN+xkDrFiiVu63/GqaGQkBBeOQPqNrR7kQql8i0wBtjzhhj7jfGFDPGFDHGPGCMOZsd4ZRKT6NijXii3hP8cvAX5h6Ya3ectAILQZ9vICIM5j2j1+Nzq4Q4mP88/DIYKrWDR36HkCp2p1K5SKYFXkQqish8ETktIqdEZK6IVMyOcEpdyyN1HqFp8aaMXjeagxEH7Y6TVpmm0P51a5rPDd/YnUZlt8unrLP2jZOgxWDo+6PVEVOpbORME/33wE9ACaAkMAP4wZWhlMqMt5c377Z8F39vf15e8TIxCTF2R0qr+bNQuQP89iqc2Gp3GpVdjm+Gr9pa//b+Gm5/A7w8evBP5aacKfCBxphvjTEJjsc0wN/VwZTKTNHAorzd4m32nt/LBxvccFY3Ly/o+aXVZD9zIMResjuRcrVtM62e8iIwaBHU0UE/lX2cKfALReQVESkvIuVEZAjwq4gUEpFCrg6oVEZalW5F/5r9mb5nOksPL7U7Tlp5Q6D3/+DcQVgwWK/He6qkROvOiVmDoGRDeGQZlKhndyqVyzkzVO2/GbxtjDFucT1eh6rNveIT43lw4YMcvnSYGd1mUCqolN2R0lrxPix7B7qPhwYP2J1GZaXoC1Zh378UGg+Czu/pePIq29zUULXGmAoZPNyiuKvczdfbl/dbv48xhqErhxKfFG93pLRavggVWsEvL8EpHUbCY5zeCxPbwcHl0PUj6DpOi7tyG870ovcWkVAReTb5tLHZEU4pZ5UJLsMbzd5gy+kt/N9mN5wqwcsbev3PmmJ2xgBryFKVs+35Df7XHmIvQv8F0PghuxMplYIz1+DnAwOAwqScNjZTItJZRPaIyH4ReSWd98uJyO8islVElotI6VTv5xORMBH53Jntqdytc4XO9K7Sm6+3fc2a42vsjpNWcDHoNRFO74GFQ+xOo26UMbDyA2sO90IVrMliyjWzO5VSafg4sU5pY0zd6/1iEfEGxgMdgDBgvYjMM8bsTLbaB8BUY8wUEWkHvAv0S/b+KGDl9W5b5V5Dmw5ly+ktvPrnq8wKnUVIQIjdkVKq1NZqrv/zA6vJvu7ddidS1yMu0ppMaMdsqHMXdPtUx5NXbsvZXvQ3MrZiU2C/MeagMSYO+BHonmqdmsAfjufLkr8vIo2AYsDiG9i2yqUCfAIY22osUfFRvPbnaySZJLsjpdXmVSjbHBa8AGf2251GOevCEesWuB1zoMNbVmuMFnflxpwp8GuB2SISLSIXReSSiFx04nOlgOSz0IU5liW3BejleN4TCBaRwiLiBXwIvJTRBkTkURHZICIbTp8+7UQklRtULliZoU2H8teJv/hmuxuOIuftY9065+1nXY+Pd8NBelRKh1Y5Jos5AvfPgNue08lilNtzpsCPA5phDXiTzxgTbIzJl0XbfwloLSL/AK2BY1hT0T4J/GqMCcvow8aYr4wxjY0xjYsUKZJFkZQn6F2lN53Kd+Lzfz5n86nNdsdJK38paxCck9tg8TC706hrMQb+nghTu0NgYWuymCod7E6llFOcmi4W2G6uf9quY0CZZK9LO5ZdZYw5bozpZYxpAAxzLLuAdUDxtIgcwrpO/6CIvHed21e5mIjwRrM3KJ63OENXDiUi1g1ndavaCZo/A+v/ZzX7KveSEAfzn4NfX4JK7eHhpRBS2e5USjnNmQJ/EFguIq9e521y64EqIlJBRPyAe4F5yVcQkRBHczzAq8A3AI7Z68oaY8pjneVPNcak6YWvVEaC/YIZ22osp6JOMXLNSPebWhag/RtQqrE169y5jMaUUtnq8imY0g02TbE6Rfb9QSeLUTmOMwX+X+B3wI/ruE3OGJMAPA0sAnYBPxljdojIWyIS6litDbBHRPZidah757r3QKkM1ClSh+caPsfSI0v5fvf3dsdJy9vXmlpWBGY+ZJ01Knsd22Rdbz+xxfpt2r+uk8WoHCnToWqvrigSBGCMuezSRDdIh6pV15Jkknjuj+dYdWwVX3f6mobFGtodKa1d82H6A3DrU9B5tN1pcq8t02H+s5C3KNz7HZS47juElcpWNzVUrYjUdnSC2wHsEJGNIlIrq0Mq5Spe4sXolqMpFVyKF1e8yKmoU3ZHSqtGN2j6GKwdD7t/tTtN7pOUCIuHw+xHrUsmjy7T4q5yPGea6L8CBhtjyhljygEvAhNdG0uprBXsF8zHbT4mMj6SF5e/SHyiG45X33GUNQPZnCfgwtHM11dZI/o8fHcXrPkMmjwCD86xZgFUKodzpsDnNcYsu/LCGLMcyOuyREq5SOWClRl12yg2n97MmPVj7I6Tlk8e6DPJOpucNQjc8SDE05zabU0W8+9K6PYJ3PmB1S9CKQ/gVC96ERnhmA++vIgMx+pZr1SO06l8JwbWGsj0PdOZs3+O3XHSKlwJun0MR9dZ08sq19mzEP53O8RehgELoNEAuxMplaWcKfAPAUWAn4FZQIhjmVI50rMNn+WWErcw6q9R7Di7w+44adXpYxWbVR9Zc4yrrGUMrBwLP/S1DqgeXQZlb7U7lVJZzule9O5Oe9Gr63Eu5hz3LrgXgB+7/kgh/0I2J0olPtpqOr58Ch5fBflK2J3IM8RehrlPws65UOduCP0UfAPsTqXUDbvZXvRLRKRAstcFRWRRFuZTKtsV8i/ER20/4mz0WYasHEJCUoLdkVLyDYC7JkN8FPz8iHVdXt2c84esyWJ2zYcOo6DXV1rclUdzpok+xDF8LADGmPNAUZclUiqb1CpcixHNRrDuxDo+/edTu+OkVaQa3DkODv0JK963O03O9u9K+KotRBx1TBbzrE4WozyeMwU+SUTKXnkhIuUAz2jXV7lej8o9uKfaPUzaPolFh9ywYap+X6h3H6wYAwdX2J0m5zEG1k2AqT0gbxF4ZBlUvt3uVEplC2cK/DBglYh8KyLTgJVY48Yr5RGGNhlKvSL1GLF6BPvPu+H87HeMhZAqVlP9ZZ0W2WkJsTDvaVg4BKp0tCaLKVzJ7lRKZZtMC7wx5jegITAd+BFoZIxxw1MdpW6Mr7cv49qMI9AnkOeXP8/FuIt2R0opT5B1PT4mwhppLSnJ7kTu71I4TO4K/0yDVi/Dvd+Df1bNcq1UzuDMGTzGmDPGmAWOxxlXh1IquxUNLMq4NuM4dukYw/4cRpJxsyJarBZ0GQMH/oDVH9mdxr0d22hdbz+53TowajccvJz6U6eUR9H/6pVyaFisIS83eZnlYcuZsHWC3XHSatgfaveGP96Bw3/ZncY9bf4BvukC3j4waDHU6ml3IqVsowVeqWT6Vu9Lt4rd+GLzF6wMW2l3nJREoOvHUKCsNZRt1Dm7E7mPxARYNAzmPA5lmsIjy6F4HbtTKWUrpwq8iLQQkYGO50VEpIJrYyllDxHh9WavU61QNV758xWOXDxid6SU/PNZzc6Rp61JaTxkoKqbEnUOvusDf30OTR+FfrMhb2G7UyllO2cGunkDGMp/Ped9gWmuDKWUnfx9/Pm47cd4iRfPL3+eqPgouyOlVLI+dHwH9v4Gf423O429Tu2yRvw7tApCP7PuONDJYpQCnDuD7wmEApEAxpjjQLArQyllt1JBpXi/1fscuHCAkWtG4nZDOjd9BKp3haVvQNhGu9PYY/cv1mQxcZEw4Bdo+KDdiZRyK84U+Dhj/XUzACKiU8WqXKF5yeY80+AZFh5ayNSdU+2Ok5IIdP8cgkvCzAEQfcHuRK6TEAuXTlpTux7+C3b/Cktehx/vs8YHeHQ5lL3F7pRKuR0fJ9b5SUQmAAVE5BGsmeQmujaWUu5hUO1B7Dizg482fkSNQjVoWqKp3ZH+E1AQ7ppkja8+7xm4e6r7Dr9qjDWufvR5Jx4XUr6+1iWSuvdaU+vqePJKpcup2eREpAPQERBgkTFmiauDXS+dTU65SmR8JH1/6UtEbATTu06neN7idkdKac1nsHg43PGB1XTvSklJEHvRucIck+p1Yty1v9fbDwIKWQctVx8FUv2b7BEYAgXKuHZflcoBMppNTqeLVcoJ/0b8S99f+lIhXwUmd5lMHu88dkf6T1IS/HAvHFxmDcdaol7mn0lMSFWALzh3dh1zATIaBMgv6L+i7F8gbWG+1sM3wH1bH5RyYzdV4EXkEmknl4kANgAvGmMOZknKm6QFXrna70d+5/llz9O7Sm9GNh9pd5yUIs/Cly3A1x9avph5E3hsRsPxCvjnT//MOaOHfwHw8cue/VVKARkXeGeuwX8MhAHfYzXR3wtUAjYB3wBtsiSlUm6ufdn2PFLnESZum0itkFrcVfUuuyP9J29h6PM1TAmFuU9Zy8Q7ZQEOKg5FamRQpAs4CnV+8PK2dXeUUjfPmTP4LcaYeqmWbTbG1E/vPbvoGbzKDolJiTz1x1OsO7GOyZ0nU6+IW/zn/5/LpyEh2irUfkHa7K2Uh8voDN6Z2+SiRORuEfFyPO4GYhzvecYFfKWc5O3lzZiWYygWWIzBywdzJtrN5l4KKmINZZsnWIu7UrmcMwX+fqAfcAo46Xj+gIgEAE+7MJtSbil/nvx80vYTLsZe5KUVLxGfFG93JKWUSsOZ+eAPGmO6GWNCjDFFHM/3G2OijTGrsiOkUu6mWqFqvNH8DTae3Mi4DePsjqOUUmlk2slORPyBQUAtwP/KcmPMQy7MpZTb61qxKzvO7GDarmnUCqlF14pd7Y6klFJXOdNE/y1QHOgErABKA5dcGUqpnGJw48E0KtaIN9e8ye5zu+2Oo5RSVzlT4CsbY0YAkcaYKcCdgA78rBTg6+XLB60/IF+efDy/7HkiYiPsjqSUUoBzBf5KD6ILIlIbyA8UdV0kpXKWkIAQPmrzEaeiTjF05VASkxLtjqSUUk4V+K9EpCAwHJgH7ATGuDSVUjlM3SJ1efWWV1l9fDXjN+fyOdqVUm4hw052IuIFXDTGnAdWAhWzJZVSOVCfKn3Yfmb71ZHu2pdtb3ckpVQuluEZvDEmCRiSTVmUytFEhNdueY3ahWszbNUwDka4xTQNSqlcypkm+qUi8pKIlBGRQlceLk+mVA6UxzsPH7X9iDzeeXh+2fNExkfaHUkplUs5U+DvAZ7CaqLf6HjooO9KXUPxvMUZ22osRy4eYfiq4XjKlMxKqZzFmZHsKqTz0GvxSmWgaYmmvNDoBZYeWcrX27+2O45SKhfKtMCLSKCIDBeRrxyvq4iIDtmlVCYerPkgXcp34bN/PmPNsTV2x1FK5TLONNFPAuKA5o7Xx4C3XZZIKQ8hIoxsPpKK+Ssy5M8hhF0KszuSUioXcabAVzLGvI9jwBtjTBSg81Aq5YRA30A+afsJSSaJF5a/QHRCtN2RlFK5hDMFPs4xNawBEJFKQKxLUynlQcrmK8t7Ld9jz7k9jPprlHa6U0plC2cK/EjgN6CMiHwH/I7eG6/UdWlVuhVP1H+C+Qfn88PuH+yOo5TKBZzpRb8Y6AUMAH4AGhtjljvz5SLSWUT2iMh+EXklnffLicjvIrJVRJaLSGnH8voi8peI7HC8d8/17JRS7uixuo/RpnQbxq4fy8aTG+2Oo5TycM70op8PdASWG2MWGGPOOPPFIuINjAe6ADWBviJSM9VqHwBTjTF1gbeAdx3Lo4AHjTG1gM7AxyJSwJntKuWuvMSL0S1HUyq4FC8uf5FTUafsjqSU8mDONNF/ALQEdorITBHpIyL+TnyuKbDfGHPQGBMH/Ah0T7VOTeAPx/NlV943xuw1xuxzPD8OnAKKOLFNpdxasF8wH7f5mKiEKAYvH0x8YnzmH1JKqRvgTBP9CmPMk1gTzUwA7sYquJkpBRxN9jrMsSy5LVjN/wA9gWARKZx8BRFpCvgBB1JvQEQeFZENIrLh9OnTTkRSyn6VC1Zm1G2j2HJ6C2PW68SMSinXcOYMHkcv+t7A40ATYEoWbf8loLWI/AO0xrrH/upk2iJSAvgWGOiY+CYFY8xXxpjGxpjGRYroCb7KOTqV78TAWgOZvmc6s/fNtjuOUsoDZThdLICI/ITV3P4b8DmwIr1im45jQJlkr0s7ll3laH7v5dhOENDbGHPB8Tof8AswzBiz1ontKZWjPNvwWXae28nba9+masGq1AqpZXckpZQHceYM/muswW4eN8YsA5qLyHgnPrceqCIiFUTED7gXmJd8BREJccw5D/Aq8I1juR8wG6sD3kwn90WpHMXHy4exrcZSOKAwzy9/nnMx5+yOpJTyIM5cg18E1BWR90XkEDAK2O3E5xKAp4FFwC7gJ2PMDhF5S0RCHau1AfaIyF6gGPCOY/ndQCtggIhsdjzqX9eeKZUDFPQvyEdtP+Jc9DmGrBhCQlKC3ZGUUh5CrjWqlohUBfo6HmeA6cBLxphy2RfPeY0bNzYbNugstipnmrN/DiNWj2BgrYEMbjzY7jhKqRxCRDYaYxqn915G1+B3A38CXY0x+x1f9IIL8imV6/Wo3IPtZ7YzacckaobUpHP5znZHUkrlcBk10fcCTgDLRGSiiLRHJ5lRymWGNhlKvSL1eH316+w7v8/uOEqpHO6aBd4YM8cYcy9QHWsQmueBoiLyhYh0zKZ8SuUavt6+jGszjry+eXlh+QtcjLtodySlVA7mTCe7SGPM98aYbli3uv0DDHV5MqVyoaKBRfmw9Yccu3SM1/58jSSn7khVSqm0nBro5gpjzHnH4DLtXRVIqdyuYbGGvNzkZVaErWDC1gl2x1FK5VDXVeCVUtmjb/W+hFYK5YvNX7AybKXdcZRSOZAWeKXckIgw4tYRVC9UnVdWvsKRi0fsjqSUymG0wCvlpvx9/Pmo7Ud4eXnx3LLniIqPsjuSUioH0QKvlBsrFVSK91u9z8GIg7yx5g2uNTCVUkqlpgVeKTfXvGRznmnwDL8d+o2pO6faHUcplUNogVcqBxhUexAdynXgo40f8feJv+2Oo5TKAbTAK5UDiAijbhtFuXzleGnFS4RHhtsdSSnl5rTAK5VD5PXNy8dtPyYuKY7nlz1PbGKs3ZGUUm5MC7xSOUiF/BUY3WI0O87u4J2172inO6XUNWmBVyqHaVe2HY/WfZTZ+2czY+8Mu+MopdyUFnilcqAn6z3JbaVu492/32XL6S12x1FKuSEt8ErlQN5e3oxpOYbigcUZvGwwZ6LP2B1JKeVmtMArlUPlz5Ofj9t+zMW4i7y4/EXik+LtjqSUciNa4JXKwaoVqsbI5iPZdGoT4zaMszuOUsqN+NgdQCl1c+6seCfbz2xn2q5p1Cxck26VutkdSSnlBvQMXikPMLjxYBoXa8xbf73FqmOr7I6jlHIDWuCV8gC+Xr6MbT2WEkEleGLpE7y04iVORp60O5ZSykZa4JXyECEBIczsNpOn6z/N8qPLCZ0TytQdU0lISrA7mlLKBlrglfIgft5+PFbvMWZ3n02jYo0Yu2Es9yy4h39O/WN3NKVUNtMCr5QHKhNchvHtx/NxG+s2ugcXPsjrq1/nfMx5u6MppbKJFnilPJSI0L5ce+Z2n8vA2gOZf2A+3eZ0Y9beWSSZJLvjKaVcTAu8Uh4u0DeQwY0GM6PbDCoXqMzIv0bSb2E/dp/bbXc0pZQLaYFXKpeoXLAykzpNYnSL0YRdCuOeBfcw5u8xXI67bHc0pZQLaIFXKhcREbpV6sa8HvO4q+pdfLfrO0LnhLLw34U69axSHkYLvFK5UP48+Rl+63C+v/N7igQWYcjKITyy5BH+jfjX7mhKqSyiBV6pXKx2SG2+v+N7ht0yjJ1ndtJrXi8+3fQp0QnRdkdTSt0kLfBK5XLeXt7cW/1e5vWcR5fyXZi4bSI95/ZkxdEVdkdTSt0ELfBKKcAaCW90y9F80+kb/L39efqPp3nuj+c4fvm43dGUUjdAC7xSKoUmxZswo9sMXmj0An+d+Isec3vw9baviU/U+eaVykm0wCul0vD19uWh2g8xt/tcmpdszsebPqbP/D6sD19vdzSllJO0wCulrqlEUAk+bvsx49uPJzYxlocWPcSrf77KmegzdkdTSmVCC7xSKlOtSrdidvfZPFr3URYdWkTo7FB+2P0DiUmJdkdTSl2DFnillFMCfAJ4psEzzAqdRa2QWoxeN5q+v/Rl+5ntdkdTSqVDC7xS6rpUyF+Brzp8xdhWYzkTfYb7frmPt9e+TURshN3RlFLJaIFXSl03EaFzhc7M6zGP+2vcz4y9MwidE8q8A/N0yFul3IQWeKXUDQvyC2Jo06FM7zqdMsFlGLZqGAN+G8C+8/vsjqZUrqcFXil106oXqs7ULlN5s/mbHIg4wN3z72bchnFExUfZHU2pXMulBV5EOovIHhHZLyKvpPN+ORH5XUS2ishyESmd7L3+IrLP8ejvypxKqZvnJV70qtKL+T3mE1o5lEk7JhE6J5Slh5dqs71SNhBX/R9PRLyBvUAHIAxYD/Q1xuxMts4MYIExZoqItAMGGmP6iUghYAPQGDDARqCRMeb8tbbXuHFjs2HDBpfsi1Lq+m0+tZlRa0ex9/xeWpRqwWtNX6NMvjJ2x1LKo4jIRmNM4/Tec+UZfFNgvzHmoDEmDvgR6J5qnZrAH47ny5K93wlYYow55yjqS4DOLsyqlMpi9YvWZ3rX6QxpMoRNJzfRc15PvtzyJbGJsXZHUypXcGWBLwUcTfY6zLEsuS1AL8fznkCwiBR28rNKKTfn4+VDv5r9mNdjHm3LtGX85vH0ntebNcfW2B1NKY9ndye7l4DWIvIP0Bo4Bjg9NJaIPCoiG0Rkw+nTp12VUSl1k4rlLcbY1mOZ0GECAI8tfYyXVrzEyciTNidTynO5ssAfA5JfcCvtWHaVMea4MaaXMaYBMMyx7IIzn3Ws+5UxprExpnGRIkWyOL5SKqs1L9mcn0N/5un6T7P86HJC54QydcdUEpIS7I6mlMdxZSc7H6xOdu2xivN64D5jzI5k64QA54wxSSLyDpBojHnd0cluI9DQseomrE525661vfQ62cXHxxMWFkZMTExW7prKQv7+/pQuXRpfX1+7o6hsdvTSUd5d9y5/HvuTqgWrMvzW4TQo2sDuWErlKBl1svNx1UaNMQki8jSwCPAGvjHG7BCRt4ANxph5QBvgXRExwErgKcdnz4nIKKyDAoC3Miru1xIWFkZwcDDly5dHRLJgr1RWMsZw9uxZwsLCqFChgt1xVDYrE1yG8e3H88fRP3jv7/d4cOGD9KzckxcavUBB/4J2x1Mqx3PZGXx2S+8MfteuXVSvXl2LuxszxrB7925q1KhhdxRlo6j4KL7c+iXf7viWvH55eb7h8/Sq0gsvsbubkFLuza7b5NyCFnf3pr+PAgj0DWRwo8HM6DaDygUq8+Zfb9JvYT92n9ttdzSlskySScrW7Xl8gXcHJ0+e5L777qNixYo0atSIZs2aMXv2bJYvX46IMH/+/Kvrdu3aleXLlwPQpk0bGjf+78Bsw4YNtGnTJpvTK5V9KheszKROkxjdYjRhl8K4Z8E9jPl7DJfjLtsdTakbZozh9yO/031Od/ac25Nt29UC72LGGHr06EGrVq04ePAgGzdu5McffyQsLAyA0qVL884771zz86dOnWLhwoXZFVcp24kI3Sp1Y16PedxV9S6+2/UdoXNCWfjvQh3yVuU4e87t4eHFD/P8sufxFu9sHehJC7yL/fHHH/j5+fH4449fXVauXDmeeeYZAOrVq0f+/PlZsmRJup9/+eWXMzwAUMpT5c+Tn+G3DueHO3+gaGBRhqwcwiNLHuHfiH/tjqZUps5En2HkmpHcNf8u9p7fy7BbhjEzdCZ1i9TNtgwu60Xvbt6cv4Odxy9m6XfWLJmPN7rVynCdHTt20LBhwwzXGTZsGCNGjKBDhw5p3rvSnL9s2TKCg4NvKq9SOVGtkFp8d8d3zNw7k082fUKveb0YWGsgA2oPIJ9fPrvjKZVCXGIc03ZN46utXxGbEEu/mv14tO6j5M+TP9uz6Bl8NnvqqaeoV68eTZo0ubqsVatWAKxatSrdzwwfPpy33347W/Ip5Y68vby5p/o9zOs5jy7luzBx20Ta/9SeYauG8c+pf7TpXtnOGMOSw0sInRPKRxs/oknxJszuPpuXm7xsS3GHXHQGn9mZtqvUqlWLWbNmXX09fvx4zpw5k6LzHFhn8W+//TY+Pml/knbt2jF8+HDWrl3r8rxKubOQgBBGtxzNAzUfYObemfxy8BfmHZhHpfyV6F21N90qdqOAfwG7Y6pcZufZnby//n02ntxI5QKV+arDVzQr2czuWHoG72rt2rUjJiaGL7744uqyqKioNOt17NiR8+fPs3Xr1nS/Z/jw4bz//vsuy6lUTlKzcE1eb/Y6y+5expvN3ySvb17eX/8+7Wa0Y8jKIfx94m89q1cudzrqNK+vfp17F9zLwQsHGXHrCGZ0m+EWxR1y0Rm8XUSEOXPm8MILL/D+++9TpEgR8ubNy5gxY9KsO2zYMLp3Tz2jruWOO+5Ax9tXKqVA30B6VelFryq92HNuD7P2zWLBwQUs/Hch5fKVo1eVXnSv1J3CAYXtjqo8SExCDN/u/Jb/bfsfcUlxDKg1gEfqPkKwn3v1k/L4kex0hDT3p7+TykoxCTEsObyEmXtnsunUJnzEh7Zl29KnSh9uLXmrjo6nbpgxhkWHF/HRho84Hnmc9mXbM7jRYMrmK2tbJlvGoldKKTv4+/jTrVI3ulXqxsELB5m1bxbzDsxjyeEllAoqRc/KPelRuQfF8hazO6rKQXac2cGY9WP459Q/VCtYja9v+5qmJZraHStDegavbKe/k3K1uMQ4/jjyBzP3zmRd+Dq8xItWpVvRp0ofbit1Gz5eeq6j0ncy8iSf/vMp8w7Mo5B/IZ5r+BzdK3XH28vb7miAnsErpXI5P28/OlfoTOcKnTly8Qg/7/uZOfvnsPzocooGFqVn5Z70qtKLkkEl7Y6q3ER0QjRTdkzhm+3fkJCUwKDag3i4zsME+QXZHc1pegavbKe/k7JDfFI8K4+uZMa+Gaw5tgaA5qWa06dKH1qXaY2vl6/NCZUdjDEs/HchH236iPDIcDqU68ALjV6gTHAZu6OlS8/glVIqFV8vX9qXa0/7cu05fvk4s/fP5ud9P/PC8hco7F+YHpV70LtKb8rkc88/7CrrbT29lTHrx7D19FZqFKrBuy3epXHxdGtnjqBn8Mp2+jspd5GQlMDqY6uZuW8mf4b9SaJJ5Jbit9C7am/al22Pn7ef3RGVC4RHhvPxpo/55eAvhASE8FzD5witFJoj7rjQM3ibnTx5khdeeIG1a9dSsGBB/Pz8GDJkCD179szS7QwYMICuXbvSp0+fLP1epXILHy8fWpdpTesyrTkVdYo5++fw876fGbJyCAXyFCC0Uii9q/amYv6KdkdVWSAqPorJOyYzafskkkwSj9R5hIfrPEygb6Dd0bKEFngXuzJdbP/+/fn+++8BOHz4MPPmzUuxXkJCQrrD1Cql7FE0sCiP1n2Uh+s8zNrja5m5bybf7/qeqTun0rBoQ/pU7UOHch3w9/G3O6q6TkkmiV8O/sLHmz7mVNQpOpfvzAuNXvC4Tpbu3/6Qw2U0XezkyZMJDQ2lXbt2tG/fnsjISB566CGaNm1KgwYNmDt3LgCJiYm8/PLLNGnShLp16zJhwgTAOnh4+umnqVatGrfffjunTp26us0ePXpc3d6SJUuyvLVAqdzCS7xoXqo549qMY+ldSxncaDBnY87y2qrXaDejHaPXjWbPuT12x1RO2nxqM/f/cj+vrXqNogFFmdplKmNbj/W44g656Qx+4SsQvi1rv7N4HejyXoarZDZd7KZNm9i6dSuFChXitddeo127dnzzzTdcuHCBpk2bcvvtt/Pdd9+RP39+1q9fT2xsLLfddhsdO3bkn3/+Yc+ePezcuZOTJ09Ss2ZNHnroIdq2bcuTTz7J6dOnKVKkCJMmTeKhhx7K2n1XKhcqHFCYgbUHMqDWADac3MDMvTOZuXcmP+z+gbohdeldtTedy3f2mCZeT3L88nE+3vgxCw8tpGhAUUa3GM2dFe/MEdfZb1TuKfBu4qmnnmLVqlX4+fnx1FNP0aFDBwoVKgTA4sWLmTdvHh988AEAMTExHDlyhMWLF7N161ZmzpwJQEREBPv27WPlypX07dsXb29vSpYsSbt27QBr/Pt+/foxbdo0Bg4cyF9//cXUqVPt2WGlPJCI0KR4E5oUb8KrMa8y/+B8Zu2dxRtr3mDM32O4o+Id9Knah1qF7ZnFUv0nKj6K/237H1N3TkUQHq/3OANrDcwVB2G5p8BncqbtKplNF5s3b96r7xljmDVrFtWqVUvxHcYYPvvsMzp16pRi+a+//nrN7Q4cOJBu3brh7+/PXXfdpdf3lXKRAv4F6FezHw/UeIAtp7cwc+9MFhxYwMy9M6lRqAa9q/Tmjop3uN1EJJ4uySQx78A8Pt30KaejT3NnxTt5vuHzFM9b3O5o2cZz2ybchLPTxQJ06tSJzz777Oo0l//888/V5V988QXx8fEA7N27l8jISFq1asX06dNJTEzkxIkTLFu27Op3lSxZkpIlS/L2228zcOBAV+2eUspBRKhftD5vt3ib3+/+nWG3DMNgeHvd27Sf0Z7hq4az+dRmncY2G2w8uZG+v/RlxOoRlMhbgml3TOO9lu/lquIOuekM3iYZTRcbHR2dYt0RI0bw/PPPU7duXZKSkqhQoQILFizg4Ycf5tChQzRs2BBjDEWKFGHOnDn07NmTP/74g5o1a1K2bFmaNUs5B/H999/P6dOn9R5zpbJZPr983Fv9Xu6pdg87z+5k5r6Z/HrwV+YemEvlApXpXaU33Sp1I3+e/HZH9Shhl8L4aONHLD68mGKBxXiv5XvcUeEORMTuaLbQgW482NNPP02DBg0YNGiQ3VEylNt/J5U7RMVHsfDfhczaN4ttZ7bh5+VHh/Id6F2lN42LNc61RSgrRMZHMnHrRL7d+S3eXt5XO0IG+ATYHc3ldKCbXKhRo0bkzZuXDz/80O4oSikg0DeQ3lV707tqb/ac28PMvTP55eAv/HLwF8rnK0+vKr0IrRRK4YDCdkfNMRKTEpl7YC6fbvqUszFnCa0UyrMNntWpgB30DF7ZTn8nlVtFJ0Sz5PASZu2dxaZTm/Dx8qFdmXb0rtqbW0vc6tG3cN2s9eHreX/9++w+t5v6ReoztOlQaofUtjtWttMzeKWUckMBPgGEVgoltFIoBy4cYNa+Wcw/MJ/FhxdTKqgUPSv3pFZILYoHFqd43uI5aqpSVzl68SgfbvyQ34/8Tsm8JRnbaiydynfSSxzp0AKvlFJuoFKBSgxpMoTnGz7P70d+Z9beWXy++fMU6wT5BlE8b/H/HoHFU7wuFljMY4fOvRR3iYlbJzJt1zR8vHx4tsGz9KvZz2P3NytogVdKKTfi5+1Hlwpd6FKhC2eizxB2KYzwyHBORJ4gPDLcekSFs/PsTs7FnEvz+UL+hSgWWCzdA4ESeUtQJLAIPl45509/YlIiP+//mc//+ZzzMefpXrk7zzZ4liKBReyO5vZyzq+slFK5TEhACCEBIdd8PzYxlpORJ68W/asHAJHhhF0OY0P4Bi7FX0rxGS/xIiQgJE3hT35AUMi/kFtc/197Yi1j149l7/m9NCzakC9u/4KahWvaHSvH0ALvYkFBQVy+fDnFspEjRzJx4kSKFClCQkICo0ePJjQ0NMU6kydP5uWXX6ZUqVLExMTw2GOP8cILL1x9/6uvvmLcuHEA5MuXj3HjxtGiRQsAypcvz4YNGwgJsf4wLF++nA8++IAFCxYwefJkHnroITZv3kzdunUBqF27NgsWLKB8+fKUL1+e4GBrxK3ExER69erF8OHD8ff359ChQ3Tt2pXt27ezfPly2rZty7x58+jWrRsAXbt25aWXXqJNmzYkJCTw+uuvM2PGjKuj9d11110MGzYsq/8nVirXyuOdh7L5ylI2X9lrrhMZH5mi8IdHhXPi8gnCo8LZe34vK8NWEpMYk+Izvl6+FA0smrL4p7ockM8vn8uuex++eJgPNnzA8qPLKRVUinFtxnF72dv1Ovt10gJvkxdeeIGXXnqJXbt20bJlS06dOoWXV8oj5nvuuYfPP/+cs2fPUq1aNfr06UOZMmVYsGABEyZMYNWqVYSEhLBp0yZ69OjB33//TfHimY/UVLp0ad555x2mT5+e7vvLli0jJCSEy5cv8+ijj/LYY48xZcqUa37PlQKf3PDhwwkPD2fbtm34+/tz6dIlvWVPKRvk9c1LpQKVqFSgUrrvG2OIiI242gKQ4lJAZDj/nPqHk5EnSTAJKT4X4BOQbuFP/vp6x3u/GHeRCVsm8P3u78njnYfnGz7PAzUfII93nhve/9xMC7zNatSogY+PD2fOnKFo0aLprlO4cGEqV67MiRMnKFOmDGPGjGHs2LFXz9AbNmxI//79GT9+PKNGjcp0m127dmXlypXs2bMnzbj3yQUFBfHll19SpkwZzp1Le62vXr16xMfHs2TJEjp06HB1eVRUFBMnTuTQoUP4+1sdYIKDgxk5cmSm2ZRS2UtEKOBfgAL+BaheqHq66yQmJXI25myaloDwyHBORp5k1bFVnIk+gyHlbdf5/PJds0PglU6Bft5+JCQlXO1UGBEbQa8qvXi6wdMZXp5Qmcs1BX7M32PYfW53ln5n9ULVGdp06E19x7p16/Dy8qJIkWt3GDly5AgxMTFXm9R37NhBo0aNUqzTuHHjdM+y0+Pl5cWQIUMYPXp0pp/Jly8fFSpUYN++fRQrlnbwiGHDhjFixIgUBX7//v2ULVv2alO/Uipn8/bypmhgUYoGFqVukbrprhOfGM+p6FMpDwKSHQxsPb2VC7EX0nyusH9hvL28ORV1iibFmzCkyZBrHmio65NrCry7+eijj5g2bRrBwcFMnz493WtL06dPZ+XKlezevZvPP//86tlwZtL7rtTL7rvvPt555x3+/fffTL8vo8GQWrVqBcCqVauuuc6kSZP45JNPOHv2LGvWrKFMmTKZblMplbP4evtSKqgUpYJKXXOd6IRoq1NgsssBJyNPciH2At0qdaNdmXZ6nT0L5ZoCf7Nn2lntyjX4jFy5Br9hwwY6duxIaGgoxYsXp2bNmmzcuPHq/O8AGzdupFYta+7pwoULc/78+atN+OfOnbv6/AofHx9efPFFxowZk2GGS5cucejQIapWrUpERES66wwbNoy333776pS0lStX5siRI1y6dIng4GAGDhzIwIEDqV27NomJiRn/D6OU8lgBPgGUz1+e8vnL2x0lV7D/PgiVqcaNG9OvXz8++eQTAIYMGcLQoUM5e/YsAJs3b2by5Mk8+eSTALRp04Zvv/0WsHrCT5s2jbZt26b53gEDBrB06VJOnz6d7nYvX77Mk08+SY8ePShYsOA183Xs2JHz58+zdetWAAIDAxk0aBBPP/00MTExV3PExcXd4P8CSimlrleuOYO3S1RUFKVLl776evDgwTf0PUOHDqVhw4a89tprhIaGcuzYMZo3b46IEBwczLRp0yhRogRgTTv7xBNPUK9ePYwxdO7cmQceeCDNd/r5+fHss8/y3HPPpVjetm1bjDEkJSXRs2dPRowYkWm+YcOG0b1796uv33nnHUaMGEHt2rUJDg4mICCA/v37U7JkyRvaf6WUUtdHJ5tRttPfSSmlbkxGk81oE71SSinlgbTAK6WUUh7IpQVeRDqLyB4R2S8ir6TzflkRWSYi/4jIVhG5w7HcV0SmiMg2EdklIq+6MqdSSinlaVxW4EXEGxgPdAFqAn1FJPUsAcOBn4wxDYB7gf9zLL8LyGOMqQM0Ah4TkfI3ksNT+hh4Kv19lFLKNVx5Bt8U2G+MOWiMiQN+BLqnWscA+RzP8wPHky3PKyI+QAAQB1y83gD+/v6cPXtWi4ibMsZw9uxZpwfwUUop5TxX3iZXCjia7HUYcEuqdUYCi0XkGSAvcLtj+Uysg4ETQCDwgjEm7WDomShdujRhYWHXvM9b2c/f3z/FbYRKKaWyht33wfcFJhtjPhSRZsC3IlIb6+w/ESgJFAT+FJGlxpiDyT8sIo8CjwKULZt2ukRfX18qVKjg4l1QSiml3I8rm+iPAckHHS/tWJbcIOAnAGPMX4A/EALcB/xmjIk3xpwCVgNp7vMzxnxljGlsjGmc0WQtSimlVG7jygK/HqgiIhVExA+rE928VOscAdoDiEgNrAJ/2rG8nWN5XuBWIGunglNKKaU8mMsKvDEmAXgaWATswuotv0NE3hKRUMdqLwKPiMgW4AdggLF6xI0HgkRkB9aBwiRjzFZXZVVKKaU8jccMVSsip4HDdufIAiHAGbtDZAPdT8+i++lZdD9zjnLGmHSvUXtMgfcUIrLhWuMKexLdT8+i++lZdD89gw5Vq5RSSnkgLfBKKaWUB9IC736+sjtANtH99Cy6n55F99MD6DV4pZRSygPpGbxSSinlgbTA28CJaXQHiMhpEdnseDxsR86bJSLfiMgpEdl+jfdFRD51/O+wVUQaZnfGrODEfrYRkYhkv+fr2Z3xZolIGcfUzjtFZIeIPJfOOjn+93RyPz3h9/QXkb9FZItjP99MZ508IjLd8Xuuu9EZPe3k5H56xN/bdBlj9JGND8AbOABUBPyALUDNVOsMAD63O2sW7GsroCGw/Rrv3wEsBARrtMJ1dmd20X62ARbYnfMm97EE0NDxPBjYm85/tzn+93RyPz3h9xQgyPHcF1gH3JpqnSeBLx3P7wWm253bRfvpEX9v03voGXz2c2YaXY9gjFkJZDQLYHdgqrGsBQqISInsSZd1nNjPHM8Yc8IYs8nx/BLW6JSlUq2W439PJ/czx3P8RpcdL30dj9QdsroDUxzPZwLtRUSyKWKWcHI/PZYW+OyX3jS66f0B6e1o5pwpImXSed8TOPu/hSdo5mgmXCgitewOczMcTbUNsM6GkvOo3zOD/QQP+D1FxFtENgOngCXGmGv+nsYaejwCKJytIbOAE/sJHvr3Vgu8e5oPlDfG1AWW8N9RtMqZNmENJ1kP+AyYY2+cGyciQcAs4HljzEW787hKJvvpEb+nMSbRGFMfa6bPpo6puj2OE/vpsX9vtcBnv0yn0TXGnDXGxDpe/g9olE3ZspszUwrneMaYi1eaCY0xvwK+IhJic6zrJiK+WEXvO2PMz+ms4hG/Z2b76Sm/5xXGmAvAMqBzqreu/p4i4gPkB85ma7gsdK399OS/t1rgs1+m0+imum4ZinUd0BPNAx509L6+FYgwxpywO1RWE5HiV65dikhTrP/f5ag/lI78XwO7jDHjrrFajv89ndlPD/k9i4hIAcfzAKADaafkngf0dzzvA/xhHL3Scgpn9tOT/9762B0gtzHGJIjIlWl0vYFvjGMaXWCDMWYe8KxYU+omYHXeGmBb4JsgIj9g9TgOEZEw4A2sTi4YY74EfsXqeb0fiAIG2pP05jixn32AJ0QkAYgG7s1pfyiB24B+wDbH9UyA14Cy4FG/pzP76Qm/Zwlgioh4Yx2g/GSMWZDq79DXwLcish/r79C99sW9Yc7sp0f8vU2PjmSnlFJKeSBtoldKKaU8kBZ4pZRSygNpgVdKKaU8kBZ4pZRSygNpgVdKKaU8kBZ4pdyMiLwrIm1FpIeIvJpF31leHLPdiUhjEfk0K77X8X33isiwDN5f5pjV62MRaXad393SMQvYZhEJEJGxjtdjRWSkiLzkWO8tEbn9ZvdFKU+iBV4p93MLsBZoDazM6i83xmwwxjybhV/ZBfgtvTccg4skGWNigCbAhuv87vuBd40x9Y0x0cCjQF1jzMvJVzLGvG6MWXr90ZXyXFrglXITjrPSrViF8C/gYeALSWe+cccZ+R+OCTJ+F5GyjuWTxZqTfY2IHBSRPul8to2ILHA8HynWfPbLHes/m2y9B8SaS3uziExwDBaS+rsEqI81Pnvq95YB24DaIrINqAOsF5E70lm3vYj8IyLbHHnyiDUv993AKBH5TkTmAUHARhG5J9XnJ1/ZVxE5JCJvisgmx/dVdyzP6/juvx3b8shZHJW6Qgu8Um7CcVY6CJiMVeS3GmPqGmPeSmf1z4ApjgkyvgOSN7mXAFoAXYH3nNh0daAT1lTGb4iIr4jUAO4BbnNM1JGIdTadWgNgS3ojuRlj2gITsOYVfxqY4DgT/zX5eiLi79jne4wxdbBG2HzCGPM/rOFSXzbG3G+MCQWiHd8xPZN9OmOMaQh8AbzkWDYMa7jVpkBbYKyI5M3ke5TKsbTAK+VeGgJbsIpuRmNiNwO+dzz/FqugXzHHGJNkjNkJFHNim78YY2KNMWewptQsBrTHmnRjvWPI1vZAxXQ+2xlYmMF3X9mfuo5/01MN+NcYs9fxegrQyoncGbkyScxGoLzjeUfgFcf+LAf8cQxBq5Qn0rHolXIDIlIf6yy2NHAGCLQWy2agmeP6s7Nikz2X61w/EevvgmC1EGTWya8j0Dv1Qkfz+tNAZaAGViE9KSJdjDHptQRktSv7dGV/wNqn3saYPdmwfaVsp2fwSrkBY8xmR1P4XqAm8AfQKVnnstTW8N/kH/cDf2ZxpN+BPiJSFEBEColIueQriEh+wMcYk2YmNUfzekesJvH6wH5jTI1rFPc9QHkRqex43Q9YkXW7ctUi4JlkM8E1cME2lHIbWuCVchMiUgQ4b4xJAqo7mtiv5RlgoKNTXj/guazM4tj2cGCxYxtLsK7tJ9cByKjneitglYiUAQ5nsK0YrJnnZjg64yUBX95E/GsZhTXL31YR2eF4rZTH0tnklFI3RET+B/zPGLPW7ixKqbS0wCullFIeSJvolVJKKQ+kBV4ppZTyQFrglVJKKQ+kBV4ppZTyQFrglVJKKQ+kBV4ppZTyQFrglVJKKQ/0/+KSKjoeNpR9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "for q, comp_ratios in data.items():\n",
    "    greedy_avg_ratios = []\n",
    "    gnn_avg_ratios = []\n",
    "    lp_match_avg_ratios = []\n",
    "\n",
    "\n",
    "    for trial_ratios in comp_ratios:\n",
    "        gnn_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
    "        greedy_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
    "        lp_match_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
    "\n",
    "    # title = f\"PART_size_{size}\"\n",
    "    title = f\"FEAT_only_ratings_{q}\"\n",
    "    print(title)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(title)\n",
    "    plt.plot(ratios, gnn_avg_ratios, label='GNN')\n",
    "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
    "    plt.plot(ratios, lp_match_avg_ratios, label='LP ROUNDING')\n",
    "    plt.xlabel('# online / # offline')\n",
    "    plt.ylabel('Average competitive ratio')\n",
    "    plt.legend()\n",
    "    # plt.savefig(f\"data/{title}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
