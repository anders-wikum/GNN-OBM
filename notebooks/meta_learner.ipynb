{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import torch_converter as tc\n",
    "import instance_generator as ig\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gnn_library.util import train, save, load\n",
    "from util import NumpyDataset, Dataset\n",
    "from evaluate import evaluate_model, pp_output\n",
    "from gnn_library.OBM_greedy import OBM_Greedy\n",
    "#import evaluate as ev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN1, args1 = load('GNN1', device)\n",
    "GNN2, args2 = load('GNN2', device)\n",
    "GREEDY = OBM_Greedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Meta GNN training/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'TEST',\n",
    "    'head':              'meta',\n",
    "    'num_layers':        2,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        32,\n",
    "    'node_feature_dim':  4,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        64,\n",
    "    'output_dim':        3,\n",
    "    'dropout':           0.25,\n",
    "    'epochs':            25,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "train_num = 50; test_num = 10\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 1,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 4,\n",
    "    'weighted': False\n",
    "}\n",
    "geom_config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "train_instances = [\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "\n",
    "test_instances = [\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "train_data = Dataset(\n",
    "    tc._instances_to_train_samples(\n",
    "        instances=train_instances,\n",
    "        head=args['head'],\n",
    "        meta_model_type='gnn',\n",
    "        base_models=[GNN1, GNN2, GREEDY]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_data = Dataset(\n",
    "    tc._instances_to_train_samples(\n",
    "        instances=test_instances,\n",
    "        head=args['head'],\n",
    "        meta_model_type='gnn',\n",
    "        base_models=[GNN1, GNN2, GREEDY]\n",
    "    )\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'TEST',\n",
    "    'head':              'meta',\n",
    "    'num_layers':        2,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        32,\n",
    "    'node_feature_dim':  4,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        64,\n",
    "    'output_dim':        3,\n",
    "    'dropout':           0.25,\n",
    "    'epochs':            25,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "train_num = 50; test_num = 10\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 1,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 4,\n",
    "    'weighted': False\n",
    "}\n",
    "geom_config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "train_instances = [\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "\n",
    "test_instances = [\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "train_data = Dataset(\n",
    "    tc._instances_to_gnn_samples(\n",
    "        instances=train_instances,\n",
    "        head='regression',\n",
    "        base_models=[GNN1, GNN2, GREEDY],\n",
    "        batch_size=args['batch_size']\n",
    "    )\n",
    ")\n",
    "\n",
    "test_data = Dataset(\n",
    "    tc._instances_to_gnn_samples(\n",
    "        instances=test_instances,\n",
    "        head='regression',\n",
    "        base_models=[GNN1, GNN2, GREEDY],\n",
    "        batch_size=args['batch_size']\n",
    "    )\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, META_GNN, _ = train(train_loader, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(0, 500000)\n",
    "(m, n) = (10, 16)\n",
    "config = er_config\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "eval_instances = ig.sample_instances(m, n, 100, rng, **config)\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "ratios1 = evaluate_model(\n",
    "    meta_model=META_GNN,\n",
    "    meta_model_type='gnn',\n",
    "    base_models=[GNN1, GNN2, GREEDY],\n",
    "    instances=eval_instances,\n",
    "    batch_size=500,\n",
    "    rng=rng,\n",
    "    num_realizations=1\n",
    ")\n",
    "\n",
    "pp_output(ratios1, _, show_log=False)\n",
    "print()\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "ratios2 = evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[GNN1],\n",
    "    instances=eval_instances,\n",
    "    batch_size=500,\n",
    "    rng=rng,\n",
    "    num_realizations=1\n",
    ")\n",
    "\n",
    "pp_output(ratios2, _, show_log=False)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "ratios = evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[GNN2],\n",
    "    instances=eval_instances,\n",
    "    batch_size=500,\n",
    "    rng=rng,\n",
    "    num_realizations=1\n",
    ")\n",
    "\n",
    "pp_output(ratios, _, show_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Meta NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 200; test_num = 40\n",
    "\n",
    "er_config = {\n",
    "    'graph_type': 'ER',\n",
    "    'p': 1,\n",
    "    'weighted': True\n",
    "}\n",
    "ba_config = {\n",
    "    'graph_type': 'BA',\n",
    "    'ba_param': 4,\n",
    "    'weighted': False\n",
    "}\n",
    "geom_config = {\n",
    "    'graph_type': 'GEOM',\n",
    "    'threshold': 0.2,\n",
    "    'scaling': 1 / np.sqrt(2)\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'processor':         'NN',\n",
    "    'head':              'meta',\n",
    "    'num_layers':        5,\n",
    "    'input_dim':         17,\n",
    "    'batch_size':        4,\n",
    "    'hidden_dim':        16,\n",
    "    'output_dim':        2,\n",
    "    'dropout':           0,\n",
    "    'epochs':            50,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "train_instances = [\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, train_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, train_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "\n",
    "test_instances = [\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(6, 10, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(8, 8, test_num, rng, **geom_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **er_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **ba_config),\n",
    "    *ig.sample_instances(10, 6, test_num, rng, **geom_config)\n",
    "]\n",
    "\n",
    "train_data = NumpyDataset(\n",
    "    tc._instances_to_train_samples(\n",
    "        instances=train_instances,\n",
    "        head=args['head'],\n",
    "        meta_model_type='nn',\n",
    "        base_models=[GNN1, GNN2, GREEDY]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_data = NumpyDataset(\n",
    "    tc._instances_to_train_samples(\n",
    "        instances=test_instances,\n",
    "        head=args['head'],\n",
    "        meta_model_type='nn',\n",
    "        base_models=[GNN1, GNN2, GREEDY]\n",
    "    )\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = test_data[0]\n",
    "example = (ex[0].to('cuda:2'), ex[1].to('cuda:2')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'processor':         'NN',\n",
    "    'head':              'meta',\n",
    "    'num_layers':        2,\n",
    "    'input_dim':         23,\n",
    "    'batch_size':        10,\n",
    "    'hidden_dim':        8,\n",
    "    'output_dim':        3,\n",
    "    'dropout':           0,\n",
    "    'epochs':            100,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "_, _, META_NN, _ = train(train_loader, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(0, 50000)\n",
    "(m, n) = (8, 16)\n",
    "config = er_config\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "eval_instances = ig.sample_instances(m, n, 10, rng, **config)\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "ratios1 = evaluate_model(\n",
    "    meta_model=META_NN,\n",
    "    meta_model_type='nn',\n",
    "    base_models=[GNN1, GNN2, GREEDY],\n",
    "    instances=eval_instances,\n",
    "    batch_size=50,\n",
    "    rng=rng,\n",
    "    num_realizations=5\n",
    ")\n",
    "\n",
    "pp_output(ratios1, _, show_log=False)\n",
    "print()\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "ratios2 = evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[GNN1],\n",
    "    instances=eval_instances,\n",
    "    batch_size=50,\n",
    "    rng=rng,\n",
    "    num_realizations=5\n",
    ")\n",
    "\n",
    "pp_output(ratios2, _, show_log=False)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "ratios = evaluate_model(\n",
    "    meta_model=None,\n",
    "    meta_model_type=None,\n",
    "    base_models=[GNN2],\n",
    "    instances=eval_instances,\n",
    "    batch_size=50,\n",
    "    rng=rng,\n",
    "    num_realizations=5\n",
    ")\n",
    "\n",
    "pp_output(ratios, _, show_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,2]) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "node_configs = [(x, 16) for x in np.arange(4, 64, 4)]\n",
    "# of nodes [20 -> 80]\n",
    "# of nodes in batch [10,000 -> 40,000]\n",
    "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
    "graph_configs = [\n",
    "    # {\n",
    "    #     'graph_type': 'GM'\n",
    "    # },\n",
    "    {\n",
    "        'graph_type': 'ER',\n",
    "        'p': 0.75,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'BA',\n",
    "        'ba_param': 4,\n",
    "        'weighted': True\n",
    "    },\n",
    "    {\n",
    "        'graph_type': 'GEOM',\n",
    "        'threshold': 0.2,\n",
    "        'scaling': 1 / np.sqrt(2),\n",
    "    }\n",
    "]\n",
    "\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "print(ratios)\n",
    "data = {config['graph_type']: [] for config in graph_configs}\n",
    "for graph_config in graph_configs:\n",
    "    for i, node_config in enumerate(node_configs):\n",
    "        print(graph_config, node_config)\n",
    "        seed = np.random.randint(0, 500000)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        instances = ig.sample_instances(*node_config, num_trials, rng, **graph_config)\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        (meta_learned_ratios, _) = evaluate_model(\n",
    "            meta_model=META_GNN,\n",
    "            meta_model_type='gnn',\n",
    "            base_models=[GNN1, GNN2, GREEDY],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        gnn1_learned_ratios, greedy_ratios = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type=None,\n",
    "            base_models=[GNN1],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        gnn2_learned_ratios, _ = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type=None,\n",
    "            base_models=[GNN2],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        gnn3_learned_ratios, _ = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type=None,\n",
    "            base_models=[GNN3],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=5\n",
    "        )\n",
    "\n",
    "        data[graph_config['graph_type']].append(np.array(\n",
    "            [\n",
    "                meta_learned_ratios,\n",
    "                gnn1_learned_ratios,\n",
    "                gnn2_learned_ratios,\n",
    "                gnn3_learned_ratios,\n",
    "                greedy_ratios\n",
    "            ]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ratios = [x/y for (x,y) in node_configs]\n",
    "for graph_type, comp_ratios in data.items():\n",
    "    greedy_avg_ratios = []\n",
    "    meta_avg_ratios = []\n",
    "    gnn1_avg_ratios = []\n",
    "    gnn2_avg_ratios = []\n",
    "    gnn3_avg_ratios = []\n",
    "    max_avg_ratios = []\n",
    "\n",
    "    for trial_ratios in comp_ratios:\n",
    "        meta_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
    "        gnn1_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
    "        gnn2_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
    "        gnn3_avg_ratios.append(np.array(trial_ratios[3]).mean())\n",
    "        greedy_avg_ratios.append(np.array(trial_ratios[4]).mean())\n",
    "        max_avg_ratios.append(np.array(np.max(trial_ratios[1:, :], axis=0)).mean())\n",
    "\n",
    "    print(graph_type)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(graph_type)\n",
    "    plt.plot(ratios, gnn1_avg_ratios, label='GNN1')\n",
    "    plt.plot(ratios, gnn2_avg_ratios, label='GNN2')\n",
    "    #plt.plot(ratios, gnn3_avg_ratios, label='GNN3')\n",
    "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
    "    plt.plot(ratios, max_avg_ratios, label='MAX')\n",
    "    plt.plot(ratios, meta_avg_ratios, label='META')\n",
    "    plt.xlabel('# online / # offline')\n",
    "    plt.ylabel('Average competitive ratio')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = np.vstack([gnn1_learned_ratios, gnn2_learned_ratios, greedy_ratios]).T\n",
    "comp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(comp[:2, :], axis=1).mean())\n",
    "print(comp.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = np.argmax(comp[:, 0] - comp[:, 1])\n",
    "index2 = np.argmax(comp[:, 1] - comp[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc._featurize(instances[index1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc._featurize(instances[index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN2_features = []\n",
    "GNN1_features = []\n",
    "for i, boolean in enumerate(comp[:, 1] > comp[:, 0]):\n",
    "    if boolean:\n",
    "        GNN2_features.append(tc._featurize(instances[i]))\n",
    "    else:\n",
    "        GNN1_features.append(tc._featurize(instances[i]))\n",
    "\n",
    "out1 = np.vstack(GNN1_features)\n",
    "out2 = np.vstack(GNN2_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
