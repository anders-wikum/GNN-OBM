{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gnn_library.util import train, save, load\n",
    "from evaluate import evaluate_model, pp_output\n",
    "import instance_generator as ig\n",
    "import torch_converter as tc\n",
    "import evaluate as ev\n",
    "import osmnx as ox\n",
    "from util import Dataset\n",
    "from gnn_library.OBM_threshold_greedy import OBM_Threshold_Greedy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.12.0+cu102\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam optimized for 10,6\n",
    "\n",
    "args = {\n",
    "    'processor':         'GENConv',\n",
    "    'head':              'regression',     \n",
    "    'num_layers':        3,\n",
    "    'num_mlp_layers':    3,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        8,\n",
    "    'node_feature_dim':  5,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        32,\n",
    "    'output_dim':        1,\n",
    "    'dropout':           0.0306,\n",
    "    'epochs':            64,\n",
    "    'opt':               'adagrad',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.0121,\n",
    "    'device':            device,\n",
    "    'noise':             0 # Set to 0 to not train on noisy features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the threshold greedy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [29:33<00:00, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold value: 0.0 achieves CR: 0.05581373962215269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import util\n",
    "seed = 0\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "thresholded_greedy_models = {threshold: OBM_Threshold_Greedy(threshold) for threshold in thresholds}\n",
    "\n",
    "# Node configs and graph configs on which threshold greedy is optimized\n",
    "node_configs = util.node_configs_GNN1\n",
    "graph_configs = util.graph_configs_standard\n",
    "train_num = 20\n",
    "\n",
    "train_instances = [\n",
    "        ig.sample_instances(node_config[0], node_config[1], train_num, rng, args, **graph_config)\n",
    "        for graph_config in graph_configs\n",
    "        for node_config in node_configs\n",
    "]\n",
    "\n",
    "# flat map the train instances\n",
    "train_instances = [instance for instances in train_instances for instance in instances]\n",
    "\n",
    "greedy_ratios = {}\n",
    "for threshold, model in tqdm(thresholded_greedy_models.items()): \n",
    "    ratio, _ = ev.evaluate_model(\n",
    "        meta_model=None,\n",
    "        meta_model_type=None,\n",
    "        base_models=[model],\n",
    "        instances=train_instances,\n",
    "        batch_size=50,\n",
    "        rng=rng,\n",
    "        num_realizations=5\n",
    "    )\n",
    "    greedy_ratios[threshold] = np.mean(ratio['learned'])\n",
    "    \n",
    "\n",
    "max_threshold = max(greedy_ratios, key = greedy_ratios.get)\n",
    "print(f\"Best threshold value: {max_threshold} achieves CR: {greedy_ratios[max_threshold]}\")\n",
    "THRESHOLD_MODEL = thresholded_greedy_models[max_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.991188005856922, 0.01: 0.991188005856922, 0.02: 0.991188005856922, 0.03: 0.991188005856922, 0.04: 0.991188005856922, 0.05: 0.991188005856922, 0.06: 0.991188005856922, 0.07: 0.991188005856922, 0.08: 0.991188005856922, 0.09: 0.991188005856922, 0.1: 0.991188005856922, 0.11: 0.991188005856922, 0.12: 0.991188005856922, 0.13: 0.991188005856922, 0.14: 0.991188005856922, 0.15: 0.991188005856922, 0.16: 0.991188005856922, 0.17: 0.991188005856922, 0.18: 0.991188005856922, 0.19: 0.991188005856922, 0.2: 0.991188005856922, 0.21: 0.991188005856922, 0.22: 0.991188005856922, 0.23: 0.991188005856922, 0.24: 0.991188005856922, 0.25: 0.9902019295044397, 0.26: 0.9902019295044397, 0.27: 0.9902019295044397, 0.28: 0.9902019295044397, 0.29: 0.9902019295044397, 0.3: 0.9902019295044397, 0.31: 0.9902019295044397, 0.32: 0.9902019295044397, 0.33: 0.9902019295044397, 0.34: 0.9902019295044397, 0.35000000000000003: 0.9902019295044397, 0.36: 0.9902019295044397, 0.37: 0.9902019295044397, 0.38: 0.9843320526626002, 0.39: 0.9843320526626002, 0.4: 0.9843320526626002, 0.41000000000000003: 0.9843320526626002, 0.42: 0.9843320526626002, 0.43: 0.9843320526626002, 0.44: 0.9843320526626002, 0.45: 0.9843320526626002, 0.46: 0.9843320526626002, 0.47000000000000003: 0.9843320526626002, 0.48: 0.9843320526626002, 0.49: 0.9843320526626002, 0.5: 0.9843320526626002, 0.51: 0.9843320526626002, 0.52: 0.9843320526626002, 0.53: 0.9843320526626002, 0.54: 0.979407312358734, 0.55: 0.979407312358734, 0.56: 0.979407312358734, 0.5700000000000001: 0.979407312358734, 0.58: 0.9734972553262986, 0.59: 0.9734972553262986, 0.6: 0.9707233178603174, 0.61: 0.9707233178603174, 0.62: 0.9676675166779131, 0.63: 0.9676675166779131, 0.64: 0.9676675166779131, 0.65: 0.9676675166779131, 0.66: 0.9617583187059224, 0.67: 0.9617583187059224, 0.68: 0.9617583187059224, 0.6900000000000001: 0.9617583187059224, 0.7000000000000001: 0.9429772336544191, 0.71: 0.9429772336544191, 0.72: 0.9429772336544191, 0.73: 0.9132090907880122, 0.74: 0.9132090907880122, 0.75: 0.9132090907880122, 0.76: 0.9057725702260783, 0.77: 0.9020783975943706, 0.78: 0.9020783975943706, 0.79: 0.8791015038485144, 0.8: 0.8791015038485144, 0.81: 0.8583653281443541, 0.8200000000000001: 0.8583653281443541, 0.8300000000000001: 0.853483085754162, 0.84: 0.831583286795548, 0.85: 0.8242552510840838, 0.86: 0.8158680470715142, 0.87: 0.8158680470715142, 0.88: 0.7915186446478388, 0.89: 0.7634139147463666, 0.9: 0.7527738342621577, 0.91: 0.7173243331561661, 0.92: 0.7173243331561661, 0.93: 0.7139044132628289, 0.9400000000000001: 0.6817667716926843, 0.9500000000000001: 0.6297126048856235, 0.96: 0.6137721359416153, 0.97: 0.5844409766467589, 0.98: 0.4887017839169906, 0.99: 0.4150992656041641, 1.0: 0.4}\n"
     ]
    }
   ],
   "source": [
    "print(greedy_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
