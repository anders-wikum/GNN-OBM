{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from instance_generator import sample_instances\n",
    "from gnn_library.util import train, save, load, gen_train_input\n",
    "from evaluate import evaluate_model\n",
    "from params import *\n",
    "from util import upload_meta_experiment, load_meta_experiments, \\\n",
    "    graph_config_to_string, _plot_meta_ratios\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.12.0+cu102\n",
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train meta-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN1, args1 = load('GNN_large_6_10', device)\n",
    "GNN2, args2 = load('GNN_large_10_6', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhay/GNN-OBM/torch_converter.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(mask)\n",
      "Training:   0%|          | 0/35 [00:01<?, ?Epochs/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'base_model_preds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'base_model_preds'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/alexhay/GNN-OBM/notebooks/exp_regime_generalization.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736f616c2d372e7374616e666f72642e656475222c2275736572223a22616c6578686179227d/home/alexhay/GNN-OBM/notebooks/exp_regime_generalization.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(META_TRAIN_CONFIG[\u001b[39m\"\u001b[39m\u001b[39mtrain_num\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736f616c2d372e7374616e666f72642e656475222c2275736572223a22616c6578686179227d/home/alexhay/GNN-OBM/notebooks/exp_regime_generalization.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m train_loader, val_loader \u001b[39m=\u001b[39m gen_train_input(META_TRAIN_CONFIG, args, seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, base_models\u001b[39m=\u001b[39m[GNN1, GNN2])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736f616c2d372e7374616e666f72642e656475222c2275736572223a22616c6578686179227d/home/alexhay/GNN-OBM/notebooks/exp_regime_generalization.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m _, _, _, META_GNN, _ \u001b[39m=\u001b[39m train(train_loader, val_loader, args)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736f616c2d372e7374616e666f72642e656475222c2275736572223a22616c6578686179227d/home/alexhay/GNN-OBM/notebooks/exp_regime_generalization.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m save(META_GNN, args, \u001b[39m'\u001b[39m\u001b[39mMETA_GNN\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/GNN-OBM/gnn_library/util.py:154\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, args, trial)\u001b[0m\n\u001b[1;32m    151\u001b[0m acc_fn \u001b[39m=\u001b[39m _get_acc(args)\n\u001b[1;32m    152\u001b[0m _, opt \u001b[39m=\u001b[39m build_optimizer(args, model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m--> 154\u001b[0m \u001b[39mreturn\u001b[39;00m _train(\n\u001b[1;32m    155\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    156\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    157\u001b[0m     acc_fn\u001b[39m=\u001b[39;49macc_fn,\n\u001b[1;32m    158\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m    159\u001b[0m     test_loader\u001b[39m=\u001b[39;49mtest_loader,\n\u001b[1;32m    160\u001b[0m     epochs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m    161\u001b[0m     opt\u001b[39m=\u001b[39;49mopt,\n\u001b[1;32m    162\u001b[0m     device\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    163\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial\n\u001b[1;32m    164\u001b[0m )\n",
      "File \u001b[0;32m~/GNN-OBM/gnn_library/util.py:234\u001b[0m, in \u001b[0;36m_train\u001b[0;34m(model, loss_fn, acc_fn, train_loader, test_loader, epochs, opt, device, trial)\u001b[0m\n\u001b[1;32m    231\u001b[0m     scale \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mnum_graphs\n\u001b[1;32m    232\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 234\u001b[0m pred \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m    235\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, batch)\n\u001b[1;32m    237\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GNN-OBM/gnn_library/OBM_deeperGCN.py:76\u001b[0m, in \u001b[0;36mDeeperGCN.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m x, edge_index, edge_attr, batch_ids, num_graphs, graph_features \u001b[39m=\u001b[39m \\\n\u001b[1;32m     73\u001b[0m     _extract_batch(batch)\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack([x, batch\u001b[39m.\u001b[39;49mbase_model_preds])\n\u001b[1;32m     78\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_encoder(x)\n\u001b[1;32m     79\u001b[0m edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_encoder(edge_attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/data.py:441\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'base_model_preds'"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'processor':         'DeeperGCN',\n",
    "    'head':              'meta',\n",
    "    'num_layers':        4,\n",
    "    'num_mlp_layers':    2,\n",
    "    'aggr':              'max',\n",
    "    'batch_size':        6,\n",
    "    'node_feature_dim':  7,\n",
    "    'edge_feature_dim':  1,\n",
    "    'graph_feature_dim': 2,\n",
    "    'hidden_dim':        8,\n",
    "    'output_dim':        2,\n",
    "    'head_mlp_dim':      8,\n",
    "    'dropout':           0,\n",
    "    'epochs':            35,\n",
    "    'opt':               'adam',\n",
    "    'opt_scheduler':     'none',\n",
    "    'opt_restart':       0,\n",
    "    'weight_decay':      5e-3,\n",
    "    'lr':                0.001,\n",
    "    'device':            device\n",
    "}\n",
    "\n",
    "print(\"loading data\")\n",
    "print(META_TRAIN_CONFIG[\"train_num\"])\n",
    "train_loader, val_loader = gen_train_input(META_TRAIN_CONFIG, args, seed=0, base_models=[GNN1, GNN2])\n",
    "_, _, _, META_GNN, _ = train(train_loader, val_loader, args)\n",
    "save(META_GNN, args, 'META_GNN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime generalization experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute meta-GNN CRs over all graph configurations and node ratio regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_GNN, args = load('META_GNN', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "num_trials = 100\n",
    "batch_size = 100\n",
    "graph_configs = ALL_TESTING_GRAPH_CONFIGS\n",
    "node_configs = EXPERIMENT_META_REGIMES\n",
    "baselines_kwargs = {\n",
    "    'greedy': {},\n",
    "    'greedy_t': {'threshold': 0.35},\n",
    "    'lp_rounding': {'rng': rng},\n",
    "    'naor_lp_rounding': {'rng': rng},\n",
    "    'pollner_lp_rounding': {'rng': rng}\n",
    "}\n",
    "\n",
    "regimes = [x/y for (x,y) in node_configs]\n",
    "\n",
    "def _init_data():\n",
    "    return {\n",
    "        \"num_trials\": num_trials,\n",
    "        \"meta_gnn\": [],\n",
    "        \"greedy\": [],\n",
    "        \"greedy_t\": [],\n",
    "        \"lp_rounding\": [],\n",
    "        \"naor_lp_rounding\": [],\n",
    "        \"pollner_lp_rounding\": [],\n",
    "        \"meta_threshold\": []\n",
    "    }\n",
    "\n",
    "for graph_config in graph_configs:\n",
    "    data = _init_data()\n",
    "    graph_str = graph_config_to_string(graph_config)\n",
    "\n",
    "    for i, node_config in enumerate(node_configs):\n",
    "        print(graph_config, node_config)\n",
    "        instances = sample_instances(\n",
    "            *node_config,\n",
    "            num_trials,\n",
    "            rng,\n",
    "            args.__dict__,\n",
    "            **graph_config\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        crs, _ = evaluate_model(\n",
    "            meta_model=None,\n",
    "            meta_model_type='gnn',\n",
    "            base_models=[],#[GNN2],\n",
    "            instances=instances,\n",
    "            batch_size=batch_size,\n",
    "            rng=rng,\n",
    "            num_realizations=20,\n",
    "            baselines=['lp_rounding', 'naor_lp_rounding', 'pollner_lp_rounding'],\n",
    "            **baselines_kwargs\n",
    "        )\n",
    "        \n",
    "        # rng = np.random.default_rng(seed)\n",
    "        # threshold_crs, _ = evaluate_model(\n",
    "        #     meta_model=None,\n",
    "        #     meta_model_type='threshold',\n",
    "        #     base_models=[GNN1, GNN2],\n",
    "        #     instances=instances,\n",
    "        #     batch_size=batch_size,\n",
    "        #     rng=rng,\n",
    "        #     num_realizations=5\n",
    "        # )\n",
    "\n",
    "        #data['meta_gnn'].append(crs['learned'])\n",
    "        # data['greedy'].append(crs['greedy'])\n",
    "        # data['greedy_t'].append(crs['greedy_t'])\n",
    "        data['lp_rounding'].append(crs['lp_rounding'])\n",
    "        data['naor_lp_rounding'].append(crs['naor_lp_rounding'])\n",
    "        data['pollner_lp_rounding'].append(crs['pollner_lp_rounding'])\n",
    "        # data['meta_threshold'].append(threshold_crs['learned'])\n",
    "    \n",
    "    upload_meta_experiment(graph_str, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys():\n",
    "    if key != 'num_trials' and key != 'meta_threshold':\n",
    "        print(key, np.mean(data[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate regime generalization plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_meta_experiments(ALL_TESTING_GRAPH_CONFIGS)\n",
    "_plot_meta_ratios(\n",
    "    regimes,\n",
    "    results,\n",
    "    ['lp_rounding', 'naor_lp_rounding', 'pollner_lp_rounding'],\n",
    "    lambda graph_type: graph_type,\n",
    "    confidence = 0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_meta_experiments(graph_configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
