{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "\n",
                "import os\n",
                "os.chdir('..')\n",
                "from torch_geometric.loader import DataLoader\n",
                "from gnn_library.util import train, save, load\n",
                "from evaluate import evaluate_model, pp_output\n",
                "import instance_generator as ig\n",
                "import torch_converter as tc\n",
                "import evaluate as ev\n",
                "import osmnx as ox\n",
                "from util import Dataset\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
                "print(\"PyTorch has version {}\".format(torch.__version__))\n",
                "print('Using device:', device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "args = {\n",
                "    'processor':         'GENConv',\n",
                "    'head':              'regression',\n",
                "    'num_layers':        2,\n",
                "    'num_mlp_layers':    2,\n",
                "    'aggr':              'max',\n",
                "    'batch_size':        32,\n",
                "    'node_feature_dim':  5,\n",
                "    'edge_feature_dim':  1,\n",
                "    'graph_feature_dim': 2,\n",
                "    'hidden_dim':        64,\n",
                "    'output_dim':        1,\n",
                "    'dropout':           0.35,\n",
                "    'epochs':            25,\n",
                "    'opt':               'adam',\n",
                "    'opt_scheduler':     'none',\n",
                "    'opt_restart':       0,\n",
                "    'weight_decay':      5e-3,\n",
                "    'lr':                0.0001,\n",
                "    'device':            device,\n",
                "    'noise':             0 # Set to 0 to not train on noisy features\n",
                "}\n",
                "\n",
                "# Hyperparameter optimized for 9/7\n",
                "\n",
                "# args = {\n",
                "#     'processor':         'GENConv',\n",
                "#     'head':              'regression',     \n",
                "#     'num_layers':        4,\n",
                "#     'num_mlp_layers':    2,\n",
                "#     'aggr':              'max',\n",
                "#     'batch_size':        8,\n",
                "#     'node_feature_dim':  5,\n",
                "#     'edge_feature_dim':  1,\n",
                "#     'graph_feature_dim': 2,\n",
                "#     'hidden_dim':        58,\n",
                "#     'output_dim':        1,\n",
                "#     'dropout':           0.066,\n",
                "#     'epochs':            80,\n",
                "#     'opt':               'adagrad',\n",
                "#     'opt_scheduler':     'none',\n",
                "#     'opt_restart':       0,\n",
                "#     'weight_decay':      5e-3,\n",
                "#     'lr':                0.0022434,\n",
                "#     'device':            device,\n",
                "#     'noise':             0 # Set to 0 to not train on noisy features\n",
                "# }\n",
                "\n",
                "# Hyperparam optimized for 6,10\n",
                "\n",
                "args = {\n",
                "    'processor':         'GENConv',\n",
                "    'head':              'regression',     \n",
                "    'num_layers':        5,\n",
                "    'num_mlp_layers':    5,\n",
                "    'aggr':              'max',\n",
                "    'batch_size':        2,\n",
                "    'node_feature_dim':  5,\n",
                "    'edge_feature_dim':  1,\n",
                "    'graph_feature_dim': 2,\n",
                "    'hidden_dim':        128,\n",
                "    'output_dim':        1,\n",
                "    'dropout':           0.0115,\n",
                "    'epochs':            32,\n",
                "    'opt':               'adagrad',\n",
                "    'opt_scheduler':     'none',\n",
                "    'opt_restart':       0,\n",
                "    'weight_decay':      5e-3,\n",
                "    'lr':                0.0083,\n",
                "    'device':            device,\n",
                "    'noise':             0 # Set to 0 to not train on noisy features\n",
                "}\n",
                "\n",
                "# Hyperparam optimized for 10,6\n",
                "\n",
                "args = {\n",
                "    'processor':         'GENConv',\n",
                "    'head':              'regression',     \n",
                "    'num_layers':        3,\n",
                "    'num_mlp_layers':    3,\n",
                "    'aggr':              'max',\n",
                "    'batch_size':        8,\n",
                "    'node_feature_dim':  5,\n",
                "    'edge_feature_dim':  1,\n",
                "    'graph_feature_dim': 2,\n",
                "    'hidden_dim':        32,\n",
                "    'output_dim':        1,\n",
                "    'dropout':           0.0306,\n",
                "    'epochs':            64,\n",
                "    'opt':               'adagrad',\n",
                "    'opt_scheduler':     'none',\n",
                "    'opt_restart':       0,\n",
                "    'weight_decay':      5e-3,\n",
                "    'lr':                0.0121,\n",
                "    'device':            device,\n",
                "    'noise':             0 # Set to 0 to not train on noisy features\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_num = 200; test_num = 100\n",
                "node_config = (10,6)\n",
                "\n",
                "er_config = {\n",
                "    'graph_type': 'ER',\n",
                "    'p': 0.75,\n",
                "    'weighted': True\n",
                "}\n",
                "ba_config = {\n",
                "    'graph_type': 'BA',\n",
                "    'ba_param': 2,\n",
                "    'weighted': True\n",
                "}\n",
                "geom_config = {\n",
                "    'graph_type': 'GEOM',\n",
                "    'threshold': 0.2,\n",
                "    'scaling': 1 / np.sqrt(2)\n",
                "}\n",
                "\n",
                "rng = np.random.default_rng()\n",
                "\n",
                "\n",
                "train_instances = [\n",
                "        *ig.sample_instances(*node_config, train_num, rng, args, **er_config),\n",
                "        *ig.sample_instances(*node_config, train_num, rng, args, **ba_config),\n",
                "        *ig.sample_instances(*node_config, train_num, rng, args, **geom_config),\n",
                "    ]\n",
                "\n",
                "test_instances = [\n",
                "        *ig.sample_instances(*node_config, test_num, rng, args, **er_config),\n",
                "        *ig.sample_instances(*node_config, test_num, rng, args, **ba_config),\n",
                "        *ig.sample_instances(*node_config, test_num, rng, args, **geom_config),\n",
                "    ]\n",
                "\n",
                "\n",
                "train_data = Dataset(tc._instances_to_train_samples(train_instances, args['head']))\n",
                "test_data = Dataset(tc._instances_to_train_samples(test_instances, args['head']))\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_data,\n",
                "    batch_size=args['batch_size'],\n",
                "    shuffle=True,\n",
                "    num_workers=4\n",
                ")\n",
                "\n",
                "test_loader = DataLoader(\n",
                "    test_data,\n",
                "    batch_size=args['batch_size'],\n",
                "    shuffle=True,\n",
                "    num_workers=4\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, _, _, GNN, _ = train(train_loader, test_loader, args)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save(GNN, args, 'GNN2_hyperparam_tuned')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GNN, args = load('GNN2', device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from gnn_library.OBM_greedy import OBM_Greedy\n",
                "from gnn_library.OBM_threshold_greedy import OBM_Threshold_Greedy\n",
                "\n",
                "thresholds = np.linspace(0, 1, 101)\n",
                "thresholded_greedy_models = [(threshold, OBM_Threshold_Greedy(threshold)) for threshold in thresholds]\n",
                "\n",
                "seed = np.random.randint(0, 500000)\n",
                "(m, n) = (8, 16)\n",
                "config = er_config\n",
                "\n",
                "rng = np.random.default_rng(seed)\n",
                "eval_instances = ig.sample_instances(m, n, 10, rng, **config)\n",
                "\n",
                "ratios2 = evaluate_model(\n",
                "    meta_model=None,\n",
                "    meta_model_type=None,\n",
                "    base_models=[GNN],\n",
                "    instances=eval_instances,\n",
                "    batch_size=50,\n",
                "    rng=rng,\n",
                "    num_realizations=5\n",
                ")\n",
                "\n",
                "greedy_ratios = {}\n",
                "for threshold, model in thresholded_greedy_models: \n",
                "    ratio = evaluate_model(\n",
                "        meta_model=None,\n",
                "        meta_model_type=None,\n",
                "        base_models=[model],\n",
                "        instances=eval_instances,\n",
                "        batch_size=50,\n",
                "        rng=rng,\n",
                "        num_realizations=5\n",
                "    )\n",
                "    greedy_ratios[threshold] = np.mean(ratio[0])\n",
                "pp_output(ratios2, _, show_log=False)\n",
                "print(greedy_ratios)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_threshold = max(greedy_ratios, key = greedy_ratios.get)\n",
                "print(max_threshold, greedy_ratios[max_threshold])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pivot to feature-generated graphs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_location_graph(city):\n",
                "\tlocation_graph = ox.graph_from_place(city, network_type=\"drive\")\n",
                "\tlocation_graph = ox.speed.add_edge_speeds(location_graph)\n",
                "\tlocation_graph = ox.speed.add_edge_travel_times(location_graph)\n",
                "\treturn {'location_graph': location_graph, 'city': city}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "piedmont = get_location_graph(\"Piedmont, California, USA\")\n",
                "# san_francisco = get_location_graph(\"San Francisco, California, USA\")\n",
                "founex = get_location_graph(\"Founex, Switzerland\")\n",
                "carmel = get_location_graph(\"Carmel, Indiana, USA\")\n",
                "geneva = get_location_graph(\"Geneva, Switzerland\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arg = args.__dict__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# args = {\n",
                "#     'processor':         'GENConv',\n",
                "#     'head':              'regression',\n",
                "#     'num_layers':        2,\n",
                "#     'num_mlp_layers':    2,\n",
                "#     'aggr':              'max',\n",
                "#     'batch_size':        32,\n",
                "#     'node_feature_dim':  4,\n",
                "#     'edge_feature_dim':  1,\n",
                "#     'graph_feature_dim': 2,\n",
                "#     'hidden_dim':        64,\n",
                "#     'output_dim':        1,\n",
                "#     'dropout':           0.35,\n",
                "#     'epochs':            25,\n",
                "#     'opt':               'adam',\n",
                "#     'opt_scheduler':     'none',\n",
                "#     'opt_restart':       0,\n",
                "#     'weight_decay':      5e-3,\n",
                "#     'lr':                0.0001,\n",
                "#     'device':            device\n",
                "# }\n",
                "\n",
                "train_num = 100; test_num = 30\n",
                "\n",
                "er_config = {\n",
                "    'graph_type': 'ER',\n",
                "    'p': 0.75,\n",
                "    'weighted': True\n",
                "}\n",
                "ba_config = {\n",
                "    'graph_type': 'BA',\n",
                "    'ba_param': 2,\n",
                "    'weighted': True\n",
                "}\n",
                "feat_config = {\n",
                "    'graph_type': 'FEAT',\n",
                "    'q': 0.85,\n",
                "    'weighted': True\n",
                "}\n",
                "feat_config = {\n",
                "    'graph_type': 'GEOM',\n",
                "    'q': 0.25,\n",
                "    'd': 2,\n",
                "    'weighted': True\n",
                "}\n",
                "# osmnx_config = {\n",
                "#     'graph_type': 'OSMNX',\n",
                "#     'location_graph': piedmont['location_graph']\n",
                "# }\n",
                "# osmnx_config_2 = {\n",
                "#     'graph_type': 'OSMNX',\n",
                "#     'location_graph': san_francisco['location_graph']\n",
                "# }\n",
                "\n",
                "# ox.plot_graph(piedmont['location_graph'])\n",
                "# ox.plot_graph(san_francisco['location_graph'])\n",
                "\n",
                "# part_config = {\n",
                "# \t'graph_type': 'PART',\n",
                "#     'p': 0.5,\n",
                "#     'size': 4,\n",
                "#     'eps': 0.1\n",
                "# },\n",
                "# part_config = {\n",
                "# \t'graph_type': 'PART',\n",
                "#     'p': 0.5,\n",
                "#     'size': 3,\n",
                "#     'eps': 0.3\n",
                "# }\n",
                "\n",
                "rng = np.random.default_rng()\n",
                "\n",
                "\n",
                "train_instances = [\n",
                "        *ig.sample_instances(8, 8, train_num, rng, arg, **er_config),\n",
                "        *ig.sample_instances(8, 8, train_num, rng, arg, **ba_config),\n",
                "        *ig.sample_instances(8, 8, train_num, rng, arg, **feat_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config_2),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **part_config),\n",
                "    ]\n",
                "\n",
                "test_instances = [\n",
                "        *ig.sample_instances(8, 8, test_num, rng, arg, **er_config),\n",
                "        *ig.sample_instances(8, 8, test_num, rng, arg, **ba_config),\n",
                "        *ig.sample_instances(8, 8, train_num, rng, arg, **feat_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **osmnx_config_2),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
                "        # *ig.sample_instances(8, 8, train_num, rng, **part_config),\n",
                "    ]\n",
                "\n",
                "\n",
                "train_data = Dataset(tc._instances_to_train_samples(train_instances, arg['head']))\n",
                "test_data = Dataset(tc._instances_to_train_samples(test_instances, arg['head']))\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_data,\n",
                "    batch_size=arg['batch_size'],\n",
                "    shuffle=True,\n",
                "    num_workers=4\n",
                ")\n",
                "\n",
                "test_loader = DataLoader(\n",
                "    test_data,\n",
                "    batch_size=arg['batch_size'],\n",
                "    shuffle=True,\n",
                "    num_workers=4\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, _, _, GNN, _ = train(train_loader, test_loader, arg)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set up the threshold greedy value\n",
                "The instance set used to determine the threshold should be the same as the training set for the base models. Here we reduce the number of instances to make the evaluation faster.\n",
                "\n",
                "For the moment, the instance set is the evaluation set since they are too different and would disadvantage threshold greedy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from gnn_library.OBM_threshold_greedy import OBM_Threshold_Greedy\n",
                "from tqdm import tqdm\n",
                "seed = np.random.randint(0, 500000)\n",
                "rng = np.random.default_rng(seed)\n",
                "\n",
                "\n",
                "thresholds = np.linspace(0, 1, 101)\n",
                "thresholds = np.linspace(0, 1, 2) # TODO remove\n",
                "#TODO max value in threshold should be max value observable in graphs (is not the case for osmnx graphs for the moment)\n",
                "thresholded_greedy_models = {threshold: OBM_Threshold_Greedy(threshold) for threshold in thresholds}\n",
                "\n",
                "osmnx_config1 = {\n",
                "    'graph_type': 'OSMNX',\n",
                "    'location_graph': piedmont['location_graph']\n",
                "}\n",
                "osmnx_config2 = {\n",
                "    'graph_type': 'OSMNX',\n",
                "    'location_graph': geneva['location_graph']\n",
                "}\n",
                "osmnx_config3 = {\n",
                "    'graph_type': 'OSMNX',\n",
                "    'location_graph': carmel['location_graph']\n",
                "}\n",
                "\n",
                "train_num = 10\n",
                "train_instances = [\n",
                "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config1),\n",
                "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config2),\n",
                "        *ig.sample_instances(8, 8, train_num, rng, **osmnx_config3),\n",
                "]\n",
                "\n",
                "# train_instances = [\n",
                "#         *ig.sample_instances(8, 8, train_num, rng, **er_config),\n",
                "#         *ig.sample_instances(8, 8, train_num, rng, **ba_config),\n",
                "#         *ig.sample_instances(8, 8, train_num, rng, **feat_config),\n",
                "#         *ig.sample_instances(8, 8, train_num, rng, **osmnx_config),\n",
                "# ]\n",
                "\n",
                "\n",
                "greedy_ratios = {}\n",
                "for threshold, model in tqdm(thresholded_greedy_models.items()): \n",
                "    rng = np.random.default_rng(seed)\n",
                "    ratio = ev.evaluate_model(\n",
                "        meta_model=None,\n",
                "        meta_model_type=None,\n",
                "        base_models=[model],\n",
                "        instances=train_instances,\n",
                "        batch_size=50,\n",
                "        rng=rng,\n",
                "        num_realizations=5\n",
                "    )\n",
                "    greedy_ratios[threshold] = np.mean(ratio[0])\n",
                "    \n",
                "\n",
                "max_threshold = max(greedy_ratios, key = greedy_ratios.get)\n",
                "print(f\"Best threshold value: {max_threshold} achieves CR: {greedy_ratios[max_threshold]}\")\n",
                "THRESHOLD_MODEL = thresholded_greedy_models[max_threshold]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(greedy_ratios)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = np.random.randint(0, 500000)\n",
                "(m, n) = (32, 16)\n",
                "# config = {\n",
                "#     'graph_type': 'FEAT',\n",
                "#     'q': 0.85,\n",
                "#     'weighted': True\n",
                "# }\n",
                "# config = {\n",
                "#     'graph_type': 'OSMNX',\n",
                "#     'location_graph': piedmont['location_graph']\n",
                "# }\n",
                "# config = {\n",
                "# \t'graph_type': 'PART',\n",
                "#     'p': 0.5,\n",
                "#     'size': 4,\n",
                "#     'eps': 0.1\n",
                "# }\n",
                "\n",
                "rng = np.random.default_rng(seed)\n",
                "# eval_instances = ig.sample_instances(m, n, 100, rng, **config)\n",
                "eval_num = 25\n",
                "eval_instances = [\n",
                "        *ig.sample_instances(m, n, eval_num, rng, **er_config),\n",
                "        *ig.sample_instances(m, n, eval_num, rng, **ba_config),\n",
                "        *ig.sample_instances(m, n, eval_num, rng, **feat_config),\n",
                "        *ig.sample_instances(m, n, eval_num, rng, **osmnx_config),\n",
                "]\n",
                "\n",
                "ratios = ev.evaluate_model(\n",
                "    meta_model=None,\n",
                "    meta_model_type=None,\n",
                "    base_models=[GNN],\n",
                "    instances=eval_instances,\n",
                "    batch_size=50,\n",
                "    rng=rng,\n",
                "    num_realizations=5\n",
                ")\n",
                "\n",
                "\n",
                "ratios2 = ev.evaluate_model(\n",
                "    meta_model=None,\n",
                "    meta_model_type=None,\n",
                "    base_models=[THRESHOLD_MODEL],\n",
                "    instances=eval_instances,\n",
                "    batch_size=50,\n",
                "    rng=rng,\n",
                "    num_realizations=5\n",
                ")\n",
                "\n",
                "pp_output(ratios, _, show_log=False)\n",
                "print(f\"Thresholded greedy: {np.mean(ratios2[0]).round(4)}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "GNN, args = load('GNN2_hyperparam_tuned', device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Box plot baseline evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 40\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "\n",
                "models = [(\"GNN\", GNN)]\n",
                "\n",
                "node_config = (10,10)\n",
                "\n",
                "graph_configs = [\n",
                "    {\n",
                "        'graph_type': 'ER',\n",
                "        'p': 0.75,\n",
                "        'weighted': True\n",
                "    },\n",
                "    {\n",
                "        'graph_type': 'BA',\n",
                "        'ba_param': 4,\n",
                "        'weighted': True\n",
                "    },\n",
                "    {\n",
                "        'graph_type': 'GEOM',\n",
                "        'q': 0.15,\n",
                "        'd': 2,\n",
                "        'weighted': True\n",
                "    }\n",
                "]\n",
                "\n",
                "data = {}\n",
                "\n",
                "for graph_config in graph_configs:\n",
                "        print(graph_config)\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, args, **graph_config)\n",
                "\n",
                "\n",
                "        rng = np.random.default_rng(seed)\n",
                "\n",
                "        for model_name, model in models:\n",
                "            cr_ratios, _ = evaluate_model(\n",
                "                meta_model=None,\n",
                "                meta_model_type=None,\n",
                "                base_models=[model],\n",
                "                instances=instances,\n",
                "                batch_size=batch_size,\n",
                "                rng=rng,\n",
                "                num_realizations=5,\n",
                "                baselines=['greedy', 'lp_rounding']\n",
                "            )\n",
                "\n",
                "            data[graph_config['graph_type']] = cr_ratios"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open(f\"saved_runs/box_plot_eval_{node_config[1]}x{node_config[0]}.pickle\", 'wb') as handle:\n",
                "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(f'saved_runs/box_plot_eval_{node_config[1]}x{node_config[0]}.pickle', 'rb') as handle:\n",
                "    data_copy = pickle.load(handle)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from util import _box_plots\n",
                "_box_plots(data, lambda graph_type: f\"{graph_type} {node_config[1]}x{node_config[0]}\", colors = ['pink', 'lightblue', 'lightgreen'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Baseline ER/BA/GEOM evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 40\n",
                "node_configs = [(x, 16) for x in np.arange(4, 40, 8)]\n",
                "# of nodes [20 -> 80]\n",
                "# of nodes in batch [10,000 -> 40,000]\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "\n",
                "models = [(\"GNN\", GNN)]\n",
                "\n",
                "graph_configs = [\n",
                "    {\n",
                "        'graph_type': 'ER',\n",
                "        'p': 0.75,\n",
                "        'weighted': True\n",
                "    },\n",
                "    {\n",
                "        'graph_type': 'BA',\n",
                "        'ba_param': 4,\n",
                "        'weighted': True\n",
                "    },\n",
                "    # {\n",
                "    #     'graph_type': 'GEOM',\n",
                "    #     'threshold': 0.2,\n",
                "    #     'scaling': 1 / np.sqrt(2),\n",
                "    #     'weighted': True\n",
                "    # }\n",
                "]\n",
                "\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "print(ratios)\n",
                "\n",
                "data = {config['graph_type']: [] for config in graph_configs}\n",
                "for graph_config in graph_configs:\n",
                "    for i, node_config in enumerate(node_configs):\n",
                "        print(graph_config, node_config)\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, args, **graph_config)\n",
                "\n",
                "\n",
                "        rng = np.random.default_rng(seed)\n",
                "\n",
                "        baselines = ['greedy']\n",
                "        for model_name, model in models:\n",
                "            cr_ratios = evaluate_model(\n",
                "                meta_model=None,\n",
                "                meta_model_type=None,\n",
                "                base_models=[model],\n",
                "                instances=instances,\n",
                "                batch_size=batch_size,\n",
                "                rng=rng,\n",
                "                num_realizations=5,\n",
                "                # baselines=['greedy', 'lp_rounding']\n",
                "                baselines=baselines\n",
                "            )\n",
                "\n",
                "            baselines = []\n",
                "\n",
                "            cr_ratios[model_name] = cr_ratios.pop(\"learned\")\n",
                "\n",
                "        data[graph_config['graph_type']].append(cr_ratios)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from util import _plot_approx_ratios\n",
                "_plot_approx_ratios(ratios, data, lambda graph_type: graph_type, confidence = 0.95)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "\n",
                "for graph_type, comp_ratios in data.items():\n",
                "    aggregated_ratios = {}\n",
                "\n",
                "    for trial_ratios in comp_ratios:\n",
                "        for model, ratio_values in trial_ratios.items():\n",
                "            current_ratios = aggregated_ratios.get(model, [])\n",
                "            current_ratios.append(np.array(ratio_values).mean())\n",
                "            aggregated_ratios[model] = current_ratios\n",
                "\n",
                "    fig = plt.figure(figsize=(8,6))\n",
                "    for model, model_ratios in aggregated_ratios.items():\n",
                "        plt.plot(ratios, model_ratios, label=model)\n",
                "\n",
                "    title = f\"{graph_type}\"\n",
                "    plt.title(title)\n",
                "    plt.xlabel('# online / # offline')\n",
                "    plt.ylabel('Average competitive ratio')\n",
                "    plt.legend()\n",
                "    plt.savefig(f\"data/17_01_2024_{title}_no_probabilities.png\")\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Noise experiments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_noise_robust_models(noise_values):\n",
                "    models = []\n",
                "    for noise_value in noise_values:\n",
                "        print(f\"Training model for noise {noise_value}\")\n",
                "        args = {\n",
                "        'processor':         'GENConv',\n",
                "        'head':              'regression',\n",
                "        'num_layers':        2,\n",
                "        'num_mlp_layers':    2,\n",
                "        'aggr':              'max',\n",
                "        'batch_size':        32,\n",
                "        'node_feature_dim':  5,\n",
                "        'edge_feature_dim':  1,\n",
                "        'graph_feature_dim': 2,\n",
                "        'hidden_dim':        64,\n",
                "        'output_dim':        1,\n",
                "        'dropout':           0.35,\n",
                "        'epochs':            25,\n",
                "        'opt':               'adam',\n",
                "        'opt_scheduler':     'none',\n",
                "        'opt_restart':       0,\n",
                "        'weight_decay':      5e-3,\n",
                "        'lr':                0.0001,\n",
                "        'device':            device,\n",
                "        'noise':             noise_value # Set to 0 to not train on noisy features\n",
                "        }\n",
                "\n",
                "        train_num = 100; test_num = 30\n",
                "\n",
                "        er_config = {\n",
                "            'graph_type': 'ER',\n",
                "            'p': 0.75,\n",
                "            'weighted': True\n",
                "        }\n",
                "        ba_config = {\n",
                "            'graph_type': 'BA',\n",
                "            'ba_param': 2,\n",
                "            'weighted': True\n",
                "        }\n",
                "        geom_config = {\n",
                "            'graph_type': 'GEOM',\n",
                "            'threshold': 0.2,\n",
                "            'scaling': 1 / np.sqrt(2)\n",
                "        }\n",
                "\n",
                "        rng = np.random.default_rng()\n",
                "\n",
                "\n",
                "        train_instances = [\n",
                "                *ig.sample_instances(9, 7, train_num, rng, args, **er_config),\n",
                "                *ig.sample_instances(9, 7, train_num, rng, args, **ba_config),\n",
                "                *ig.sample_instances(9, 7, train_num, rng, args, **geom_config),\n",
                "            ]\n",
                "\n",
                "        test_instances = [\n",
                "                *ig.sample_instances(9, 7, test_num, rng, args, **er_config),\n",
                "                *ig.sample_instances(9, 7, test_num, rng, args, **ba_config),\n",
                "                *ig.sample_instances(9, 7, test_num, rng, args, **geom_config),\n",
                "            ]\n",
                "\n",
                "\n",
                "        train_data = Dataset(tc._instances_to_train_samples(train_instances, args['head']))\n",
                "        test_data = Dataset(tc._instances_to_train_samples(test_instances, args['head']))\n",
                "\n",
                "        train_loader = DataLoader(\n",
                "            train_data,\n",
                "            batch_size=args['batch_size'],\n",
                "            shuffle=True,\n",
                "            num_workers=4\n",
                "        )\n",
                "\n",
                "        test_loader = DataLoader(\n",
                "            test_data,\n",
                "            batch_size=args['batch_size'],\n",
                "            shuffle=True,\n",
                "            num_workers=4\n",
                "        )\n",
                "\n",
                "\n",
                "        _, _, _, GNN, _ = train(train_loader, test_loader, args)\n",
                "        models.append((f\"GNN_{args['noise']}\", GNN))\n",
                "    return models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "noise_values = np.linspace(0,5,20)\n",
                "# models = create_noise_robust_models(noise_values)\n",
                "models = [GNN] * len(noise_values) # TODO change this"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 80\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "node_config = (9,7)\n",
                "graph_configs = [\n",
                "    {\n",
                "        'graph_type': 'ER',\n",
                "        'p': 0.75,\n",
                "        'weighted': True\n",
                "    },\n",
                "    {\n",
                "        'graph_type': 'BA',\n",
                "        'ba_param': 4,\n",
                "        'weighted': True\n",
                "    },\n",
                "    # {\n",
                "    #     'graph_type': 'GEOM',\n",
                "    #     'threshold': 0.2,\n",
                "    #     'scaling': 1 / np.sqrt(2),\n",
                "    #     'weighted': True\n",
                "    # }\n",
                "]\n",
                "\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "print(ratios)\n",
                "\n",
                "data = {config['graph_type']: [] for config in graph_configs}\n",
                "for graph_config in graph_configs:\n",
                "    for noise_value, model in zip(noise_values, models):\n",
                "        print(f\"Evaluating model for noise {noise_value}\")\n",
                "\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "\n",
                "        args['noise'] = noise_value\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, args, **graph_config)\n",
                "\n",
                "        cr_ratios, _ = evaluate_model(\n",
                "            meta_model=None,\n",
                "            meta_model_type=None,\n",
                "            base_models=[model],\n",
                "            instances=instances,\n",
                "            batch_size=batch_size,\n",
                "            rng=rng,\n",
                "            num_realizations=5,\n",
                "            baselines=['greedy', 'lp_rounding']\n",
                "        )\n",
                "\n",
                "        data[graph_config['graph_type']].append(cr_ratios)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from util import _plot_approx_ratios\n",
                "_plot_approx_ratios(noise_values, data, lambda graph_type: f\"noisy {graph_type}\", x_axis_name=\"noise level\", confidence = 0.95)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## FEAT graph evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 40\n",
                "node_configs = [(x, 16) for x in np.arange(4, 64, 8)]\n",
                "# of nodes [20 -> 80]\n",
                "# of nodes in batch [10,000 -> 40,000]\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "graph_configs = [\n",
                "    {\n",
                "        'graph_type': 'FEAT',\n",
                "        'q': 0.75,\n",
                "        'weighted': True\n",
                "    },\n",
                "    # {\n",
                "    #     'graph_type': 'FEAT',\n",
                "    #     'q': 0.9,\n",
                "    #     'weighted': True\n",
                "    # },\n",
                "    # {\n",
                "    #     'graph_type': 'FEAT',\n",
                "    #     'q': 0.95,\n",
                "    #     'weighted': True\n",
                "    # },\n",
                "    # {\n",
                "    #     'graph_type': 'PART',\n",
                "    #     'p': 0.5,\n",
                "    #     'size': 4,\n",
                "    #     'eps': 0.1\n",
                "    # },\n",
                "    # {\n",
                "    #     'graph_type': 'PART',\n",
                "    #     'p': 0.5,\n",
                "    #     'size': 3,\n",
                "    #     'eps': 0.3\n",
                "    # }\n",
                "]\n",
                "\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "print(ratios)\n",
                "\n",
                "data = {config['q']: [] for config in graph_configs}\n",
                "for graph_config in graph_configs:\n",
                "    for i, node_config in enumerate(node_configs):\n",
                "        print(graph_config, node_config)\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, **graph_config)\n",
                "\n",
                "\n",
                "        rng = np.random.default_rng(seed)\n",
                "        gnn_learned_ratios, greedy_ratios, lp_match_ratios = evaluate_model(\n",
                "            meta_model=None,\n",
                "            meta_model_type=None,\n",
                "            base_models=[GNN],\n",
                "            instances=instances,\n",
                "            batch_size=batch_size,\n",
                "            rng=rng,\n",
                "            num_realizations=5\n",
                "        )\n",
                "        ratios = evaluate_model(\n",
                "            meta_model=None,\n",
                "            meta_model_type=None,\n",
                "            base_models=[GNN],\n",
                "            instances=instances,\n",
                "            batch_size=batch_size,\n",
                "            rng=rng,\n",
                "            num_realizations=5\n",
                "        )\n",
                "\n",
                "\n",
                "        data[graph_config['q']].append(np.array(\n",
                "            [\n",
                "                gnn_learned_ratios,\n",
                "                greedy_ratios,\n",
                "                lp_match_ratios\n",
                "            ]\n",
                "        ))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "for q, comp_ratios in data.items():\n",
                "    greedy_avg_ratios = []\n",
                "    gnn_avg_ratios = []\n",
                "    lp_match_avg_ratios = []\n",
                "\n",
                "\n",
                "    for trial_ratios in comp_ratios:\n",
                "        gnn_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
                "        greedy_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
                "        lp_match_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
                "\n",
                "    # title = f\"PART_size_{size}\"\n",
                "    title = f\"FEAT_only_ratings_{q}\"\n",
                "    print(title)\n",
                "    fig = plt.figure(figsize=(8,6))\n",
                "    plt.title(title)\n",
                "    plt.plot(ratios, gnn_avg_ratios, label='GNN')\n",
                "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
                "    plt.plot(ratios, lp_match_avg_ratios, label='LP ROUNDING')\n",
                "    plt.xlabel('# online / # offline')\n",
                "    plt.ylabel('Average competitive ratio')\n",
                "    plt.legend()\n",
                "    # plt.savefig(f\"data/{title}.png\")\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## OSMNX evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 30\n",
                "node_configs = [(x, 16) for x in np.arange(4, 64, 8)]\n",
                "# of nodes [20 -> 80]\n",
                "# of nodes in batch [10,000 -> 40,000]\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "\n",
                "graph_configs = [\n",
                "    {\n",
                "        'graph_type': 'OSMNX',\n",
                "        'location_graph': piedmont['location_graph'],\n",
                "        'city': piedmont['city']\n",
                "    },\n",
                "    # {\n",
                "    #     'graph_type': 'OSMNX',\n",
                "    #     'location_graph': carmel['location_graph'],\n",
                "    #     'city': carmel['city']\n",
                "    # },\n",
                "    # {\n",
                "    #     'graph_type': 'OSMNX',\n",
                "    #     'location_graph': geneva['location_graph'],\n",
                "    #     'city': geneva['city']\n",
                "    # },\n",
                "    # {\n",
                "    #     'graph_type': 'OSMNX',\n",
                "    #     'location_graph': founex['location_graph'],\n",
                "    #     'city': founex['city']\n",
                "    # },\n",
                "]\n",
                "\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "print(ratios)\n",
                "\n",
                "data = {config['city']: [] for config in graph_configs}\n",
                "for graph_config in graph_configs:\n",
                "    for i, node_config in enumerate(node_configs):\n",
                "        print(node_config, graph_config)\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, **graph_config)\n",
                "\n",
                "\n",
                "        rng = np.random.default_rng(seed)\n",
                "        gnn_learned_ratios, greedy_ratios, lp_match_ratios = evaluate_model(\n",
                "            meta_model=None,\n",
                "            meta_model_type=None,\n",
                "            base_models=[GNN],\n",
                "            instances=instances,\n",
                "            batch_size=batch_size,\n",
                "            rng=rng,\n",
                "            num_realizations=5\n",
                "        )\n",
                "        thresholded_greedy_ratios = [0]\n",
                "\n",
                "        data[graph_config['city']].append(np.array(\n",
                "            [\n",
                "                gnn_learned_ratios,\n",
                "                thresholded_greedy_ratios,\n",
                "                greedy_ratios,\n",
                "                lp_match_ratios\n",
                "            ]\n",
                "        ))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "ratios = [x/y for (x,y) in node_configs]\n",
                "print(ratios)\n",
                "for city, comp_ratios in data.items():\n",
                "    greedy_avg_ratios = []\n",
                "    thresholded_greedy_avg_ratios = []\n",
                "    gnn_avg_ratios = []\n",
                "    lp_match_avg_ratios = []\n",
                "\n",
                "\n",
                "    for trial_ratios in comp_ratios:\n",
                "        gnn_avg_ratios.append(np.array(trial_ratios[0]).mean())\n",
                "        thresholded_greedy_avg_ratios.append(np.array(trial_ratios[1]).mean())\n",
                "        greedy_avg_ratios.append(np.array(trial_ratios[2]).mean())\n",
                "        lp_match_avg_ratios.append(np.array(trial_ratios[3]).mean())\n",
                "        \n",
                "\n",
                "    title = f\"OSMNX_discard_{city}\"\n",
                "    fig = plt.figure(figsize=(8,6))\n",
                "    plt.title(title)\n",
                "    plt.plot(ratios, gnn_avg_ratios, label='GNN')\n",
                "    plt.plot(ratios, thresholded_greedy_avg_ratios, label='Thresholded Greedy')\n",
                "    plt.plot(ratios, greedy_avg_ratios, label='Greedy')\n",
                "    plt.plot(ratios, lp_match_avg_ratios, label='LP ROUNDING')\n",
                "    plt.xlabel('# online / # offline')\n",
                "    plt.ylabel('Average competitive ratio')\n",
                "    plt.legend()\n",
                "    plt.savefig(f\"data/{title}.png\")\n",
                "    plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Graph transferability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_trials = 100\n",
                "node_configs = [(x, x) for x in np.arange(4, 40, 4)]\n",
                "batch_size = 500 #[int(min(32, x + y)) for (x, y) in node_configs]\n",
                "\n",
                "\n",
                "graph_configs = [\n",
                "    {\n",
                "    'graph_type': 'FEAT',\n",
                "    'q': 0.75,\n",
                "    'weighted': True\n",
                "    },\n",
                "]\n",
                "\n",
                "sizes = [x+y for (x,y) in node_configs]\n",
                "print(sizes)\n",
                "\n",
                "data = {config['q']: [] for config in graph_configs}\n",
                "for graph_config in graph_configs:\n",
                "    for i, node_config in enumerate(node_configs):\n",
                "        print(node_config, graph_config)\n",
                "        seed = np.random.randint(0, 500000)\n",
                "        rng = np.random.default_rng(seed)\n",
                "        instances = ig.sample_instances(*node_config, num_trials, rng, args, **graph_config)\n",
                "\n",
                "\n",
                "        rng = np.random.default_rng(seed)\n",
                "\n",
                "        cr_ratios, _ = evaluate_model(\n",
                "            meta_model=None,\n",
                "            meta_model_type=None,\n",
                "            base_models=[GNN],\n",
                "            instances=instances,\n",
                "            batch_size=batch_size,\n",
                "            rng=rng,\n",
                "            num_realizations=5,\n",
                "            baselines=['greedy', 'lp_rounding']\n",
                "        )\n",
                "\n",
                "        data[graph_config['q']].append(cr_ratios)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from util import _plot_approx_ratios\n",
                "\n",
                "_plot_approx_ratios(sizes, data, lambda graph_type: f\"Generalization to node size for ratio {node_config[1]/node_config[0]}\", x_axis_name= \"Total number of nodes\", confidence = 0.95)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "sizes = [x for (x,_) in node_configs]\n",
                "\n",
                "aggregated_ratios = {}\n",
                "for q, comp_ratios in data.items():\n",
                "    for trial_ratios in comp_ratios:\n",
                "        for model, ratio_values in trial_ratios.items():\n",
                "            current_ratios = aggregated_ratios.get(model, [])\n",
                "            current_ratios.append(np.array(ratio_values).mean())\n",
                "            aggregated_ratios[model] = current_ratios\n",
                "\n",
                "fig = plt.figure(figsize=(8,6))\n",
                "for model, ratios in aggregated_ratios.items():\n",
                "    plt.plot(sizes, ratios, label=model)\n",
                "\n",
                "title = f\"16_01_2024_graph_transferability_{q}\"\n",
                "plt.title(\"Graph transferability NxN ratio - trained on 8x8\")\n",
                "plt.xlabel('Number of online nodes')\n",
                "plt.ylabel('Average competitive ratio')\n",
                "plt.legend()\n",
                "plt.savefig(f\"data/{title}.png\")\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "clrs",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
